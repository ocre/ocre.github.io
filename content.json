{"meta":{"title":"憨憨呆呆的IT之旅","subtitle":"我见，我思，我行","description":"这是ocre的个人技术博客，主要记录日常接触的一些技术知识，涵盖后端开发、服务器运维、数据分析等IT领域。也会记录一些所遇问题的解决办法，以备自己和有需要的人按需查找。记录风格偏流水账一些，知识点较分散，尚未成体系，是为：憨憨呆呆的IT之旅。","author":"ocre","url":"http://example.com","root":"/"},"pages":[{"title":"about","date":"2023-12-06T01:16:49.000Z","updated":"2023-12-06T05:56:41.935Z","comments":true,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":"这是ocre的个人技术博客，主要记录日常接触的一些技术知识，涵盖后端开发、服务器运维、数据分析等IT领域。也会记录一些所遇问题的解决办法，以备自己和有需要的人按需查找。记录风格偏流水账一些，知识点较分散，尚未成体系，是为：憨憨呆呆的IT之旅。"},{"title":"标签","date":"2023-12-06T01:16:26.000Z","updated":"2023-12-06T01:43:58.555Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""},{"title":"分类","date":"2023-12-06T01:15:58.000Z","updated":"2023-12-06T01:45:27.252Z","comments":true,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"在麒麟V10编译安装redis 6.x","slug":"install-redis-6-on-kylin-linux-v10-sword","date":"2024-02-07T01:38:21.000Z","updated":"2024-02-07T05:39:55.523Z","comments":true,"path":"2024/02/07/install-redis-6-on-kylin-linux-v10-sword/","link":"","permalink":"http://example.com/2024/02/07/install-redis-6-on-kylin-linux-v10-sword/","excerpt":"","text":"背景现需要在一台信创虚拟机安装redis 6.x, 未找到二进制包版本，因此需要自行编译安装。服务器环境如下： CPU架构 系统类别 系统发行版本 x86_64 Linux Kylin Linux Advanced Server release V10 (Sword) 因为是编译安装，一切都是从源码开始，实际上跟CPU架构和操作系统版本关系不大。下面着重记录一下安装配置过程。 安装redis前的准备工作1. 预期目标 目标项 目标值 安装目录 &#x2F;usr&#x2F;local&#x2F;redis 支持TLS 是 支持远程访问 否 支持免密访问 否 集群部署 暂不考虑 2. 编译环境准备主要是准备好gcc编译器。一般来说麒麟V10已经自带gcc，我机器上gcc版本是7.3.0，版本已经比CentOS 7.x的4.8.5新了，本着够用就好的原则，没有升级到高版本的必要。 3. 准备依赖包主要是openssl库。如果redis不使用TLS模式的话，本步骤可以跳过。我机器上已经自带了OpenSSL 1.1.1f版本，只需要额外安装openssl-devel库即可。偷懒选择yum方式安装。 1yum -y install openssl-devel 这里简单说明一下，机器是离线的，但事先配置好了本地yum源本地yum源配置方法看这里，所以可以用yum install来安装一些系统镜像里自带的库。 编译安装redis1. 准备官网源码先从官网（http://download.redis.io/releases/）下载对应版本源码包。 我下载的是6.2.14版本，下面的记录都以这个版本为准。上传压缩包到安装目标机器，使用tar xvfz redis-6.2.14.tar.gz解压。解压后目录为：redis-6.2.14 2. 编译安装依次执行如下命令进行编译： 123456789101112# 进入源码目录cd redis-6.2.14# 先编译deps子目录下的依赖库cd depsmake -j4 hiredis lua jemalloc linenoisecd ..# 编译（启用TLS支持，这个参数可选）make -j4 BUILD_TLS=yes# 测试一下，这个命令执行时间较长make test# 安装到自定义目录make install PREFIX=/usr/local/redis make过程中可能会出现各种问题，这里就要具体问题具体分析了。一般都是因为缺少lib库，或者没有事先编译deps目录下的依赖库造成的，根据错误提示找找缺少的库文件等等，缺啥补啥，然后make distclean后重新make，大概率能解决。 配置redis服务设置配置文件12345678#在安装目录下创建子目录：mkdir /usr/local/redis/confmkdir /usr/local/redis/data#从源码目录copy配置文件`redis.conf`到安装目录的`conf`子目录cd redis-6.2.14cp redis.conf /usr/local/redis/conf# 根据预先规划需要，编辑redis.confvim redis.conf 主要修改配置项包括： 123456789# 只开启本地监听bind 127.0.0.1 -::1protected-mode yesport 6379daemonize yespidfile /var/run/redis_6379.pidlogfile &quot;&quot;dir /usr/local/redis/datarequirepass &quot;密码&quot; 使用cat /usr/local/redis/conf/redis.conf |grep -v &quot;^#&quot;|grep -v &quot;^$&quot;命令得到完整有效的配置项如下（已过滤注释），供参考： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970bind 127.0.0.1 -::1protected-mode yesport 6379tcp-backlog 511timeout 0tcp-keepalive 300daemonize yespidfile /var/run/redis_6379.pidloglevel noticelogfile &quot;&quot;databases 16always-show-logo noset-proc-title yesproc-title-template &quot;&#123;title&#125; &#123;listen-addr&#125; &#123;server-mode&#125;&quot;stop-writes-on-bgsave-error yesrdbcompression yesrdbchecksum yesdbfilename dump.rdbrdb-del-sync-files nodir /usr/local/redis/datareplica-serve-stale-data yesreplica-read-only yesrepl-diskless-sync norepl-diskless-sync-delay 5repl-diskless-load disabledrepl-disable-tcp-nodelay noreplica-priority 100acllog-max-len 128requirepass &quot;jgDWw**RxRG&amp;%#J3&quot;lazyfree-lazy-eviction nolazyfree-lazy-expire nolazyfree-lazy-server-del noreplica-lazy-flush nolazyfree-lazy-user-del nolazyfree-lazy-user-flush nooom-score-adj nooom-score-adj-values 0 200 800disable-thp yesappendonly noappendfilename &quot;appendonly.aof&quot;appendfsync everysecno-appendfsync-on-rewrite noauto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mbaof-load-truncated yesaof-use-rdb-preamble yeslua-time-limit 5000slowlog-log-slower-than 10000slowlog-max-len 128latency-monitor-threshold 0notify-keyspace-events &quot;&quot;hash-max-ziplist-entries 512hash-max-ziplist-value 64list-max-ziplist-size -2list-compress-depth 0set-max-intset-entries 512zset-max-ziplist-entries 128zset-max-ziplist-value 64hll-sparse-max-bytes 3000stream-node-max-bytes 4096stream-node-max-entries 100activerehashing yesclient-output-buffer-limit normal 0 0 0client-output-buffer-limit replica 256mb 64mb 60client-output-buffer-limit pubsub 32mb 8mb 60hz 10dynamic-hz yesaof-rewrite-incremental-fsync yesrdb-save-incremental-fsync yesjemalloc-bg-thread yes 配置开机启动新建或编辑一个启动配置文件：vim /lib/systemd/system/redis.service文件内容如下： 123456789101112[Unit]Description=RedisAfter=network.target[Service]Type=forkingPIDFile=/var/run/redis_6379.pidExecStart=/usr/local/redis/bin/redis-server /usr/local/redis/conf/redis.confExecReload=/bin/kill -s HUP $MAINPIDExecStop=/bin/kill -s QUIT $MAINPIDPrivateTmp=true[Install]WantedBy=multi-user.target 然后执行： 1234systemctl daemon-reloadsystemctl enable redissystemctl start redissystemctl status redis 测试验证下面列一下我用来验证redis的命令, 供参考： 12345678910111213141516171819# 打开命令行客户端cd /usr/local/redisbin/redis-cli# 输入密码完成认证auth &quot;密码&quot;# 选择db 0select 0# 设置键值对 a:10set a 10# 获取所有keykeys *# 获取a的值get a# 删除键值对adel a# 获取所有keykeys *# 退出客户端quit","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://example.com/tags/Linux/"},{"name":"redis","slug":"redis","permalink":"http://example.com/tags/redis/"}]},{"title":"给麒麟V10配置本地离线yum源","slug":"configure-local-yum-repository-for-kylin-V10","date":"2024-02-07T00:29:21.000Z","updated":"2024-02-07T05:41:19.755Z","comments":true,"path":"2024/02/07/configure-local-yum-repository-for-kylin-V10/","link":"","permalink":"http://example.com/2024/02/07/configure-local-yum-repository-for-kylin-V10/","excerpt":"","text":"我拿到的机器是一台Linux内网机，操作系统是麒麟V10, 由于需要自己在无网环境下安装一些软件，这些软件都或多或少依赖一些系统基础包，因此需要配置本地yum源。记录配置过程如下： 获取系统ios镜像文件这个需要自行获取。 挂载ios镜像我是让同事帮忙挂载的，大体步骤如下 12345678# 先挂载ios文件mount /root/upload/Kylin-Server-10-SP2-aarch64-Release-Build09-20210524.iso /run/media/root/Kylin-Server-10# 再挂载cdrom设备mount /dev/sr0 /run/media/root/Kylin-Server-10# 查看挂载点df -h# 可以像普通目录一样查看ios文件内容ls /run/media/root/Kylin-Server-10 备份yum源123cd /etc/yum.repo.d/mkdir backupmv *.repo backup 配置本地源创建xxx.repo文件并设置内容： 12345678910cat &gt; /etc/yum.repos.d/local.repo &lt;&lt; EOF ###Kylin Linux Advanced Server 10 - os repo###[ks10-adv-os]name = Kylin Linux Advanced Server 10 - Osbaseurl = file:///run/media/root/Kylin-Server-10gpgcheck = 1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-kylinenabled = 1EOF 更新yum源： 123yum clean allyum makecacheyum list 完毕！","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://example.com/tags/Linux/"},{"name":"yum","slug":"yum","permalink":"http://example.com/tags/yum/"}]},{"title":"maven常用命令整理","slug":"maven-common-commands","date":"2024-01-29T04:52:09.000Z","updated":"2024-01-29T05:25:22.261Z","comments":true,"path":"2024/01/29/maven-common-commands/","link":"","permalink":"http://example.com/2024/01/29/maven-common-commands/","excerpt":"","text":"记录一下maven常用命令，免得需要时到处乱找。 123456789101112131415161718192021222324mvn -v //查看版本mvn archetype:create //创建 Maven 项目mvn compile //编译源代码mvn test-compile //编译测试代码mvn test //运行应用程序中的单元测试mvn site //生成项目相关信息的网站mvn package //依据项目生成 jar 文件mvn install //在本地 Repository 中安装 jarmvn -Dmaven.test.skip=true //忽略测试文档编译mvn clean //清除目标目录中的生成结果mvn clean compile //将.java类编译为.class文件mvn clean package //进行打包mvn clean test //执行单元测试mvn clean deploy //部署到版本仓库mvn clean install //使其他项目使用这个jar,会安装到maven本地仓库中mvn archetype:generate //创建项目架构mvn dependency:list //查看已解析依赖mvn dependency:tree //看到依赖树mvn dependency:analyze //查看依赖的工具mvn help:system //从中央仓库下载文件至本地仓库mvn help:active-profiles //查看当前激活的profilesmvn help:all-profiles //查看所有profilesmvn help:effective -pom //查看完整的pom信息","categories":[],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"}]},{"title":"如何查看Linux系统版本","slug":"how-to-find-linux-release-version","date":"2023-12-14T02:54:32.000Z","updated":"2023-12-14T03:03:23.140Z","comments":true,"path":"2023/12/14/how-to-find-linux-release-version/","link":"","permalink":"http://example.com/2023/12/14/how-to-find-linux-release-version/","excerpt":"","text":"最近老是碰到需要确认linux发行版本的需求，自己记不住，每次都去查bing，查烦了。特意搜集整理、记录一下。总的来说，以下这么几种方法搭配使用，效果更佳。 cat /etc/*-release – 感觉这个最靠谱，红帽的、ubuntu的甚至国产的发行版，一般能查出来。 cat /etc/issue – 有时候啥有用信息也没有，查了个寂寞。 lsb_release – 不少发行版不支持，聊胜于无吧。 uname -a – 能看到一些信息吧，比如是 x86_64 架构的，甚至发行版名称也有。 cat /proc/version – 感觉跟uname差不多。 dmesg | grep &quot;Linux&quot; – 难记，不常用","categories":[],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"http://example.com/tags/DevOps/"},{"name":"Linux","slug":"Linux","permalink":"http://example.com/tags/Linux/"}]},{"title":"pandas DataFrame替换指定列的nan","slug":"how-to-replace-nan-in-dataframe","date":"2023-12-04T01:15:32.000Z","updated":"2023-12-04T02:02:50.322Z","comments":true,"path":"2023/12/04/how-to-replace-nan-in-dataframe/","link":"","permalink":"http://example.com/2023/12/04/how-to-replace-nan-in-dataframe/","excerpt":"","text":"平时习惯针对整个DataFrame把nan替换成0，用df.fillna(0, inplace=True)就OK了。今天突然有人问，如何只替换某一列的nan。测试并记录如下。构建测试DataFrame，由3列组成 name、age、score, 后两列都有nan值。接下来测试如何只处理age列。 1234df = pd.DataFrame(&#123;&#x27;name&#x27;:[&#x27;aby&#x27;,&#x27;boy&#x27;,&#x27;cilia&#x27;],&#x27;age&#x27;:[18,np.nan,20],&#x27;score&#x27;:[9.5,8.0,np.nan]&#125;)print(df)df[&#x27;age&#x27;].fillna(0, inplace=True)print(df) 处理前，DataFrame如下： 1234 name age score0 aby 18.0 9.51 boy NaN 8.02 cilia 20.0 NaN 处理后，DataFrame如下： 1234 name age score0 aby 18.0 9.51 boy 0.0 8.02 cilia 20.0 NaN 以上示例代码表明，可直接用fillna()方法针对某一列DataSeries做替换，参数同DataFrame一样。","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"},{"name":"数据分析","slug":"数据分析","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"}]},{"title":"常用的PostgreSQL窗口函数的案例学习","slug":"usecases-of-postgresql-window-functions","date":"2023-11-30T01:21:29.000Z","updated":"2023-12-02T10:24:08.944Z","comments":true,"path":"2023/11/30/usecases-of-postgresql-window-functions/","link":"","permalink":"http://example.com/2023/11/30/usecases-of-postgresql-window-functions/","excerpt":"","text":"窗口函数简介窗口函数主要是用来对表的数值字段做统计分析的。既然是统计分析就必然涉及到多条记录。窗口函数一般配合avg、max等聚合函数一起使用，通过跨越多行记录的统计数据来影响当前行。它们跟普通聚合函数最大的不同在于它们不改变结果集记录行数。窗口函数的调用语法类似： 1function_name(expression) over(window_name) function_name可以为max,min,avg,sum,count等普通聚合函数，也可以为rank,dense_rank等排名函数。 over子句确定了窗口划分方法，也就是我们通常意义上说的分组,类似group by。 窗口函数注意事项执行顺序窗口函数在GROUP BY、HAVING、WHERE子句以及聚合函数之后、排序子句之前执行。因此只允许出现在查询的SELECT和ORDER BY子句中。 窗口函数案例学习下面用一些实际的使用场景来说明窗口函数的作用。 数据准备先准备一些测试数据： 12345678910111213141516171819202122-- postgresql创建自增序列和表结构CREATE SEQUENCE employee_empno_seq START 1;CREATE TABLE employee_tbl ( empno int4 NOT NULL DEFAULT nextval(&#x27;employee_empno_seq&#x27;::regclass), empname varchar(100) COLLATE &quot;pg_catalog&quot;.&quot;default&quot;, deptname varchar(100) COLLATE &quot;pg_catalog&quot;.&quot;default&quot;, salary int4, PRIMARY KEY (&quot;empno&quot;));-- 准备测试数据INSERT INTO employee_tbl(empno,deptname,empname,salary) VALUES(1,&#x27;sales&#x27;,&#x27;s1&#x27;,5000),(2,&#x27;personnel&#x27;,&#x27;p1&#x27;,3900),(3,&#x27;sales&#x27;,&#x27;s2&#x27;,4800),(4,&#x27;sales&#x27;,&#x27;s3&#x27;,5000),(5,&#x27;personnel&#x27;,&#x27;p2&#x27;,3500),(6,&#x27;personnel&#x27;,&#x27;p3&#x27;,4100),(7,&#x27;develop&#x27;,&#x27;d1&#x27;,4200),(8,&#x27;develop&#x27;,&#x27;d2&#x27;,6000),(9,&#x27;develop&#x27;,&#x27;d3&#x27;,4500),(10,&#x27;develop&#x27;,&#x27;d4&#x27;,5200),(11,&#x27;develop&#x27;,&#x27;d5&#x27;,5200); 准备好的表数据如下： 1234567891011121314 empno | empname | deptname | salary-------+---------+-----------+-------- 1 | s1 | sales | 5000 2 | p1 | personnel | 3900 3 | s2 | sales | 4800 4 | s3 | sales | 5000 5 | p2 | personnel | 3500 6 | p3 | personnel | 4100 7 | d1 | develop | 4200 8 | d2 | develop | 6000 9 | d3 | develop | 4500 10 | d4 | develop | 5200 11 | d5 | develop | 5200(11 rows) 统计员工工资和所在部门平均工资的差异百分比使用窗口函数计算各部门平均工资： 123SELECT empno,empname,deptname,salary,(avg(salary) over(partition by deptname)) as avg_salaryFROM employee_tblorder by empno asc; 结果如下： 1234567891011121314 empno | empname | deptname | salary | avg_salary-------+---------+-----------+--------+----------------------- 1 | s1 | sales | 5000 | 4933.3333333333333333 2 | p1 | personnel | 3900 | 3833.3333333333333333 3 | s2 | sales | 4800 | 4933.3333333333333333 4 | s3 | sales | 5000 | 4933.3333333333333333 5 | p2 | personnel | 3500 | 3833.3333333333333333 6 | p3 | personnel | 4100 | 3833.3333333333333333 7 | d1 | develop | 4200 | 5020.0000000000000000 8 | d2 | develop | 6000 | 5020.0000000000000000 9 | d3 | develop | 4500 | 5020.0000000000000000 10 | d4 | develop | 5200 | 5020.0000000000000000 11 | d5 | develop | 5200 | 5020.0000000000000000(11 rows) 对上述sql美化一下,把平均工资取整，再加上员工工资跟部门平均工资的差异比例（这里暂不考虑性能调优啥的）： 123SELECT empno,empname,deptname,salary,(round(avg(salary) over(partition by deptname))) as avg_salary, round(((salary/(avg(salary) over(partition by deptname)))-1), 2) as diff_ratio FROM employee_tblorder by empno asc; 最终得到结果如下： 1234567891011121314 empno | empname | deptname | salary | avg_salary | diff_ratio-------+---------+-----------+--------+------------+------------ 1 | s1 | sales | 5000 | 4933 | 0.01 2 | p1 | personnel | 3900 | 3833 | 0.02 3 | s2 | sales | 4800 | 4933 | -0.03 4 | s3 | sales | 5000 | 4933 | 0.01 5 | p2 | personnel | 3500 | 3833 | -0.09 6 | p3 | personnel | 4100 | 3833 | 0.07 7 | d1 | develop | 4200 | 5020 | -0.16 8 | d2 | develop | 6000 | 5020 | 0.20 9 | d3 | develop | 4500 | 5020 | -0.10 10 | d4 | develop | 5200 | 5020 | 0.04 11 | d5 | develop | 5200 | 5020 | 0.04(11 rows) 这样我们就能很直观的看到部门内每个员工工资相对平均工资的偏离情况了。如果窗口函数的over子句括号内容为空，则表示把所有结果集作为一个分组来处理。例如，以下SQL可以在员工工资记录后追加一列“公司平均工资”： 123SELECT empno,empname,deptname,salary,round(avg(salary) over()) as avg_salaryFROM employee_tblorder by empno asc; 得到结果如下： 1234567891011121314 empno | empname | deptname | salary | avg_salary-------+---------+-----------+--------+------------ 1 | s1 | sales | 5000 | 4673 2 | p1 | personnel | 3900 | 4673 3 | s2 | sales | 4800 | 4673 4 | s3 | sales | 5000 | 4673 5 | p2 | personnel | 3500 | 4673 6 | p3 | personnel | 4100 | 4673 7 | d1 | develop | 4200 | 4673 8 | d2 | develop | 6000 | 4673 9 | d3 | develop | 4500 | 4673 10 | d4 | develop | 5200 | 4673 11 | d5 | develop | 5200 | 4673(11 rows) 按员工工资由高到低排名先在全公司排名： 1select empno, empname, deptname, salary, rank() over(order by salary desc) from employee_tbl; 得到结果如下： 1234567891011121314 empno | empname | deptname | salary | rank-------+---------+-----------+--------+------ 8 | d2 | develop | 6000 | 1 11 | d5 | develop | 5200 | 2 10 | d4 | develop | 5200 | 2 1 | s1 | sales | 5000 | 4 4 | s3 | sales | 5000 | 4 3 | s2 | sales | 4800 | 6 9 | d3 | develop | 4500 | 7 7 | d1 | develop | 4200 | 8 6 | p3 | personnel | 4100 | 9 2 | p1 | personnel | 3900 | 10 5 | p2 | personnel | 3500 | 11(11 rows) 接着在各自部门内排名： 1select empno, empname, deptname, salary, rank() over(partition by deptname order by salary desc) from employee_tbl; 得到结果如下： 1234567891011121314 empno | empname | deptname | salary | rank-------+---------+-----------+--------+------ 8 | d2 | develop | 6000 | 1 11 | d5 | develop | 5200 | 2 10 | d4 | develop | 5200 | 2 9 | d3 | develop | 4500 | 4 7 | d1 | develop | 4200 | 5 6 | p3 | personnel | 4100 | 1 2 | p1 | personnel | 3900 | 2 5 | p2 | personnel | 3500 | 3 1 | s1 | sales | 5000 | 1 4 | s3 | sales | 5000 | 1 3 | s2 | sales | 4800 | 3(11 rows) 观察上述两个案例中的rank()得到的排名，如果有并列第N名，则排名序号会不连续。比如上面示例，并列第2名后直接跳到了第4名，没有第3名。如果想要名次编号连续，可以换成dense_rank()： 1select empno,empname,deptname,salary,dense_rank() over(order by salary desc) from employee_tbl; 得到结果如下： 1234567891011121314 empno | empname | deptname | salary | dense_rank-------+---------+-----------+--------+------------ 8 | d2 | develop | 6000 | 1 11 | d5 | develop | 5200 | 2 10 | d4 | develop | 5200 | 2 1 | s1 | sales | 5000 | 3 4 | s3 | sales | 5000 | 3 3 | s2 | sales | 4800 | 4 9 | d3 | develop | 4500 | 5 7 | d1 | develop | 4200 | 6 6 | p3 | personnel | 4100 | 7 2 | p1 | personnel | 3900 | 8 5 | p2 | personnel | 3500 | 9(11 rows) 可见，使用dense_rank()后，并列第2名之后就是并列第3名。 在员工工资记录后展示各部门工资总额列直接使用sum()聚合函数对应的窗口函数： 1select empno,empname,deptname,salary,(sum(salary) over(partition by deptname)) as dept_total_salary from employee_tbl order by empno asc; 结果如下： 1234567891011121314 empno | empname | deptname | salary | dept_total_salary-------+---------+-----------+--------+------------------- 1 | s1 | sales | 5000 | 14800 2 | p1 | personnel | 3900 | 11500 3 | s2 | sales | 4800 | 14800 4 | s3 | sales | 5000 | 14800 5 | p2 | personnel | 3500 | 11500 6 | p3 | personnel | 4100 | 11500 7 | d1 | develop | 4200 | 25100 8 | d2 | develop | 6000 | 25100 9 | d3 | develop | 4500 | 25100 10 | d4 | develop | 5200 | 25100 11 | d5 | develop | 5200 | 25100(11 rows) 在员工工资记录后展示各部门截止当前员工记录行累加得到的工资总额列直接使用sum()聚合函数对应的窗口函数, 注意over子句要使用order by： 1select empno,empname,deptname,salary,(sum(salary) over(partition by deptname order by empno asc)) as dept_total_salary from employee_tbl order by deptname asc, empno asc; 结果如下： 1234567891011121314 empno | empname | deptname | salary | dept_total_salary-------+---------+-----------+--------+------------------- 7 | d1 | develop | 4200 | 4200 8 | d2 | develop | 6000 | 10200 9 | d3 | develop | 4500 | 14700 10 | d4 | develop | 5200 | 19900 11 | d5 | develop | 5200 | 25100 2 | p1 | personnel | 3900 | 3900 5 | p2 | personnel | 3500 | 7400 6 | p3 | personnel | 4100 | 11500 1 | s1 | sales | 5000 | 5000 3 | s2 | sales | 4800 | 9800 4 | s3 | sales | 5000 | 14800(11 rows) 这里需要特别注意一下，dept_total_salary是首先按部门分组，再对部门内员工记录按empno升序排序，然后累加计算组内(本例中即部门内)第一条记录到当前记录的工资得到的。 获取工资前3高的员工需要先用窗口函数对员工按工资排序，然后排序号&lt;4的几条记录。 123select * from ( select empno,empname,deptname,salary,(rank() over(order by salary desc)) as pos from employee_tbl) as a where a.pos &lt; 4; 也可以根据需要取前3条记录: 123select * from ( select empno,empname,deptname,salary,(rank() over(order by salary desc)) as pos from employee_tbl) as a limit 3; 或： 1select empno,empname,deptname,salary,(rank() over(order by salary desc)) as pos from employee_tbl limit 3; 在员工工资记录后展示所在部门截止当前员工记录的工资总额和平均工资这里需要两个窗口函数，可以复用partition by xxx order by yyy部分： 12select empno,empname,deptname,(sum(salary) over w) as dept_total_salary, round(avg(salary) over w) as avg_salary FROM employee_tbl WINDOW w as(partition by deptname order by salary asc); 结果如下： 1234567891011121314 empno | empname | deptname | dept_total_salary | avg_salary-------+---------+-----------+-------------------+------------ 7 | d1 | develop | 4200 | 4200 9 | d3 | develop | 8700 | 4350 10 | d4 | develop | 19100 | 4775 11 | d5 | develop | 19100 | 4775 8 | d2 | develop | 25100 | 5020 5 | p2 | personnel | 3500 | 3500 2 | p1 | personnel | 7400 | 3700 6 | p3 | personnel | 11500 | 3833 3 | s2 | sales | 4800 | 4800 1 | s1 | sales | 14800 | 4933 4 | s3 | sales | 14800 | 4933(11 rows) 吐槽一下，感觉这个需求好没意义，纯粹为了炫技。同样的，开头计算部门平均工资以及员工工资和部门平均工资偏差比例的sql也可以稍微简化一下： 1234SELECT empno,empname,deptname,salary,round(avg(salary) over w) as avg_salary, round(salary/(avg(salary) over w)-1, 2) as diff_ratio FROM employee_tblWINDOW w as (partition by deptname)order by empno asc; 执行结果跟原始语句相同： 1234567891011121314 empno | empname | deptname | salary | avg_salary | diff_ratio-------+---------+-----------+--------+------------+------------ 1 | s1 | sales | 5000 | 4933 | 0.01 2 | p1 | personnel | 3900 | 3833 | 0.02 3 | s2 | sales | 4800 | 4933 | -0.03 4 | s3 | sales | 5000 | 4933 | 0.01 5 | p2 | personnel | 3500 | 3833 | -0.09 6 | p3 | personnel | 4100 | 3833 | 0.07 7 | d1 | develop | 4200 | 5020 | -0.16 8 | d2 | develop | 6000 | 5020 | 0.20 9 | d3 | develop | 4500 | 5020 | -0.10 10 | d4 | develop | 5200 | 5020 | 0.04 11 | d5 | develop | 5200 | 5020 | 0.04(11 rows)","categories":[],"tags":[{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"http://example.com/tags/PostgreSQL/"},{"name":"Database","slug":"Database","permalink":"http://example.com/tags/Database/"}]},{"title":"个人最常用的PostgreSQL命令整理","slug":"most-useful-postgresql-commands","date":"2023-11-29T02:10:29.000Z","updated":"2023-12-02T10:23:42.626Z","comments":true,"path":"2023/11/29/most-useful-postgresql-commands/","link":"","permalink":"http://example.com/2023/11/29/most-useful-postgresql-commands/","excerpt":"","text":"psql命令列出所有数据库: 1psql -l 进入指定数据库： 1psql -d my_db_name 带用户名密码进入指定数据库: 1psql -h your_host_name_or_ip -p your_port -U username -W 执行sql文件： 1psql -d my_db_name -f a.sql 通过一条终端指令执行简单操作： 1psql -d my_db_name -c &quot;\\dt&quot; 上述指令可替代如下三条指令构成的操作序列： 123psql -d my_db_name\\dt\\q 单步执行SQL指令，每一步都要敲回车确认: 1psql -s 查看版本号： 1psql -V 数据库信息查看查看有哪些用户: 1\\du 切换数据库: 1\\c my_db_name 查看有哪些数据库： 1\\l 查看当前数据库下有哪些表: 1\\dt 查看某个表的信息: 1\\d my_table_name 查看有哪些索引: 1\\di 查看有哪些表空间： 1\\db 退出psql： 1\\q 执行外部SQL文件: 1\\i a.sql 把后续执行结果写入外部文件,直到退出psql: 1\\o output_file.txt 查看可用指令列表： 1\\? 查看某个命令的语法帮助: 1\\h create table 数据库使用状态查看查看数据库占用空间大小: 1select pg_database_size(&#x27;my_test_db&#x27;); 查看所有数据库占用空间的大小: 1select datname, pg_database_size(datname) AS size from pg_database; 查看所有数据库占用空间大小，并以KB、MB等可读方式显示: 1select datname, pg_size_pretty(pg_database_size(datname)) as size from pg_database; 查看表或索引大小: 1select pg_relation_size(&#x27;my_table_or_index_name&#x27;); 查看表的总大小，包括索引: 1select pg_size_pretty(pg_total_relation_size(my_table)); 查看表空间大小: 1select pg_size_pretty(pg_tablespace_size(&#x27;pg_default&#x27;)); 数据库、用户设置创建用户: 1create user my_test_user with password &#x27;my_password&#x27;; 创建数据库: 1create database my_test_db; 把数据库分配给用户: 1alter database my_test_db owner my_test_user; 直接创建用户并设置属主： 1create database my_test_db_2 owner my_test_user; 别忘了把权限赋予用户: 1grant all privileges on database my_test_db to my_test_user; 如果用新创建的数据库用户登录报以下错误：psql: error: connection to server on socket &quot;/var/run/postgresql/.s.PGSQL.5432&quot; failed: FATAL: Peer authentication failed for user &quot;my_test_user&quot;这是因为，该机器上psql的连接建立于Unix Socket上默认使用peer authentication，必须要用和数据库用户相同的系统用户进行登录。解决办法也简单，要么创建对应的操作系统用户my_test_user后sudo su - my_test_user再用psql -d my_test_db登录，要么把登录认证方式从peer authentiction改为md5。 如果要收回权限，使用下面语句: 1revoke all on database my_test_db from my_test_user; 删除数据库用户，使用下面语句： 1drop user my_test_user;","categories":[],"tags":[{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"http://example.com/tags/PostgreSQL/"},{"name":"Database","slug":"Database","permalink":"http://example.com/tags/Database/"}]},{"title":"如何用系统命令把文件内容复制到剪贴板","slug":"how-to-copy-file-content-to-clipboard","date":"2023-11-20T04:15:32.000Z","updated":"2023-11-20T03:11:55.399Z","comments":true,"path":"2023/11/20/how-to-copy-file-content-to-clipboard/","link":"","permalink":"http://example.com/2023/11/20/how-to-copy-file-content-to-clipboard/","excerpt":"","text":"换电脑后需要给github配置新的ssh key以便于通过ssh协议免密push代码。使用ssh-keygen -t rsa -C &quot;xx@xx.com&quot; 在本机生成ssh密钥对后，需要把~/.id_rsa.pub公钥文件的内容复制出来，再粘贴到github账号里。通常做法是用诸如记事本、notpad++等文本编辑软件直接打开id_rsa.pub文件，然后Ctrl+A、Ctrl+C复制到系统剪贴板即可。不过为了显得有技术范(装逼)，想试试直接用命令行执行这一动作。一时记不起来windows下如何用命令行复制文件内容了，查了些资料，整理如下。 Windows PowerShell对于PowerShell, 直接使用如下命令： 1cat id_rsa.pub | clip Windows CommandLine对于传统的cmd命令行，直接使用如下命令： 1clip &lt; id_rsa.pub Linux Shell对于Linux系统来说，反倒比较麻烦一点点，需要先安装外部小工具，xsel、xclip, 使用yum或apt-get安装都可以。如果是xclip，直接用 1cat id_rsa.pub | xclip 如果是xsel, 使用 1cat id_rsa.pub | xsel 内容将复制到系统剪贴板。注意，一般云厂商提供的服务器没有配置输入输出设备，这俩命令都无效。","categories":[],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"http://example.com/tags/DevOps/"}]},{"title":"pandas中如何合并DataFrame的两列","slug":"how-to-merge-two-dataframe-columns-with-pandas","date":"2023-11-20T04:15:32.000Z","updated":"2023-12-01T02:35:17.631Z","comments":true,"path":"2023/11/20/how-to-merge-two-dataframe-columns-with-pandas/","link":"","permalink":"http://example.com/2023/11/20/how-to-merge-two-dataframe-columns-with-pandas/","excerpt":"","text":"如下DataFrame, 一列日期，一列时间，现需要把日期和时间合并为一列。 1df = pd.DataFrame([[&#x27;2023-01-05&#x27;,&#x27;0930&#x27;,100],[&#x27;2023-01-05&#x27;,&#x27;0935&#x27;,200],[&#x27;2023-01-05&#x27;,&#x27;0940&#x27;,333]],columns=[&#x27;日期&#x27;,&#x27;时间&#x27;,&#x27;数量&#x27;]) 1234 日期 时间 数量0 2023-01-05 0930 1001 2023-01-05 0935 2002 2023-01-05 0940 333 最简单的做法是直接两列按字符串拼接： 1df[&#x27;日期时间1&#x27;] = df[&#x27;日期&#x27;] + &#x27; &#x27; + df[&#x27;时间&#x27;] 如果要合并的列不是字符串，则需显式转化一下再合并： 1df[&#x27;日期时间2&#x27;] = df[&#x27;日期&#x27;].astype(str) + &#x27; &#x27; + df[&#x27;时间&#x27;].astype(str) 还可以这样： 1df[&#x27;日期时间3&#x27;] = df[[&#x27;日期&#x27;,&#x27;时间&#x27;]].apply(lambda x: &#x27; &#x27;.join(x), axis=1) 或者： 1df[&#x27;日期时间4&#x27;] = df.apply(lambda x: x[&#x27;日期&#x27;] + &#x27; &#x27; + x[&#x27;时间&#x27;], axis=1) 如果要合并的列中有nan,则可以使用这个： 1df[&#x27;日期时间5&#x27;] = df[&#x27;日期&#x27;].str.cat(df[&#x27;时间&#x27;], sep=&#x27; &#x27;, na_rep=&#x27;?&#x27;) 最后效果如下: 12345&gt;&gt;&gt; df 日期 时间 数量 日期时间1 日期时间2 日期时间3 日期时间4 日期时间50 2023-01-05 0930 100 2023-01-05 0930 2023-01-05 0930 2023-01-05 0930 2023-01-05 0930 2023-01-05 09301 2023-01-05 0935 200 2023-01-05 0935 2023-01-05 0935 2023-01-05 0935 2023-01-05 0935 2023-01-05 09352 2023-01-05 0940 333 2023-01-05 0940 2023-01-05 0940 2023-01-05 0940 2023-01-05 0940 2023-01-05 0940 完毕！","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"},{"name":"数据分析","slug":"数据分析","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"}]},{"title":"pandas中如何合并DataFrame多行记录","slug":"how-to-reduce-dataframe-columns-with-pandas","date":"2023-11-20T04:15:32.000Z","updated":"2023-11-20T07:05:40.262Z","comments":true,"path":"2023/11/20/how-to-reduce-dataframe-columns-with-pandas/","link":"","permalink":"http://example.com/2023/11/20/how-to-reduce-dataframe-columns-with-pandas/","excerpt":"","text":"如下DataFrame, 有三个列site、material、LT，现需要根据material把site去重后合并，并取出LT最大值。 1234567df = pd.DataFrame([[&#x27;FJZ&#x27;,&#x27;A123&#x27;,123], [&#x27;FOC&#x27;,&#x27;A123&#x27;,456], [&#x27;FJZ&#x27;,&#x27;B456&#x27;,112], [&#x27;FJZ&#x27;,&#x27;B456&#x27;,245], [&#x27;FJZ&#x27;,&#x27;B456&#x27;,110], [&#x27;FOC&#x27;,&#x27;C789&#x27;,202], [&#x27;FOC&#x27;,&#x27;C789&#x27;,205]],columns=[&#x27;site&#x27;,&#x27;material&#x27;,&#x27;LT&#x27;]) 原始DataFrame数据如下： 12345678 site material LT0 FJZ A123 1231 FOC A123 4562 FJZ B456 1123 FJZ B456 2454 FJZ B456 1105 FOC C789 2026 FOC C789 205 直接groupby后join: 1df.groupby(&#x27;material&#x27;).agg(&#123;&#x27;site&#x27;: &#x27;,&#x27;.join, &#x27;LT&#x27;: max&#125;).reset_index() 处理后数据如下： 1234 material site LT0 A123 FJZ,FOC 4561 B456 FJZ,FJZ,FJZ 2452 C789 FOC,FOC 205 第二行数据中，site列的FJZ出现了重复。这里我们换一种思路，由于site列涉及去重、拼接两个步骤，可以先定义一个处理函数，把这两个步骤串起来。 12def agg_func(items): return &#x27;,&#x27;.join(set(items)) 然后再调用这个函数： 1df.groupby(&#x27;material&#x27;).agg(&#123;&#x27;site&#x27;: agg_func, &#x27;LT&#x27;: max&#125;).reset_index() 最后效果如下: 1234 material site LT0 A123 FJZ,FOC 4561 B456 FJZ 2452 C789 FOC 205 完毕！","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"},{"name":"数据分析","slug":"数据分析","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"}]},{"title":"我是如何一步步配置nodejs的","slug":"log-my-nodejs-config-step-by-step","date":"2023-11-20T04:15:32.000Z","updated":"2023-11-20T06:07:20.789Z","comments":true,"path":"2023/11/20/log-my-nodejs-config-step-by-step/","link":"","permalink":"http://example.com/2023/11/20/log-my-nodejs-config-step-by-step/","excerpt":"","text":"需要在新电脑安装node.js环境，记录步骤如下。 下载安装NodeJsnode.js版本更新较频繁，上一次安装我用的还是10.x, 现在已经17.x了。由于之前遇到过安装太高版本的node.js后装不上node-sass的问题，这次特意先查询了一下网上资料，发现16.x系列有对应的成功案例，所以选了16系列。先从官网下载了node.js16系列目前最新版本V16.20.2的msi安装包，双击安装包一路next安装即可。安装完后，打开新的cmd窗口，运行node -v和npm -v命令检查一下是否成功。我得到的命令行反馈版本号分别是v16.20.2和8.19.4。 配置npm缓存目录到非系统盘血泪教训，之前没在意npm缓存目录，所有包文件都默认装到的C盘，导致后来我C盘空间极度紧张。而且npm的包大部分都是一堆小文件，删起来特别费时间。这次特意解决这个问题。 12npm config set prefix &quot;D:\\Tools\\AppData\\nodejs\\node_global&quot;npm config set cache &quot;D:\\Tools\\AppData\\nodejs\\node_cache&quot; 然后配置系统环境变量，在用户变量Path中增加路径：D:\\Tools\\AppData\\nodejs\\node_global，在系统变量中新增NODE_PATH指向D:\\Tools\\AppData\\nodejs\\node_global\\node_modules。这里主要是为了解决之后npm install -g xxx找不到命令的问题。 配置npm镜像加速受够了外网蜗牛般的速度，果断换成国内镜像： 12npm config set registry https://registry.npm.taobao.org 关闭strict-ssl模式解决报错Warning: Setting the NODE_TLS_REJECT_UNAUTHORIZED environment variable to &#39;0&#39; makes TLS connections and HTTPS requests insecure by disabling certificate verification. 1npm config set strict-ssl false 安装node-sass首先设置国内镜像地址： 1npm config set sass_binary_site=https://npm.taobao.org/mirrors/node-sass/ 然后执行： 12npm install node-sass@6.0.1 -gnpm install sass-loader@10.2.0 -g 可选安装 hexo、vue等12npm install hexo-cli -gnpm install -g @vue/cli 完毕！","categories":[],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"http://example.com/tags/DevOps/"}]},{"title":"在阿里云OS里安装nodejs","slug":"install-nodejs-for-aliyunos","date":"2022-07-26T01:38:21.000Z","updated":"2022-07-26T10:29:52.000Z","comments":true,"path":"2022/07/26/install-nodejs-for-aliyunos/","link":"","permalink":"http://example.com/2022/07/26/install-nodejs-for-aliyunos/","excerpt":"","text":"安装Node环境安装方式分两种: 一种是nvm安装多版本, 一种是使用二进制文件安装. 这里采用nvm方式安装.步骤如下: 首先, 使用git拉取nvm代码: 1git clone https://github.com/cnpm/nvm.git ~/.nvm &amp;&amp; cd ~/.nvm &amp;&amp; git checkout `git describe --abbrev=0 --tags` 然后, 激活nvm: 12echo &quot;. ~/.nvm/nvm.sh&quot; &gt;&gt; /etc/profilesource /etc/profile 激活后即可ls出所支持的node版本: 1nvm list-remote 选择一个版本号执行安装, 安装命令如下: 1nvm install v14.20.0 检查已安装版本: 1nvm ls 切换到目标版本: 1nvm use v14.20.0 查看当前node版本: 1node -v 退出后找不到 node 及 npm 命令问题退出云服务器再次登录后, 执行node -v, 会报错: node: command not found.这时, 需要先nvm use v14.20.0一下, 然后查找一下node可执行文件路径: 1whereis node 比如我的路径是: /root/.nvm/versions/node/v14.20.0/bin/node,这里可以建立一个指向node可执行文件路径的软链接: 1ln -s /root/.nvm/versions/node/v14.20.0/bin/node /usr/local/bin/node 这样就可以在重新登录后继续使用node命令了. nvm命令也需要按上述步骤处理一下. 小尾巴显然, 这种处理方式不完美, 每次切换到不同node版本后, 需要重新建一遍软链接, 指向当前node版本.","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://example.com/tags/Linux/"},{"name":"node.js","slug":"node-js","permalink":"http://example.com/tags/node-js/"}]},{"title":"简单三步实现ssh免密登录","slug":"ssh-auto-login-no-password","date":"2022-07-15T01:38:21.000Z","updated":"2022-07-15T02:04:08.000Z","comments":true,"path":"2022/07/15/ssh-auto-login-no-password/","link":"","permalink":"http://example.com/2022/07/15/ssh-auto-login-no-password/","excerpt":"","text":"简单三步实现ssh免密登录假设我们有两台Linux服务器A(172.22.170.149), B(172.22.170.148), 现在要配置A免密登录B. 操作步骤如下: 先人工登录一次1ssh root@172.22.170.148 第一次登录时, 会提示是否把对方机器加入当前机器的已知host列表里(类似白名单). 123The authenticity of host &#x27;172.22.170.148 (172.22.170.148)&#x27; can&#x27;t be established.ECDSA key fingerprint is SHA256:78SJbYxxxxxxxxxxxxxxxxxxxxxxxxwvB2F3up7VI.Are you sure you want to continue connecting (yes/no/[fingerprint])? yes 输入yes继续. 12Warning: Permanently added &#x27;172.22.170.148&#x27; (ECDSA) to the list of known hosts.root@172.22.170.148&#x27;s password: 这里输入密码 按提示输入密码即可成功登录服务器B. 出现类似以下提示即表示登录成功(这里是阿里云的ECS服务器). 1234Welcome to Alibaba Cloud Elastic Compute Service !Last login: Fri Jul 15 09:40:47 2022 from 101.206.167.221[root@iZ8vb0nljx0sx0od8wvle6Z ~]# 然后输入exit退出服务器B, 返回服务器A. 1exit 在A服务器生成密钥对1ssh-keygen 出现交互选择信息时, 一路回车即可. 传输A服务的公钥到B服务器1ssh-copy-id 172.22.170.148 这里要再输入一次密码. 才能把公钥传过去. 然后A服务器就可以ssh免密登录B服务器了. 验证一下使用如下命令验证免密登录是否成功: 1ssh root@172.22.170.148 快来动手试试吧!","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://example.com/tags/Linux/"}]},{"title":"SQL基础面试题整理-表结构","slug":"sql-basic-interview-questions-example","date":"2022-06-25T03:49:51.000Z","updated":"2022-06-29T09:55:36.000Z","comments":true,"path":"2022/06/25/sql-basic-interview-questions-example/","link":"","permalink":"http://example.com/2022/06/25/sql-basic-interview-questions-example/","excerpt":"","text":"SQL基础面试题整理表结构 学生表 Student(s_id,s_name,s_birth,s_sex) –学生编号,学生姓名, 出生年月,学生性别 课程表 Course(c_id,c_name,t_id) – –课程编号, 课程名称, 教师编号 教师表 Teacher(t_id,t_name) –教师编号,教师姓名 成绩表 Score(s_id,c_id,s_score) –学生编号,课程编号,分数 例题 查询平均成绩大于60分的学生的学号和平均成绩 查询所有学生的学号、姓名、选课数、总成绩 查询没学过“张三”老师课的学生的学号、姓名 1234select s_id, s_name from student where s_id not in ( select s_id from score a, course b, teacher c where a.c_id = b.c_id and b.t_id = c.t_id and c.t_name = &#x27;张三&#x27;) ​ 4. 其他问题 https://zhuanlan.zhihu.com/p/43289968 1SELECT b.book_main_id, b.name, b.author, b.last_update_time, b.last_update_content from (select author, max(last_update_time) as last_update_time from book_main where author in (&#x27;$authors_str&#x27;) group by author) as a, book_main as b where a.author=b.author and a.last_update_time=b.last_update_time&quot;;","categories":[],"tags":[{"name":"SQL","slug":"SQL","permalink":"http://example.com/tags/SQL/"}]},{"title":"命令行导出MySQL数据库表数据示例","slug":"dump-mysql-database-table","date":"2022-06-22T05:59:10.000Z","updated":"2022-06-22T13:09:32.000Z","comments":true,"path":"2022/06/22/dump-mysql-database-table/","link":"","permalink":"http://example.com/2022/06/22/dump-mysql-database-table/","excerpt":"","text":"命令行导出MySQL数据库表数据示例 导出所有数据库所有表: 1mysqldump -uroot -ppassword --all-databases &gt; ./all_dbs_data.sql 导出db1, db2数据库: 1mysqldump -uroot -ppassword --databases db1 db2 &gt; ./db1_db2_data.sql 导出db1数据库的t1,t2表: 1mysqldump -uroot -ppassword --databases db1 --tables t1 t2 &gt; ./db1_t1_t2_data.sql 导出db1数据库的t1表中id=1的数据: 1mysqldump -uroot -ppassword --databases db1 --tables t1 --where=&#x27;id=1&#x27; &gt; ./t1_w1.sql 只导出表结构, 不含数据: 1mysqldump -uroot -ppassword --no-data --databases db1 --tables t1 &gt; ./t1_structure.sql 导出远程MySQL服务器的数据: 1mysqldump -hhost -Pport -uroot -ppassword --databases db1 &gt; ./remote_db1_data.sql 从host1服务器导出db1.tb1表数据,然后导入到host2服务器的db2.tb1表(会自动建表): 1mysqldump -hhost1 -Pport1 -uroot1 -ppassword1 --databases db1 --tables t1 | mysql -hhost2 -Pport2 -uroot2 -ppassword2 db2","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"},{"name":"example","slug":"example","permalink":"http://example.com/tags/example/"}]},{"title":"身份证号输入框中间用星号显示","slug":"mask-input-field-value-with-star","date":"2020-10-19T08:08:32.000Z","updated":"2023-11-20T02:27:39.772Z","comments":true,"path":"2020/10/19/mask-input-field-value-with-star/","link":"","permalink":"http://example.com/2020/10/19/mask-input-field-value-with-star/","excerpt":"","text":"接到一个需求，有一个输入框，用来显示用户的身份证号。要求显示时只显示身份证号的前4位和后4位，中间用星号代替。支持用户修改身份证号。 实现思路如下： 写两个input输入框，姑且称为input1和input2，input1用来保存正确的身份证号、表单验证、提交都读取input1的值。input2用来显示星号处理过的身份证号，并处理用户按键编辑。 给input2绑定3个事件，keyup、focusin、focusout。focusin时从input1读取正确身份证号填充给input2，keyup时将用户修改后的身份证号写回到input1，focusout时触发input1的表单验证。 具体代码如下：首先，上index.html 1234567891011121314&lt;form id=&quot;dataForm&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p class=&quot;word&quot;&gt;身份证:&lt;/p&gt; &lt;p&gt; &lt;input type=&quot;text&quot; class=&quot;int-text valid&quot; id=&quot;p_legalCertNum&quot; name=&quot;plegalCertNum&quot; value=&quot;&quot; aria-invalid=&quot;false&quot; /&gt; &lt;input type=&quot;text&quot; style=&quot;height: 0.5px;width: 0;padding: 0;margin: 0;&quot; id=&quot;legalCertNum&quot; name=&quot;legalCertNum&quot; value=&quot;511102199010162531&quot; /&gt; &lt;/p&gt; &lt;label id=&quot;legalCertNumError&quot; style=&quot;display: none;&quot;&gt; &lt;span class=&quot;ash&quot; id=&quot;legalCertNumText&quot;&gt;&lt;/span&gt; &lt;/label&gt; &lt;/li&gt; &lt;/ul&gt;&lt;/form&gt; Javascript代码如下： 12345678910111213141516171819202122232425262728293031323334&lt;script src=&quot;js/jquery.min.js&quot;&gt;&lt;/script&gt;&lt;script src=&quot;js/jquery.validate.min.js&quot;&gt;&lt;/script&gt;&lt;script&gt;$(function()&#123; var formValidator=$(&quot;#dataForm&quot;).validate(&#123; rules: &#123; legalCertNum:&#123; required:false, regexp: /(^\\d&#123;15&#125;$)|(^\\d&#123;18&#125;$)|(^\\d&#123;17&#125;(\\d|X|x)$)/, digits:false &#125; &#125;, messages: &#123; legalCertNum:&#123; regexp: &#x27;身份证号格式错误&#x27; &#125; &#125; &#125;); var $realInput = $(&#x27;#legalCertNum&#x27;), $showInput = $(&#x27;#p_legalCertNum&#x27;), _that = this; // init value on page load $showInput.val(this._maskIdCard($realInput.val())); // register events $showInput.bind(&#x27;keyup&#x27;, function()&#123; $realInput.val($showInput.val()); &#125;); $showInput.bind(&#x27;focusin&#x27;, function()&#123; $(this).val($(&#x27;#legalCertNum&#x27;).val()); &#125;); $showInput.bind(&#x27;focusout&#x27;, function()&#123; formValidator.element($realInput[0]); $(this).val(_that._maskIdCard($realInput.val())); &#125;);&#125;)&lt;/script&gt;","categories":[],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"http://example.com/tags/Javascript/"}]},{"title":"Node.js开发常用命令","slug":"node-js-development-common-commands","date":"2020-10-10T06:17:23.000Z","updated":"2023-11-20T02:27:39.774Z","comments":true,"path":"2020/10/10/node-js-development-common-commands/","link":"","permalink":"http://example.com/2020/10/10/node-js-development-common-commands/","excerpt":"","text":"node多版本管理工具 nvm nvm list nvm current nvm install stable nvm install 9.2.0 nvm use 9.2.0 包管理工具 npm npm list -g –depth 0 npm install webpack -g npm install # 安装依赖 npm run init # 项目初始化 npm run dev # 运行测试环境 npm run build # 生产环境打包","categories":[],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"}]},{"title":"raw.githubusercontent.com拒绝连接","slug":"a-solution-to-raw.githubusercontent.com-connection-refuse","date":"2020-10-10T04:28:31.000Z","updated":"2023-11-20T02:27:39.758Z","comments":true,"path":"2020/10/10/a-solution-to-raw.githubusercontent.com-connection-refuse/","link":"","permalink":"http://example.com/2020/10/10/a-solution-to-raw.githubusercontent.com-connection-refuse/","excerpt":"","text":"今天安装一个来自github的脚本，需要从raw.githubusercontent.com下载安装，但是一直提示拒绝连接。一般这种情况就是域名查询过程中被墙了。解决思路很简单，找到这个域名的香港ip，直接在host文件中配置一下，绕过域名查询就可以了。 香港ip可以从这里获取: https://site.ip138.com/raw.githubusercontent.com/","categories":[],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"}]},{"title":"Git手动打标签","slug":"common-git-tag-usage","date":"2020-10-02T02:33:21.000Z","updated":"2023-11-20T02:27:39.760Z","comments":true,"path":"2020/10/02/common-git-tag-usage/","link":"","permalink":"http://example.com/2020/10/02/common-git-tag-usage/","excerpt":"","text":"使用git很久了，以前都是直接用git-flow来管理git工作流，对标签tag的管理都由git-flow脚本封装好，自动完成了。这次因为项目特殊，需要每日手动打标签tag，特地记录一下。 git标签分类git的标签分两种：轻量标签(lightweight) 和 附注标签(annotated)。轻量标签义如其名，仅仅是对某个commit的一个引用。附注标签则是存储于git数据库中的一个完整对象，包含了打标签者的名字、email、日期时间、以及标签信息，并且可以GPG签名验证。一般我们建议创建附注标签。 列举标签1git tag 查看标签1git show v20201002-1 创建标签创建附注标签： 1git tag -a v20201002-1 -m &quot;new feature: dropbox support&quot; 创建轻量标签： 1git tag v20201002-1w 删除标签从本地仓库删除： 1git tag -d v20201002-1 从远程仓库删除： 1git push origin --delete v20201002-1","categories":[],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"}]},{"title":"Mac下安装tomcat","slug":"install-tomcat-macos-catalina","date":"2020-09-28T08:45:00.000Z","updated":"2023-11-20T02:27:39.766Z","comments":true,"path":"2020/09/28/install-tomcat-macos-catalina/","link":"","permalink":"http://example.com/2020/09/28/install-tomcat-macos-catalina/","excerpt":"","text":"提示：Tomcat依赖Java运行环境，没装java的先安装java 从Tomcat官网下载所需版本。因为是Mac系统，我们选择*.tar.gz后缀或.zip*后缀的。 下载完成后Finder进入下载文件夹（默认为~&#x2F;Downloads），双击所下载的tar.gz压缩文件，Mac会自动解压并创建同名目录，比如，我的是apache-tomcat-8.5.58。 解压缩之后，其实就算安装完毕了。可直接运行bin/startup.sh启动tomcat。我比较追求完美，把tomcat移动到了专门安装软件的/usr/local目录下，具体操作见后续步骤。 移动tomcat至/usr/local目录 1sudo mv ~/Downloads/apache-tomcat-8.5.58 /usr/local/ 创建软连接 1sudo ln -s /usr/local/apache-tomcat-8.5.58 /Library/Tomcat 测试启动、关闭脚本终端直接输入启动脚本并执行，如下： 1/Library/Tomcat/bin/startup.sh 关闭脚本跟启动脚本在同一个目录下，名字为shutdown.sh。 验证安装。打开 http://localhost:8080/，看到Tomcat页面则说明安装成功。","categories":[],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"}]},{"title":"面向对象的常用设计原则","slug":"java-oop-7-principles","date":"2020-09-15T07:19:23.000Z","updated":"2023-11-20T02:27:39.769Z","comments":true,"path":"2020/09/15/java-oop-7-principles/","link":"","permalink":"http://example.com/2020/09/15/java-oop-7-principles/","excerpt":"","text":"世上唯一不变的是变化。 相对于其他实物，软件从写下第一行代码开始就不断反复变化。为了应对各种变化，需要一些通用的设计原则和模式来指导日常开发。面向对象诞生至今早已超过半个世纪，大量前辈们早就探索和总结出了一些列设计原则和设计模式。学好面向对象开发好比学好一门武功，设计原则是内功心法，设计模式是招式套路。心法和套路相辅相成，都是不可或缺的一环。 面向对象有七个设计原则： 开放封闭原则 里氏替换原则 依赖倒置原则 接口隔离原则 迪米特法则(最少知道原则) 单一职责原则 合成复用原则下面分别简单描述一下。 开放封闭原则 OCP这个原则是所有面向对象原则的核心。任何一个软件实体（小到一个类、大到一个系统）都要对扩展开放，对修改封闭。换句话说，要在尽量不修改原有代码的基础上，对功能进行扩充。一般实践过程中，常常通过接口、抽象类定义抽象层，然后通过实现类进行功能扩展。每次增加新功能只需要增加一个实现类即可。 里氏替换原则 LSP所有引用基类的地方必须能透明地使用其派生类的对象。说人话，就是所有父类引用都可以换成子类的引用。违反里氏替换原则的一个小例子： 12345if (obj typeof SubClass1) &#123; // do a&#125; else if (obj typeof SubClass2) &#123; // do b&#125; 依赖倒置原则 DIP这个原则有两层含义： 高层模块不应依赖于低层模块，二者都应依赖于抽象。 抽象不应依赖于细节，细节应依赖于抽象 针对接口编程，不要针对实现编程 我们在编码中，应该尽量依赖于抽象类和接口，而不是实现类。 接口隔离原则 ISP不能强迫用户去依赖他们不使用的接口。换句话说，接口里包含的方法定义应尽可能少！ 大接口要拆分成小接口。 迪米特法则(最少知道原则) Law of Demeter ，LoD只与你直接的朋友们通信，不要跟“陌生人”说话。 一个实体应尽可能少地与其他实体发生相互作用，使系统各模块相互独立。 单一职责原则 SIP这个原则是主要针对类来说的，让一个类只专注于一个职责。 如果有多个职责怎么办，通过其他原则拆分、重构它！所谓类的职责，是指引起该类变化的一个原因。 合成复用原则 Composite&#x2F;Aggregate Reuse Principle ，CARP多使用组合&#x2F;聚合，少使用类继承。 参考资料 面向对象设计的七大设计原则详解","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"},{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"Java Stream接口学习笔记","slug":"java-stream-interface-note","date":"2020-09-15T06:11:23.000Z","updated":"2023-11-20T02:27:39.770Z","comments":true,"path":"2020/09/15/java-stream-interface-note/","link":"","permalink":"http://example.com/2020/09/15/java-stream-interface-note/","excerpt":"","text":"Stream接口概念辨析Java中有两类Stream，一类是IO流，常见的有InputStream、OutputStream等，还有一类是Java8 新增的Stream接口。Stream接口位于java.util.stream包中,是对集合功能的增强。如何增强呢？ 简单来说，它支持集合元素的筛选、切片、映射、排序、匹配查找、聚合等多种复杂常见操作，使用Lambda表达式简化代码编写，并支持并行和串行两种模式的操作。 Stream接口使用步骤 创建Stream，通过一个数据源来获取一个流 转换Stream，每次转换可得到一个新的Stream对象 对Stream进行聚合操作产生最终结果 Stream流的创建有以下四种创建方式： 基于现有集合，调用集合的stream()方法创建：12List&lt;Integer&gt; integerList = List.of(1, 2, 3, 4, 5, 6);Stream&lt;Integer&gt; integerStream = integerList.stream(); 基于数组，通过Stream工具类的stream()静态方法创建：1IntStream intStream = IntStream.of(1, 2, 3, 4, 5, 6); 通过Stream接口的of(T.. values)静态方法创建：1Stream&lt;Integer&gt; integerStream1 = Stream.of(1, 2, 3, 4, 5, 6); 通过Stream接口的generate(Supplier&lt;? extends T&gt; s)静态方法创建：1Stream&lt;Integer&gt; limit = Stream.generate(new Random()::nextInt).limit(10); Stream中间操作（结果仍为Stream) 筛选、切片 方法声明 功能 Stream filter&lt;Predicate&lt;? super T&gt; predicate) 过滤，返回一个包含匹配元素的流 Stream distinct() 去重，返回不含重复元素的流 Stream limit(long maxSize) 切片，返回不超过maxSize数量的元素组成的流 Stream skip(long n) 切片，返回丢弃前n个元素后的流 映射 方法声明 功能 Stream map(Function&lt;? super T, ? extends R&gt; mapper) 返回每个处理过元素组成的流 Stream flatMap(Function&lt;? super T,? extends Stream&lt;? extends R&gt;&gt; mapper) 返回每个被替换过元素组成的流，并将所有流合成一个流 排序 方法声明 功能 Stream sorted() 返回经过自然排序后元素组成的流 Stream sorted(Comparator&lt;? super T&gt; comparator) 返回经过比较器排序后元素组成的流 Stream终止操作 匹配与查找 方法声明 功能 Optional findFirst() 返回该流的第一个元素 boolean allMatch(Predicate&lt;? super T&gt; predicate) 判断所有元素是否匹配 boolean noneMatch(Predicate&lt;? super T&gt; predicate) 判断没有元素是否匹配 Optional max(Comparator&lt;? super T&gt; comparator) 根据比较器返回最大元素 Optional min(Comparator&lt;? super T&gt; comparator) 根据比较器返回最小元素 long count() 返回元素的个数 void forEach(Consumer&lt;? super T&gt; action) 对流中每个元素执行操作 规约（reduce） 方法声明 功能 Optional reduce(BinaryOperator accumulator) 返回结合后的元素值 收集 方法声明 功能 &lt;R,A&gt; R collect(Collector&lt;? super T,A,R&gt; collector) 使用收集器对元素进行处理","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"}]},{"title":"Java捕获InputMismatchException陷入死循环的bug处理","slug":"a-InputMismatchException-problem","date":"2020-09-12T09:13:23.000Z","updated":"2023-11-20T02:27:39.757Z","comments":true,"path":"2020/09/12/a-InputMismatchException-problem/","link":"","permalink":"http://example.com/2020/09/12/a-InputMismatchException-problem/","excerpt":"","text":"while(true) + scanner.nextInt() 导致InputMismatchException 死循环问题今天做一个练手项目时，需要用户输入数字来选择菜单。示例代码如下： 1234567891011protected void processOption() &#123; System.out.println(&quot;\\n\\n\\t\\t在线考试系统&quot;); System.out.println(&quot;---------------------------------&quot;); System.out.println(&quot;\\t[1] 学员登录\\t\\t[2] 管理员登录&quot;); System.out.println(&quot;\\t[0] 退出系统&quot;); System.out.print(&quot;请选择操作：&quot;); int choice = scanner.nextInt(); System.out.println(&quot;您的选择是: &quot; + choice); // 后续处理 System.out.println(&quot;后续处理逻辑。。。&quot;);&#125; 显然，上面这段代码，用户只有一次输入机会。为提高程序可用性，如果用户输入的不是数字，需要重新输入直到输入数字为止。因此考虑加上循环，修改后的代码如下： 12345678910111213protected void processOption() &#123; while(true) &#123; System.out.print(&quot;请选择操作：&quot;); int choice = scanner.nextInt(); System.out.println(&quot;您的选择是: &quot; + choice); if (choice &gt;=0 &amp;&amp; choice &lt;=2) &#123; // 输入的选项合法，跳出循环 break; &#125; &#125; // 后续处理 System.out.println(&quot;后续处理逻辑。。。&quot;);&#125; 如果用户正常输入数字，则没有问题。否则，若输入字母、其他字符等，则直接抛出运行时异常InputMismatchException，导致程序异常终止。 123456789101112请选择操作：试试水客户端关闭！Exception in thread &quot;main&quot; java.util.InputMismatchException at java.base/java.util.Scanner.throwFor(Scanner.java:939) at java.base/java.util.Scanner.next(Scanner.java:1594) at java.base/java.util.Scanner.nextInt(Scanner.java:2258) at java.base/java.util.Scanner.nextInt(Scanner.java:2212) at homework1.client.ClientView.processOption(ClientView.java:39) at homework1.client.ClientBaseView.mainPage(ClientBaseView.java:49) at homework1.test.ClientTest.main(ClientTest.java:23)Process finished with exit code 1 为避免因为这么一个小小错误引起程序终止，增加try-catch异常捕获： 1234567891011121314151617protected void processOption() &#123; while(true) &#123; try &#123; System.out.print(&quot;请选择操作：&quot;); int choice = scanner.nextInt(); System.out.println(&quot;您的选择是: &quot; + choice); if (choice &gt;=0 &amp;&amp; choice &lt;=2) &#123; // 输入的选项合法，跳出循环 break; &#125; &#125; catch (InputMismatchException e) &#123; System.out.println(&quot;输入错误！请输入数字选项。&quot;); &#125; &#125; // 后续处理 System.out.println(&quot;后续处理逻辑。。。&quot;);&#125; 输入字符串进行测试，发现程序并未如预期般循环等待输入，而是直接陷入死循环： 1234567请选择操作：输入错误！请输入数字选项。请选择操作：输入错误！请输入数字选项。请选择操作：输入错误！请输入数字选项。请选择操作：输入错误！请输入数字选项。请选择操作：输入错误！请输入数字选项。请选择操作：输入错误！请输入数字选项。... 问题原因分析为什么呢？翻一下Scanner的源码，发现nextInt()方法在识别到非数字字符串时，会抛出这个Input异常，并且在抛出异常前刻意把缓冲区指针设置到本字符串的开头位置。 12345678910111213141516171819202122// java.util.Scanner.java public int nextInt(int radix) &#123; // Check cached result if ((typeCache != null) &amp;&amp; (typeCache instanceof Integer) &amp;&amp; this.radix == radix) &#123; int val = ((Integer)typeCache).intValue(); useTypeCache(); return val; &#125; setRadix(radix); clearCaches(); // Search for next int try &#123; String s = next(integerPattern()); if (matcher.group(SIMPLE_GROUP_INDEX) == null) s = processIntegerToken(s); return Integer.parseInt(s, radix); &#125; catch (NumberFormatException nfe) &#123; position = matcher.start(); // don&#x27;t skip bad token throw new InputMismatchException(nfe.getMessage()); &#125; &#125; 重点看最后三行： 1234&#125; catch (NumberFormatException nfe) &#123; position = matcher.start(); // don&#x27;t skip bad token throw new InputMismatchException(nfe.getMessage());&#125; 也就是说，在我们的程序中，如果用nextInt()接收一个非数字字符串输入，字符串并不会被消费掉。下次再接收时，仍然会读取到跟上次一样的字符串。这样程序就陷入了死循环。 处理方案一：把错误字符串消费掉Scanner没有帮我们做的事，我们可以自己做。在Catch代码块里调用一下next()方法，把错误字符串消费掉即可。代码如下： 123456789101112131415161718protected void processOption() &#123; while(true) &#123; try &#123; System.out.print(&quot;请选择操作：&quot;); int choice = scanner.nextInt(); System.out.println(&quot;您的选择是: &quot; + choice); if (choice &gt;=0 &amp;&amp; choice &lt;=2) &#123; // 输入的选项合法，跳出循环 break; &#125; &#125; catch (InputMismatchException e) &#123; System.out.println(&quot;输入错误！请输入数字选项。&quot;); scanner.next(); // 增加这一句，消费掉输入错误的字符串 &#125; &#125; // 后续处理 System.out.println(&quot;后续处理逻辑。。。&quot;);&#125; 执行效果如下： 1234567请选择操作：xasx输入错误！请输入数字选项。请选择操作：afdsfas输入错误！请输入数字选项。请选择操作：1您的选择是: 1后续处理逻辑。。。 解决！ 处理方案二：nextInt()换成next()既然nextInt()方法有这些毛病，我们也可以放弃它，改用next()方法接收到字符串，然后自己针对字符串做处理。 代码如下： 1234567891011121314151617181920212223protected void processOption() &#123; while(true) &#123; System.out.print(&quot;请选择操作：&quot;); String temp = scanner.next(); int choice = -1; boolean match = temp.matches(&quot;[0-9]+&quot;); if (match) &#123; int choice = Integer.parseInt(temp); System.out.println(&quot;您的选择是: &quot; + choice); if (choice &gt;=0 &amp;&amp; choice &lt;=2) &#123; // 输入的选项合法，跳出循环 break; &#125; else &#123; continue; &#125; &#125; else &#123; System.out.println(&quot;输入错误！请输入数字选项。&quot;); continue; &#125; &#125; // 后续处理 System.out.println(&quot;后续处理逻辑。。。&quot;);&#125; 小结两种方案都可以处理掉while(true) + nextInt()导致的InputMismatchException死循环问题，相对来说，第一种方案代码更简洁一些。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"}]},{"title":"Java序列化多个对象到文件并正确读写的技巧","slug":"java-serialize-and-deserialize-multiple-objects","date":"2020-08-19T13:45:03.000Z","updated":"2023-11-20T02:27:39.770Z","comments":true,"path":"2020/08/19/java-serialize-and-deserialize-multiple-objects/","link":"","permalink":"http://example.com/2020/08/19/java-serialize-and-deserialize-multiple-objects/","excerpt":"","text":"我们一般使用ObjectInputStream的Object readObject()方法来从输入流中读出一个对象，这个方法有个缺陷是，无法通过返回值来判断是否读到了文件末尾。因此，我们要序列化多个对象时，需要额外一些小技巧来处理。大体来说，有四种方法能够正确序列化反序列化多个对象： 把对象装入集合中，对整个集合进行序列化和反序列化 把对象放入对象数组中，对对象数组进行序列化和反序列化 依次序列化写入多个对象，并追加一个null对象，反序列化读取时若读到null就停止 依次序列化写入多个对象，读取时以FileInputStream的int available()返回值判断是否终止下面举例说明。 数据准备&amp;测试程序准备首先准备一个要序列化的类： 1234567891011121314151617181920212223public class User implements Serializable &#123; private static final long serialVersionUID = 1105545465577482303L; private String name; private int age; private transient String phone; // transient 关键字表示该成员不参与序列化 public User() &#123; &#125; public User(String name, int age, String phone) &#123; this.name = name; this.age = age; this.phone = phone; &#125; @Override public String toString() &#123; return &quot;User&#123;&quot; + &quot;name=&#x27;&quot; + name + &#x27;\\&#x27;&#x27; + &quot;, age=&quot; + age + &quot;, phone=&#x27;&quot; + phone + &#x27;\\&#x27;&#x27; + &#x27;&#125;&#x27;; &#125; 然后准备测试程序，主体代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243public class SerializableTest &#123; public static void main(String[] args) &#123; // 1. 准备要序列化的数据 User[] users = &#123; new User(&quot;张三&quot;,33, &quot;185000011133&quot;), new User(&quot;李四&quot;,44, &quot;185000011144&quot;), new User(&quot;王五&quot;,55, &quot;185000011155&quot;), new User(&quot;赵六&quot;,66, &quot;185000011166&quot;), &#125;; ObjectOutputStream oos = null; ObjectInputStream ois = null; try &#123; // 2. 准备输出流和输入流 String fileName = &quot;./out/oos_1.txt&quot;; oos = new ObjectOutputStream(new FileOutputStream(fileName)); FileInputStream fis = new FileInputStream(fileName); ois = new ObjectInputStream(fis); // 3. 序列化到文件,并反序列化读取并输出// testSerialize1(users, oos, ois);// testSerialize2(users, oos, ois); testSerialize3(users, oos, ois);// testSerialize4(users, oos, ois, fis); &#125; catch (IOException | ClassNotFoundException e) &#123; e.printStackTrace(); &#125; finally &#123; // 4. 关闭流 if (null != ois) &#123; try &#123; ois.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; if (null != oos) &#123; try &#123; oos.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; 实现多个对象的序列化和反序列下面分别用4种方式实现多个对象的序列化和反序列化。 1. 把对象装入集合中，对整个集合进行序列化和反序列化（推荐）把下面这个方法加入到上面的SerializableTest类中。 123456789101112131415161718192021/** * 方法1： 使用集合保存多个对象，对集合进行序列化反序列化 * @param users * @param oos * @param ois */ private static void testSerialize1(User[] users, ObjectOutputStream oos, ObjectInputStream ois) throws IOException, ClassNotFoundException &#123; ArrayList&lt;User&gt; list1 = new ArrayList&lt;&gt;(); for (User user : users) &#123; list1.add(user); &#125; oos.writeObject(list1); oos.flush(); System.out.println(&quot;方法1写入完毕！&quot;); Object obj = ois.readObject(); System.out.println(&quot;方法1读取数据为：&quot; + obj); ArrayList&lt;User&gt; list2 = (ArrayList&lt;User&gt;)obj; for (User user: list2) &#123; System.out.println(user); &#125; &#125; 运行测试程序，输出为： 123456方法1写入完毕！方法1读取数据为：[User&#123;name=&#x27;张三&#x27;, age=33, phone=&#x27;null&#x27;&#125;, User&#123;name=&#x27;李四&#x27;, age=44, phone=&#x27;null&#x27;&#125;, User&#123;name=&#x27;王五&#x27;, age=55, phone=&#x27;null&#x27;&#125;, User&#123;name=&#x27;赵六&#x27;, age=66, phone=&#x27;null&#x27;&#125;]User&#123;name=&#x27;张三&#x27;, age=33, phone=&#x27;null&#x27;&#125;User&#123;name=&#x27;李四&#x27;, age=44, phone=&#x27;null&#x27;&#125;User&#123;name=&#x27;王五&#x27;, age=55, phone=&#x27;null&#x27;&#125;User&#123;name=&#x27;赵六&#x27;, age=66, phone=&#x27;null&#x27;&#125; 2. 把对象放入对象数组中，对对象数组进行序列化和反序列化把下面这个方法加入到上面的SerializableTest类中。 12345678910111213141516/** * 方法2： 使用Object数组保存多个对象，对整个数组进行序列化反序列化 * @param users * @param oos * @param ois */ private static void testSerialize2(User[] users, ObjectOutputStream oos, ObjectInputStream ois) throws IOException, ClassNotFoundException &#123; oos.writeObject(users); oos.flush(); System.out.println(&quot;方法2写入完毕！&quot;); Object[] objs = (Object[])ois.readObject(); System.out.println(&quot;方法2读取数据为：&quot;); for (Object obj: objs) &#123; System.out.println(obj); &#125; &#125; 输出跟上面类似。 3. 依次序列化写入多个对象，并追加一个null对象，反序列化读取时若读到null就停止把下面这个方法加入到上面的SerializableTest类中。 1234567891011121314151617181920/** * 方法3： 依次写入多个对象,再追加一个null对象表示结束，读取时判断读到的对象是否为null * @param users * @param oos * @param ois */ private static void testSerialize3(User[] users, ObjectOutputStream oos, ObjectInputStream ois) throws IOException, ClassNotFoundException &#123; for (User user: users) &#123; oos.writeObject(user); &#125; oos.writeObject(null); oos.flush(); System.out.println(&quot;方法3写入完毕！&quot;); System.out.println(&quot;方法3读取数据为：&quot;); Object obj = null; while ((obj = ois.readObject()) != null) &#123; System.out.println(obj); &#125; &#125; 输出同方法2。 4. 依次序列化写入多个对象，读取时以FileInputStream的int available()返回值判断是否终止把下面这个方法加入到上面的SerializableTest类中。 1234567891011121314151617181920/** * 方法4： 依次写入多个对象，读取时使用fis.available()方法判断是否读取到末尾 * @param users * @param oos * @param ois * @param fis */ private static void testSerialize4(User[] users, ObjectOutputStream oos, ObjectInputStream ois, FileInputStream fis) throws IOException, ClassNotFoundException &#123; for (User user: users) &#123; oos.writeObject(user); &#125; oos.flush(); System.out.println(&quot;方法4写入完毕！&quot;); System.out.println(&quot;方法4读取数据为：&quot;); while (fis.available() &gt; 0) &#123; Object obj = ois.readObject(); System.out.println(obj); &#125; &#125; 输出同方法2。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"}]},{"title":"一次性搞定Git中忽略.DS_Store文件","slug":"git-ignore-ds_store-files-in-mac","date":"2020-08-19T11:12:03.000Z","updated":"2023-11-20T02:27:39.763Z","comments":true,"path":"2020/08/19/git-ignore-ds_store-files-in-mac/","link":"","permalink":"http://example.com/2020/08/19/git-ignore-ds_store-files-in-mac/","excerpt":"","text":".DS_Store文件是Mac系统用来存储当前文件夹的显示属性元数据的，如图标位置等设置。.DS_Store广泛存在于每个文件夹下，一般供Finder、Spotlight使用。而对于基于Git托管的代码仓库来说，.DS_Store就是无用数据了。我们需要在Git中忽略它们。 忽略.DS_Store文件，我们通常有两种选择： 1. 当前项目忽略在当前项目根目录的.gitignore文件中添加如下一行即可: 12# vim .gitignore**/.DS_Store .gitignore文件常用规则可以看这里。 对于已经在Git版本控制的中.DS_Store，希望Git能够忽略，但不删除本地文件，需要在terminal中输入以下命令： 1git rm -r --cached .DS_Store Git如何屏蔽已经加入版本控制的文件可以看这里。 这种方式每当开新项目时都要配置，用起来比较麻烦。 2. 全局忽略首先创建一个 ~&#x2F;.gitignore_global文件： 1touch ~/.gitignore_global 然后在文件中添加如下内容： 12# vim ~/.gitignore_global**/.DS_Store 最后，将.gitignore_global作为Git的全局忽略配置文件： 1git config --global core.excludesfile ~/.gitignore_global 这种方式一劳永逸，不用每个项目都单独配置了。","categories":[],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"},{"name":"Git","slug":"Git","permalink":"http://example.com/tags/Git/"}]},{"title":"gitignore文件常用规则","slug":"common-rules-about-gitignore-file","date":"2020-08-19T11:09:03.000Z","updated":"2023-11-20T02:27:39.760Z","comments":true,"path":"2020/08/19/common-rules-about-gitignore-file/","link":"","permalink":"http://example.com/2020/08/19/common-rules-about-gitignore-file/","excerpt":"","text":".gitignore文件是Git的忽略配置文件，几乎每个Giter都需要跟这个文件打交道，有必要熟悉并记住它的一些常用规则。具体罗列如下： 所有空行或注释符号#开头的行都被忽略不计 规则按顺序从前到后依次生效 第一个/匹配Git项目根目录 以/结尾表示匹配的是目录 通配符*可匹配任意多个字符，通配符?匹配单个字符。注意：通配符不会匹配路径分隔符/ 两个连续星号**有特殊含义： 以**/开头表示匹配所有目录下的，例如**/readme.md匹配所有目录下的readme.md文件。 以/**结尾表示匹配目录下的所有内容，例如a/**匹配目录a下的所有文件和目录、子目录等。 a/**/b表示匹配目录a到目录b之间的0或多层目录，例如a/**/b可匹配 a/b, a/x/b,a/x/y/b等。 以惊叹号!开头表示不忽略，即不忽略匹配到本行规则的文件或目录。一般用于在前面规则里被忽略了，但是又想加回到版本控制的文件或目录。注意：如果匹配到的父目录还是忽略状态，则本文件或目录保持忽略状态。","categories":[],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"},{"name":"Git","slug":"Git","permalink":"http://example.com/tags/Git/"}]},{"title":"Mac系统让文件夹自动排列整齐","slug":"mac-os-align-directories","date":"2020-06-30T01:39:21.000Z","updated":"2023-11-20T02:27:39.772Z","comments":true,"path":"2020/06/30/mac-os-align-directories/","link":"","permalink":"http://example.com/2020/06/30/mac-os-align-directories/","excerpt":"","text":"在Mac系统的Finder（访达）里边，每次新建文件夹，或者拖入一个文件夹，文件夹都是停留在光标位置，甚至遮挡其他文件，显得很乱。 今天找到一个终极解决办法，可以让文件和文件夹自动排列整齐。设置步骤如下： 打开Finder的齿轮⚙小图标，点击查看显示选项： 修改下图中的分组方式和排序方式取值,全部改为**”名称”**： 修改前： 修改后： 一定要点击底部的“用作默认”按钮。 经过以上简单三步设置就可以了。看一下设置后的效果：","categories":[],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"}]},{"title":"Mac OS Catalina修改默认截图名称","slug":"mac-os-catalina-change-snapshot-name","date":"2020-06-30T00:51:09.000Z","updated":"2023-11-20T02:27:39.772Z","comments":true,"path":"2020/06/30/mac-os-catalina-change-snapshot-name/","link":"","permalink":"http://example.com/2020/06/30/mac-os-catalina-change-snapshot-name/","excerpt":"","text":"在Mac系统中，截图是一件极其简单的事。无需安装任何额外软件，直接使用command+shift+4就可以用光标框选任意屏幕大小进行截图了，截图会自动保存到桌面上。用户操作简单，通常意味着Mac系统默默帮我们做了很多事情。如果是中文系统，默认截图文件命名为类似“截屏 2020-06-30 上午 08.54.32”这样的格式，对于轻微强迫症的我来说，**”截屏”两个汉字做前缀稍微觉得不喜，可以按如下命令修改为“snapshot_”**: 1defaults write com.apple.screencapture name &quot;snapshot_&quot; 这样以后的截图文件名就改为“snapshot_2020-06-30 上午 08.54.32”这样的格式了。如果对后面的日期格式也不满意，还可以去掉日期： 1defaults write com.apple.screencapture &quot;include-date&quot; 0 这样截图文件命名将变成“snapshot_1”、“snapshot_2”，后面的数字按截图先后顺序依次递增。","categories":[],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"}]},{"title":"我理解的Unicode、UTF-8之间的关系","slug":"unicode-utf8-note","date":"2020-06-13T04:47:09.000Z","updated":"2023-11-20T02:27:39.777Z","comments":true,"path":"2020/06/13/unicode-utf8-note/","link":"","permalink":"http://example.com/2020/06/13/unicode-utf8-note/","excerpt":"","text":"Unicode和UTF-8是程序员经常遇到的词汇，基本上涉及文字处理的程序，都离不开这两个概念。可是，一会儿Unicode，一会儿又是UTF-8，它们之间到底是什么关系， 你弄明白了吗？为了搞懂这个问题，有一些基本概念需要提前安利一下。 计算机只能直接处理数字我们知道，计算机能直接处理的只有二进制数字，因为CPU的基本功能是进行数字的加减乘除四则运算、与或非等逻辑运算、算数和逻辑移位操作、比较数值、变更符号，以及计算主存地址等操作。所有其它数据，比如文本、图像、音视频等，都需要先转化成数字才能被CPU进行处理。 字符人类的语言和文字由一个个字符构成，字符包括文字（比如英文字母、汉字）、标点符号以及其他符号等。每种语言和文字都有自己的字符，全世界的字符加起来有好几百万种。 字符编码由于计算机只能处理二进制数字，而我们人类文字却由字符组成。需要一种编码标准，为每一个字符指定一个二进制数字，来代替字符输入和存储到计算机中。 ASCII编码ASCII编码是最初的编码标准。它极其简陋，只有128个字符编码，规定了英语26个字母字符和空格、逗号等其他一些常用字符的二进制编码。 ASCII码的局限ASCII编码对于英语来说足够了。但是世界上语言这么多，每种语言又有几百到几千甚至几万个字符，ASCII码不足以表示这么多字符，于是各个国家都先后制定了自己的编码标准。这些标准都是在ASCII码基础上做了大规模的扩充，兼容ASCII码没问题，但是相互之间就不兼容了。因为对于不同的编码标准，同一个二进制编码可能代表了不同的字符，而相同的字符在不同编码标准中所对应的二进制编码也不一样。这就产生了大量的转换难题。乱码问题就是因为编码识别错误，或转换错误造成的。 计算机系统编码的局限一般的计算机操作系统，只能支持两种编码混用，一种是ASCII编码，另一种是本地语言编码。计算机系统不支持多种编码的混用。比如同时使用中文GBK、中文繁体BIG5、日文Shift_JIS等。 Unicode想象一下，如果有一种编码，能够包含地球上的所有文字符号，并指定唯一编码，那前面提到的多种编码转识别难题就迎刃而解了。Unicode就是为了解决这种各自为政的混乱局面产生的。Unicode是一种字符编码方案，包括字符集和字符编码表。它囊括了世界上的所有符号，为每种语言的每个字符都设置了一个独一无二的二进制编码。 Unicode的表示问题由于Unicode意图囊括世界上所有字符(目前有100多万个字符)，它必然需要一个很大的字符集。这个字符集的二进制整数范围很广，像ASCII那样的1个字节是容纳不了的。需要两个字节的二进制数字才能完全容纳。一旦多于一个字节，就需要考虑存储和传输问题了。相关问题有二： 给定一个字符序列，计算机如何知道这是由多个字节组成的Unicode字符，还是单个字节组成的几个ASCII字符？ 一般的英文字符和数字，只需要一个字节就能表示，而Unicode却规定了至少两个字节，如果所有英文字符都按双字节存储，会造成大量的存储空间浪费。 给定一个双字节的Unicode字符，在存储和传输时，第一个字节在前，还是第二个字节在前？即Big Endian和Little Endian问题。 Unicode编码表只是规定了字符和两个字节二进制数字之间的逻辑对应关系，并没有规定这个二进制数字应该怎么存储和传输。 UTF-8为了解决上述几个问题，UTF-8编码产生了。确切的说，UTF-8编码是Unicode的一种编码实现方式。除了UTF-8，还有UTF-16，UTF-32等。 UTF-8一个最大的特点是，它是一种变长的编码方式。它使用1-4个字节来表示一个字符。UTF-8只有两条简单的编码规则： 对于单字节字符，字节首位为0，后7位为这个字符对应的unicode二进制数字编码。这部分其实就是ASCII码。 对于n字节(n&gt;1)字符，第一个字节的前n位为1，第n+1位为0；后面的第2-第n个字节的前两位为10。每个字节除了刚才指定的这几个位之外，其余用字符的unicode二级制数字码依次填充。编码规则用图表表示如下： Unicode范围（16进制） UTF-8编码方式 000000 - 00007F 0xxxxxxx 000080 - 0007FF 110xxxxx 10xxxxxx 000800 - 00FFFF 1110xxxx 10xxxxxx 10xxxxxx 010000 - 10FFFF 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx 举个例子：“汉”字的Unicode编码是0x6C49。0x6C49在0x0800-0xFFFF之间，使用3字节模板：1110xxxx 10xxxxxx 10xxxxxx。将0x6C49写成二进制是：0110 1100 0100 1001， 用这个比特流依次代替模板中的x，得到：11100110 10110001 10001001，用16进制表示是E6 B1 89。 由UTF-8编码反向解读出二进制数字也很简单。从第一个字节开始判断，如果第一个字节的第一位为0，则这个字节单独构成一个字符；而如果第一个字节是1，往后数连续有几个1，则表示这个字符占用了连续几个字节。 UTF-8、UTF-16、UTF-32除了最常用的UTF-8编码实现外，Unicode字符集还可以采用UTF-16、UTF-32等编码实现方式。下面用一个例子简答解释一下。例如，“汉字”对应的Unicode编码是0x6c49和0x5b57，分别用三种编码表示为： 123char8_t data_utf8[]=&#123;0xE6,0xB1,0x89,0xE5,0xAD,0x97&#125;; //UTF-8编码char16_t data_utf16[]=&#123;0x6C49,0x5B57&#125;; //UTF-16编码char32_t data_utf32[]=&#123;0x00006C49,0x00005B57&#125;; //UTF-32编码 字节序 Big Endian 和 Little Endian字节序有两种，Big Endian大端序和Little Endian小端序，分别简写为BE和LE。对于一个双字节字符来说，如果第一个字节在前面就是大端序，如果第二个字节在前面就是小端序。根据字节序的不同，UTF-16可被实现为UTF-16BE和UTF-16LE，UTF-32可被实现为UTF-32BE和UTF32-LE。举例说明：例如，汉字的“汉”，Unicode编码为0x6c49，分别表示为： Unicode编码 UTF-16BE UTF-16LE UTF-32BE UTF-32LE 0x006c49 6c 49 49 6c 00 00 6c 49 49 6c 00 00 0x020c30 d8 43 dc 30 30 dc 43 d8 00 02 0c 30 30 0c 02 00 那么，计算机如何知道某个文件到底使用哪种字节序呢？Unicode标准建议使用BOM（Byte Order Mark）来区分字节序。在传输字节流之前，先传输被作为BOM字符的“零宽无中断空格”（zero width no-break space）字符，用一个未定义的编号FEFF表示。正好是两个字节。各种UTF编码的BOM如下： UTF编码 Byte Order Mark UTF-8 without BOM 无 UTF-8 with BOM EF BB BF UTF-16LE FF FE UTF-16BE FE FF UTF-32LE FF FE 00 00 UTF-32BE 00 00 FE FF 根据BOM就能识别出正确的字节序，从而得到正确的编码方式了。注意，UTF-8的编码方式，其实是规定好了字节顺序的，因此BOM不是必须的。一般不建议在UTF-8文件中加BOM。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"}]},{"title":"Java IO流笔记（一）","slug":"java-io-note-1","date":"2020-06-12T07:37:03.000Z","updated":"2023-11-20T02:27:39.768Z","comments":true,"path":"2020/06/12/java-io-note-1/","link":"","permalink":"http://example.com/2020/06/12/java-io-note-1/","excerpt":"","text":"IO流的概念和分类什么是流读写数据时像流水一样，从一端到另一端，因此叫做“流”。 流的分类按处理内容分为： 字节流 字符流。 （双字节） 按输入输出类别分为： 输入流 输出流 按跟数据源的关系分为: 节点流 处理流 IO流的体系结构主要的IO流类可以用下面一张表整合： 分类 字节输入流 字节输出流 字符输入流 字符输出流 抽象基类 InputStream OutputStream Reader Writer 访问文件 FileInputStream FileOutputStream FileReader FileWriter 访问数组 ByteArrayInputStream ByteArrayOutputStream CharArrayReader CharArrayWriter 访问管道 PipedInputStream PipedOutputStream PipedReader PipedWriter 访问字符串 – – StringReader StringWriter 缓冲流 BufferedInputStream BufferedOutputStream BufferedReader BufferedWriter 转换流 – – InputStreamReader InputStreamWriter 对象流 ObjectInputStream ObjectOutputStream – – FilterInputStream FilterOutputStream FilterReader FilterWriter 打印流 – PrintStream – PrintWriter 推回输入流 PushbackInputStream – PushbackReader – 特殊流 DataInputStream DataOutputStream 我们常用需要掌握的结构：","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"}]},{"title":"Java File类笔记","slug":"java-file-note-1","date":"2020-06-12T04:32:03.000Z","updated":"2023-11-20T02:27:39.768Z","comments":true,"path":"2020/06/12/java-file-note-1/","link":"","permalink":"http://example.com/2020/06/12/java-file-note-1/","excerpt":"","text":"java.io.File类是对文件极其常用操作的抽象。 File类的常用方法直接上代码： 1234567891011121314151617public class FileTest &#123; public static void main(String[] args) throws IOException &#123; // 1. 构造函数 String filename = &quot;./README.md&quot;; System.out.println(&quot;File(&quot; + filename + &quot;)&quot;); File f1 = new File(&quot;./README.md&quot;); if (f1.exists()) &#123; System.out.println(&quot;getName(): &quot; + f1.getName()); System.out.println(&quot;getPath(): &quot; + f1.getPath()); System.out.println(&quot;getAbsolutePath(): &quot; + f1.getAbsolutePath()); System.out.println(&quot;getCanonicalPath(): &quot; + f1.getCanonicalPath()); System.out.println(&quot;lastModified(): &quot; + f1.lastModified()); System.out.println(&quot;length(): &quot; + f1.length()); System.out.println(&quot;isFile(): &quot; + f1.isFile()); &#125; &#125;&#125; 区分getName()、getPath()、getAbsolutePath()、getCanonicalPath() 文件的创建和删除示例代码： 1234567String filename = &quot;./test-file.md&quot;;File f1 = new File(filename);if (f1.exists()) &#123; System.out.println(f1.delete() ? &quot;文件删除成功！&quot; : &quot;文件删除失败！&quot;);&#125; else &#123; System.out.println(f1.createNewFile() ? &quot;文件创建成功！&quot; : &quot;文件创建失败！&quot;);&#125; 目录的创建和删除示例代码： 123456789// 2. 目录创建、删除 File f2 = new File(&quot;./test-dir/test-subdir&quot;); if (f2.exists()) &#123; System.out.println(&quot;getName(): &quot; + f2.getName()); // 这里只能删除最内层的非空目录 System.out.println(f2.delete()? &quot;目录删除成功！&quot; : &quot;目录删除失败！&quot;); &#125; else &#123; System.out.println(f2.mkdirs() ? &quot;目录创建成功！&quot; : &quot;目录创建失败！&quot;); &#125; listFiles()指定文件过滤FileFilter示例代码： 123456File f4 = new File(&quot;./.idea&quot;); FileFilter filter = (pathname) -&gt; &#123; return pathname.getName().endsWith(&quot;.xml&quot;);&#125;; File[] fileList2 = f4.listFiles(filter); for (File f: fileList2) &#123; System.out.println(f.getName()); &#125; 目录及子目录的递归遍历示例代码如下： 123456789101112131415161718192021/** * 递归打印目录和子目录下所有文件 * @param file * @param filter */ public static void show_dirs(File file, FileFilter filter) &#123; File[] files = file.listFiles(filter); for (File f: files) &#123; if (f.isFile()) &#123; System.out.println(f.getName()); &#125; else if (f.isDirectory()) &#123; System.out.println(&quot;Dir[&quot; + f.getName() + &quot;]&quot;); show_dirs(f, filter); &#125; &#125; &#125; public static void main(String[] args) &#123; FileFilter filter2 = (pathname) -&gt; &#123; return pathname.isDirectory() || pathname.getName().endsWith(&quot;.class&quot;); &#125;; show_dirs(new File(&quot;./out&quot;), filter2); &#125;","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"}]},{"title":"Java学习笔记-异常","slug":"java-exception-notes","date":"2020-06-09T06:43:21.000Z","updated":"2023-11-20T02:27:39.768Z","comments":true,"path":"2020/06/09/java-exception-notes/","link":"","permalink":"http://example.com/2020/06/09/java-exception-notes/","excerpt":"","text":"异常机制的基本概念异常就是指不正常的意思，在Java中指的是程序执行过程中发生的不正常情况。 异常VS错误Java将程序的不正常行为按严重程度分为错误（Error）和异常（Exception）两大类。java.lang.Throwable是描述错误Error和异常Exception的超类。Error类指的是Jvm无法处理的严重错误，一旦发生Error，通常Jvm无能为力，只能挂掉。Exception类通常用来描述因编程错误或偶然外部因素导致的轻微错误，一般可以通过编程解决。 异常的分类Java官方提供的异常类很多，但通常可以按异常检测的时间点分为两大类： 检测性异常，也就是说编译器可以检测到的异常，比如IOException等。 非检测性异常，RuntimeException，也叫运行时异常。 比如，被0除时会抛出ArithmeticException,空指针时的NullPointException,等等。 异常的继承结构前面已经说过，所有异常都继承自Exception类，而Exception又继承自Throwable类。再加上我们平时最常用的几个Runtime异常，构成的异常继承结构图如下： 异常的代码结构1234567try &#123; ①&#125; catch (Exception e) &#123; ②&#125; finally &#123; ③&#125; finally的注意事项 finally 异常的处理异常的处理，一般有三种方式： 异常避免 异常捕获 异常抛出如果拿感冒来比喻异常，这三种方式就好比我们的对待感冒的策略一样。首先，我们平时注意锻炼、保暖，以避免得上感冒，这相当于异常的避免。而万一得了感冒，我们可以吃点感冒药，这相当于异常的捕获。如果感冒严重了吃感冒药也不顶用，那就只能去医院看医生了，这就相当于抛出异常。 异常避免一般使用if语句来提前判断，避免异常。比如下面的语句，通过判断b是否等于0，来避免ArithmeticException： 12345int a = 10;int b = 0;if (b != 0) &#123; System.out.println(a / b);&#125; 再比如，提前判断引用变量是否为空，来避免空指针异常NullPointException： 12345FileInputStream fis = null;...if (null != fis) &#123; fis.close();&#125; 异常捕获使用catch语句来捕获异常并处理；使用finally做善后处理。 catch语句注意： 多个catch语句，小异常类应放到前面。 tips: finally语句在函数return之前必然执行。 考点：请问下面代码返回结果是几？ 12345678try &#123; System.out.println(3 / 0); return 0;&#125; catch (ArithmeticException e) &#123; return 1;&#125; finally &#123; return 2;&#125; 结果是 2， 因为finally抢在return 1之前return了。 异常抛出若方法决定自己不处理异常，则需要将异常抛出。 什么时候抛出异常，什么时候捕获异常？经验： 方法重写时，若被重写的方法未抛出异常，则重写后的方法也不应该抛出异常。 如果方法之间有好多层调用关系，可以抛出异常，交由最外层方法捕获。 自定义异常有时候我们需要自定义异常。 为什么要自定义异常呢Java官方提供的异常不够用。现实业务开发中，异常各种各样，需要自定义。 如何自定义编码示例： public class XXXException extends Exception &#123; static final long serialVersionUID = 1111111L; public XXXException() &#123; &#125; public XXXException(String message) &#123; super(message); &#125; &#125;","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"}]},{"title":"v2ray突然失效超时问题处理","slug":"solve-v2ray-timeout-problem","date":"2020-05-22T05:46:00.000Z","updated":"2023-11-20T02:27:39.777Z","comments":true,"path":"2020/05/22/solve-v2ray-timeout-problem/","link":"","permalink":"http://example.com/2020/05/22/solve-v2ray-timeout-problem/","excerpt":"","text":"今天打开Google，发现不能用了，折腾了近两个小时，才不完美的解决了。 问题描述这个问题的直接表现就是，Google打不开。查了下v2ray客户端日志，发现如下记录： 122020/05/22 13:43:00 [Info] [1562828084] v2ray.com/core/transport/internet/tcp: dialing TCP to tcp:1.1.1.1:111112020/05/22 13:43:01 [Warning] [1562828084] v2ray.com/core/app/proxyman/outbound: failed to process outbound traffic &gt; v2ray.com/core/proxy/vmess/outbound: failed to find an available destination &gt; v2ray.com/core/common/retry: [dial tcp 1.1.1.1:11111: i/o timeout dial tcp 1.1.1.1:11111: operation was canceled] &gt; v2ray.com/core/common/retry: all retry attempts failed （保密起见，记录中ip地址和端口号已经替换成假的，下文同。） 上述日志表明，连接远程v2ray服务端发生了网络IO超时。这意味着，要么服务器出故障了，要么网络出故障了。那就一项一项排查呗，先检查服务器，再检查网络。 服务器排查第一步，检查一下服务器是否还在正常工作。一般情况下用服务器ip是否能够ping通作为判断标准。 123456ping 1.1.1.1PING 1.1.1.1 (1.1.1.1): 56 data bytes64 bytes from 1.1.1.1: icmp_seq=0 ttl=50 time=205.611 msRequest timeout for icmp_seq 164 bytes from 1.1.1.1: icmp_seq=2 ttl=50 time=205.445 ms64 bytes from 1.1.1.1: icmp_seq=3 ttl=50 time=207.564 ms 可见，服务器本身是好的。 第二步，检查v2ray服务端端口是否正常工作。在本地用tcping工具检查v2ray服务端的端口号，发现端口状态为“closed”。 12# tcping 1.1.1.1 111111.1.1.1 port 11111 closed. 端口closed。似乎抓到背后问题的尾巴了！顺手再查查其他端口比如80、443等常用HTTP端口，发现状态都是“open”。那么，这里可以下一个初步结论：这个端口从本机访问不了了。不过这种情况还无法直接定位到问题根源，需要继续排查。 第三步，检查服务器中v2ray程序是否启动。 12# ps -ef | grep v2ray root 2988 1 0 14:02 ? 00:00:02 /usr/bin/v2ray/v2ray -config /etc/v2ray/config.json 第四步，检查服务器上v2ray监听端口是否开启。 12# netstat -nap | grep 11111tcp6 0 0 :::11111 :::* LISTEN 2988/v2ray 经过以上两个步骤，可以看出v2ray服务端并没有什么问题，仍在正常工作中。第五步，检查服务器防火墙配置，看看有没有禁用v2ray的监听端口。 1234567# iptables --list...Chain IN_public_allow (1 references)...ACCEPT tcp -- anywhere anywhere tcp dpt:6170 ctstate NEW,UNTRACKEDACCEPT udp -- anywhere anywhere udp dpt:6170 ctstate NEW,UNTRACKED... 可见，防火墙对v2ray监听端口也正确设置了放行规则。 经过以上检查步骤，断定服务器端配置没有问题。另外，由于本地电脑和服务器都是我一个人在用，也不存在别人改了我的配置，导致本机v2ray和服务端配置不一致的情况。 网络排查其实经过上面服务器端检查的第二步，已经能够说明很多问题了。网站服务可正常访问，ssh也能用，唯独v2ray服务受到影响，可见不是服务器机房网络的问题了，而是涉及该端口11111的流量，在传输过程中被ban了。这种情况就难以下确切结论了，只能想其他办法了。 不断试错，最终解决找不到根本原因，那就求助万能的搜索引擎吧，看看网友们怎么说。谷歌用不了就只能度娘了。打开百度输入关键词”v2ray连接超时“，竟然第一条就找到了一个貌似提供解决方案的blog，打开一看发布日期，”2020年5月20日“，哦哦，还就是这两天发布的，看来靠谱。该博文给出的方案是v2ray服务器端绑定ipv4监听地址，其实就是修改v2ray配置文件/etc/v2ray/config.json，在inbound节点中加上&quot;listen&quot;: &quot;1.1.1.1&quot;这样的配置项，然后保存退出，重启v2ray。按这个方案试了一下，不行。 回头看博文下面的评论，讨论挺热烈，大家都说方案跑不通。再翻翻其他博文，也都说的云里雾里。 实在没辙了，先换个端口试试吧。修改服务器端v2ray配置文件，端口号由原来的11111改为22222。 1234567# vim /etc/v2ray/config.json...&quot;inbound&quot;: &#123; &quot;port&quot;: 11111, &lt;------这里修改端口 &quot;protocol&quot;: &quot;vmess&quot;, &quot;listen&quot;:&quot;12.34.56.78&quot;,... 修改后，同步修改本机v2ray客户端配置里的端口号。另外别忘了在服务器防火墙里配置开放这个端口。再次打开Google测试，竟然可以访问了！ 喜大普奔！ 冷静下来后，再次检查本机v2ray日志： 1234562020/05/22 14:08:11 [Info] [713431801] v2ray.com/core/app/dispatcher: default route for tcp:www.google.com:4432020/05/22 14:08:11 [Info] [713431801] v2ray.com/core/transport/internet/tcp: dialing TCP to tcp:1.1.1.1:222222020/05/22 14:08:11 tcp:127.0.0.1:63193 accepted tcp:www.gstatic.com:443 [proxy] 2020/05/22 14:08:11 tcp:127.0.0.1:63192 accepted tcp:www.google.com:443 [proxy] 2020/05/22 14:08:11 [Info] [3172428981] v2ray.com/core/proxy/vmess/outbound: tunneling request to tcp:www.gstatic.com:443 via tcp:1.1.1.1:222222020/05/22 14:08:11 [Info] [713431801] v2ray.com/core/proxy/vmess/outbound: tunneling request to tcp:www.google.com:443 via tcp:1.1.1.1:22222 发现跟远程服务器端的tunnel通道已经成功建立了。最后总结一句话解决办法： 换端口。 问题反思这次问题算是临时得到了解决。至于为什么原来的端口不能用了，怀疑是跟网络运营商，或是国际线路节点有关，可能是因为一些不能明说的原因比如BT下载等，这个端口或端口区间被ban了。这种情况也没办法说理去，只能换端口了。下次要是遇到类似的情况，估计还得换端口。所以说这是不完美的解决办法。","categories":[],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"}]},{"title":"一个简单的ajax上传文件方案","slug":"a-simple-example-to-upload-file-using-ajax","date":"2020-05-08T09:48:00.000Z","updated":"2023-11-20T02:27:39.758Z","comments":true,"path":"2020/05/08/a-simple-example-to-upload-file-using-ajax/","link":"","permalink":"http://example.com/2020/05/08/a-simple-example-to-upload-file-using-ajax/","excerpt":"","text":"一般在前端上传文件我习惯用百度的WebUploader，不过有时候也会用到一些简单的方案。这里就记录一个比较简单的ajax上传文件方案。 前端 html部分1234&lt;form enctype=&quot;multipart/form-data&quot;&gt; &lt;p&gt;选择文件：&lt;input type=&quot;file&quot; id=&quot;upload_file&quot; name=&quot;upload_file&quot;/&gt;&lt;/p&gt; &lt;button id=&quot;submit&quot;&gt;提交&lt;/button&gt;&lt;/form&gt; js部分首先需要依赖jquery,请自行引入，这里不再描述。12345678910111213141516171819202122232425262728293031&lt;script type=&quot;application/javascript&quot;&gt;$(function() &#123; // 选择1：点击”提交“按钮时上传 $(&#x27;#submit&#x27;).click(function() &#123; ajaxUpload(); &#125;); // 选择2：文件对象改变时触发上传 $(&#x27;#upload_file&#x27;).change(function()&#123; ajaxUpload(); &#125;); function ajaxUpload() &#123; var files = $(&#x27;#upload_file&#x27;).prop(&#x27;files&#x27;); var data = new FormData(); data.append(&#x27;file&#x27;, files[0]); $.ajax(&#123; type: &#x27;POST&#x27;, url: &#x27;upload.php&#x27;, data: data, cache: false, // 兼容ie8，防止ie8之前版本缓存get请求的处理方式 contentType: false, // 避免jquery误解 processData: false, // 避免发送的数据被默认转为&quot;application/x-www-form-urlencoded&quot; success: function(data) &#123; console.log(data); console.log(typeof data); // 拿到后端传回的响应信息后，做后续业务处理 &#125; &#125;) &#125;&#125;)&lt;/script&gt; 后端 我这里在后端处理文件上传的语言是upload.php。它的主要内容如下：1234567891011121314151617181920212223242526// in upload.phpheader(&quot;Content-type: application/json&quot;);try &#123; $uploadFile = $_FILES[&#x27;csv_file&#x27;]; $originName = basename($uploadFile[&quot;name&quot;]); //被上传文件的名称 $tmpName = $uploadFile[&#x27;tmp_name&#x27;]; //检查或创建保存目录 $savePath = &#x27;../upload/&#x27; . date(&quot;Y_m_d/&quot;); if(!file_exists($savePath))&#123; mkdir($savePath); &#125; //文件重命名 $newName = $originName; // 为简单起见，这里在保存文件时未修改文件名 //保存文件 $saveFile = $savePath.$newName; if(move_uploaded_file($tmpName, $saveFile))&#123; die(json_encode(&#x27;code&#x27;=&gt;1, &#x27;msg&#x27;=&gt;$newName));//上传成功，返回文件名。 &#125; else &#123; throw new Exception(&#x27;文件写入失败，请检查上传目录是否可写&#x27;, -1); &#125;&#125; catch (Exception $e) &#123; die(json_encode(&#x27;code&#x27;=&gt;-1, &#x27;msg&#x27;=&gt;$e-&gt;getMessage()));&#125;","categories":[],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"http://example.com/tags/Javascript/"}]},{"title":"ajax上传文件时碰到的一个小坑","slug":"a-common-bug-when-upload-file-using-ajax","date":"2020-05-08T09:11:00.000Z","updated":"2023-11-20T02:27:39.757Z","comments":true,"path":"2020/05/08/a-common-bug-when-upload-file-using-ajax/","link":"","permalink":"http://example.com/2020/05/08/a-common-bug-when-upload-file-using-ajax/","excerpt":"","text":"今天调试一个ajax文件上传接口，拿到的数据看起来是标准的json字符串，但是浏览器执行始终跟期望不一样。 1234567891011121314151617181920212223$.ajax(&#123; type : &#x27;POST&#x27;, data : data, url : &#x27;upload.php&#x27;, cache: false, processData: false, contentType: false, success : function(data)&#123; console.log(data); console.log(data.code); var code = data.code; var msg = data.msg; switch(code)&#123; case 1: $(&#x27;#health_doc&#x27;).val(msg); $(&#x27;#show_plan_file&#x27;).hide(); break; default: layer.alert(msg, &#123;icon: 5&#125;); break; &#125; &#125; &#125;); 上图代码中，console.log(data)打印正常,而console.log(data.code)打印结果为undefined。 于是，再追加一条打印语句console.log(typeof data)，发现结果竟然是string，看来json字符串没有被浏览器自动解析。经检查Response Header，找到问题了。原来是接口返回的header头不对，其他接口都返回Content-Type: application/json, 唯独这个接口返回的是Content-Type: text/html，导致返回的json字符串没有办法被浏览器自动解析。再追究一层，发现Response Header的设置跟ajax请求时有关，我们为了实现文件上传，给ajax设置了contentType属性设置为false，这样后端就无法根据请求contentType自动给出正确的响应头Content-Type设置。 解决这个问题有两种方案：一是在后端输出请求响应内容前，设置Http响应头信息为application-json。假设后端是php，可以如下设置： 1header(&quot;Content-type: application/json&quot;); 另一种方案是后端不处理，前端js拿到响应字符串后自己通过JSON.parse(data)手动转为json对象。","categories":[],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"http://example.com/tags/Javascript/"}]},{"title":"Mac下安装配置maven","slug":"install-maven-for-mac","date":"2020-05-08T08:45:00.000Z","updated":"2023-11-20T02:27:39.766Z","comments":true,"path":"2020/05/08/install-maven-for-mac/","link":"","permalink":"http://example.com/2020/05/08/install-maven-for-mac/","excerpt":"","text":"在mac下安装maven，有两种可选方案： maven的安装方法1，通过官网压缩包安装 访问官网下载maven压缩包，.zip或.tar.gz后缀的都可以。 解压压缩包到你日常放置绿色软件的目录 vim ~/.bash_profile，添加M2_HOME环境变量:12export M2_HOME=/Users/xxx/Documents/maven/apache-maven-3.6.3export PATH=$PATH:$M2_HOME/bin 注意把上边命令中的路径替换为你电脑上的路径。wq保存退出后，执行以下命令使配置生效：1source ~/.bash_profile mvn -v检查安装是否成功 方法2，通过brew直接安装brew安装很简单，不需要再配置M2_HOME等环境变量。 注意，brew 安装时会自动安装maven的依赖 openjdk，可能比较慢，如果已经通过非brew的方式安装了jdk，建议还是走官网压缩包安装的方式。 brew安装命令如下： 123456# 查找mavenbrew search maven# 查看版本信息和依赖包brew info maven# 安装brew install maven 最后，使用mvn -v检查安装是否成功。 安装完成后的配置一般我们需要配置本地仓库和加速镜像即可。所有配置项都在settings.xml文件中定义。 配置本地仓库修改settings.xml文件，配置以下内容： 1&lt;localRepository&gt;/Users/xxx/maven_repo&lt;/localRepository&gt; 配置加速镜像修改settings.xml文件，配置以下内容: 123456789&lt;mirrors&gt; &lt;!-- aliyun --&gt; &lt;mirror&gt; &lt;id&gt;alimaven&lt;/id&gt; &lt;name&gt;aliyun maven&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/repositories/central/&lt;/url&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;/mirror&gt;&lt;/mirrors&gt;","categories":[],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"}]},{"title":"java局部变量、实例变量、静态变量辨析","slug":"differences-of-java-variables","date":"2020-05-05T06:50:21.000Z","updated":"2023-11-20T02:27:39.762Z","comments":true,"path":"2020/05/05/differences-of-java-variables/","link":"","permalink":"http://example.com/2020/05/05/differences-of-java-variables/","excerpt":"","text":"根据声明位置的不同，我们一般可以将java的变量分为两个类型：成员变量和局部变量。 变量的分类成员变量是指声明在类中、类方法之外的变量，包括： 实例变量： 无static修饰。 类变量(静态变量)：有static修饰。局部变量是指声明在类方法中的变量，包括： 方法参数变量：也就是形参。 方法局部变量：声明在方法体{}内，方法体嵌套的代码块外。 代码块局部变量：声明在方法体嵌套的代码块内。 各种变量的特征接下来用一个表格阐述一下这5种类型的变量各自的特征。 声明&#x2F;定义方式 作用域&amp;生命周期 访问权限 默认值&amp;初始化 内存分配 方法参数变量 方法形参 方法执行时创建，执行完释放 方法体内可见 无，必须明确初始化 栈区(java虚拟机栈) 方法局部变量 方法体{}内 方法执行时创建，执行完释放 方法体内可见 无，必须明确初始化 栈区(java虚拟机栈) 代码块局部变量 方法体内的某个代码块{}内 代码块执行时创建，执行完释放 代码块内可见 无，必须明确初始化 栈区(java虚拟机栈) 实例变量 类中，方法体外 对象创建时创建，对象销毁时释放 由修饰符决定 有，引用类型为null，基本数据类型为java预定义的默认值 随对象一起分配在堆上 静态变量 类中，方法体外，带static修饰符 类加载时创建，类卸载时销毁 由修饰符定 有，引用类型为null，基本数据类型为java预定义的默认值 方法区(静态存储区)","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"}]},{"title":"小议编码时for循环和while循环的选择","slug":"how-to-choose-for-while","date":"2020-05-04T07:15:32.000Z","updated":"2023-11-20T02:27:39.765Z","comments":true,"path":"2020/05/04/how-to-choose-for-while/","link":"","permalink":"http://example.com/2020/05/04/how-to-choose-for-while/","excerpt":"","text":"大家都知道for循环和while循环是等价的，我们平时写代码既可以用for循环也可以用while循环，正所谓条条大路通罗马。可是，既然java选择保留了这两种循环，至少意味着它们在使用场合上还是有一些侧重的。先上个例子：猜数字游戏：系统先生成一个1-100之间的随机数(不让用户知道)，然后让用户来猜测输入的数字是几，如果用户输入正确则游戏结束，否则，给出大于、小于的提示，继续让用户输入。这个题目，如果用for循环来写，大概是这样的： 1234567891011public static void guessNumberUsingFor() &#123; System.out.println(&quot;-----猜数字游戏开始------&quot;); int givenNumber = new java.util.Random().nextInt(100) + 1; java.util.Scanner scanner = new java.util.Scanner(System.in); System.out.println(&quot;请猜一个数字：&quot;); for (int inputNumber = scanner.nextInt(); inputNumber != givenNumber; inputNumber = scanner.nextInt()) &#123; System.out.println((inputNumber &lt; givenNumber) ? &quot;猜小了,再猜：&quot; : &quot;猜大了，再猜：&quot;); &#125; System.out.println(&quot;啊哈，猜对了！&quot;); System.out.println(&quot;-----猜数字游戏结束------&quot;);&#125; 用while循环的版本如下： 12345678910111213public static void guessNumberUsingWhile() &#123; System.out.println(&quot;-----猜数字游戏开始------&quot;); int givenNumber = new java.util.Random().nextInt(100) + 1; java.util.Scanner scanner = new java.util.Scanner(System.in); System.out.println(&quot;请猜一个数字：&quot;); int inputNumber = scanner.nextInt(); while (inputNumber != givenNumber) &#123; System.out.println((inputNumber &lt; givenNumber) ? &quot;猜小了,再猜：&quot; : &quot;猜大了，再猜：&quot;); inputNumber = scanner.nextInt(); &#125; System.out.println(&quot;啊哈，猜对了！&quot;); System.out.println(&quot;-----猜数字游戏结束------&quot;);&#125; 上面这个例子，for版本似乎没有while版本顺滑，症结在于for循环版本把一些比较重的赋值、更新语句（这里是scanner.nextInt()）揉进了for循环的变量初始化和更新值的过程中，显得有违常识，影响了代码的可读性。对于习惯了for(int i=0; i &lt; 10; i++) &#123;&#125;这样的人来说，极有可能会忽视掉inputNumber = scanner.nextInt()这条最重要的业务处理语句。而while版本，判断逻辑非常清晰，读起来一气呵成，没有任何认知障碍。 再看第二个例子：** 计算1到100的整数之和 **for循环版本如下： 1234567public static void sumUsingFor() &#123; int sum = 0; for (int i = 1; i &lt;= 100; i++) &#123; sum += i; &#125; System.out.println(&quot;sum = &quot; + sum);&#125; while循环版本为： 123456789public static void sumUsingWhile() &#123; int sum = 0; int i = 1; while (i &lt;= 100) &#123; sum += i; i++; &#125; System.out.println(&quot;sum = &quot; + sum);&#125; 这个例子中，for循环的优势就比较明显了。首先，单单从代码行数上来讲，for循环7行，while循环需要9行，少了两行代码。其次，while循环里的i++;语句，稍微不仔细的话就可能忘记写了，造成无限循环！而且这错误属于逻辑错误，编译器也帮不了你。 从上面两个例子可以看出，选择合适的循环语句是需要费点脑子的。那么，到底什么时候该用for，什么时候适合用while，有没有什么规矩呢？有的。一般来说，while循环更适合于明确循环条件而不明确循环次数的场合，for循环则更适合于明确循环次数或范围的场合。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"}]},{"title":"使用git stash暂存和恢复工作进度","slug":"git-stash-usage","date":"2020-05-03T13:56:31.000Z","updated":"2023-11-20T02:27:39.764Z","comments":true,"path":"2020/05/03/git-stash-usage/","link":"","permalink":"http://example.com/2020/05/03/git-stash-usage/","excerpt":"","text":"我们有时候正在开发一个feature，突然同事插进来说发现一个重大bug，需要立即修复。但是我们的feature才编码一半，不能提交。这时候就轮到git stash闪亮登场了。git stash命令可以让我们先把当前的修改内容暂存在本地，保持working directory干净状态，接着就可以切换分支去修bug了。修完bug后，再把分支切回来，使用git stash pop命令恢复之前的修改内容，继续我们的feature编码。git stash命令支持调用多次，它有一个类似栈的概念，每调用一次会把当前未暂存的修改压栈，然后可以使用git stash pop 从栈顶拿出最近一次压栈的修改内容。 git stash常见用法 git stash - 暂存当前修改 git stash save &#39;some message&#39; - 功能同git stash，可额外添加一个注释信息便于找回 git stash list - 查看当前有哪些暂存的修改，可以列出stash_id，供后续恢复时使用 git stash pop - 取出最新的修改内容 git stash pop --index - 恢复最新的修改内容到工作区和暂存区 git stash pop &#39;stash_id&#39; - 恢复到指定的stash_id对应的修改内容 git stash apply - 功能同git stash pop但不删除刚从栈中取出的这个stash git stash drop - 删除最新的修改内容stash git stash drop &#39;stash_id&#39; - 根据stash_id删除栈记录 git stash clear - 清空stash栈（删除所有stash记录）","categories":[],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"},{"name":"Git","slug":"Git","permalink":"http://example.com/tags/Git/"}]},{"title":"PHP计算货币金额的方法","slug":"how-to-calculate-money-with-php","date":"2020-04-24T09:59:08.000Z","updated":"2023-11-20T02:27:39.764Z","comments":true,"path":"2020/04/24/how-to-calculate-money-with-php/","link":"","permalink":"http://example.com/2020/04/24/how-to-calculate-money-with-php/","excerpt":"","text":"涉及到计算金额，PHP提供了两类方法。一类是使用floor()和round()进行四舍五入，还有一类是以bc打头的一系列函数。 使用floor() 和 round()计算金额1234567891011//计算折扣$value = &#x27;9.95&#x27;;//折扣$money = &#x27;39.555&#x27;;//原始价格，当然到这一步的价格，一般都是小数点后两位的，此处保留三位，主要是为了对比echo &#x27;原始价格：&#x27;. $money * ($value/10);echo &#x27;&lt;pre&gt;&#x27;;echo &#x27;直接四舍五入：&#x27;.round($money * ($value / 10),2);echo &#x27;&lt;pre&gt;&#x27;;echo &#x27;截取小数点后1位：&#x27;.floor($money * $value)/10;echo &#x27;&lt;pre&gt;&#x27;;echo &#x27;截取小数点后2位&#x27;.floor($money * ($value / 10) * 100)/100;die; 使用bc类函数计算金额123456789101112131415161718192021222324252627282930313233/** * PHP精确计算 主要用于货币的计算用 * @param string $n1 第一个数 * @param string $symbol 计算符号 + - * / % * @param string $n2 第二个数 * @param string $scale 精度 默认为小数点后两位 * @return string */function price_calc($n1, $symbol, $n2, $scale = &#x27;2&#x27;)&#123; $res = &quot;&quot;; switch ($symbol) &#123; case &quot;+&quot;://加法 $res = bcadd($n1, $n2, $scale); break; case &quot;-&quot;://减法 $res = bcsub($n1, $n2, $scale); break; case &quot;*&quot;://乘法 $res = bcmul($n1, $n2, $scale); break; case &quot;/&quot;://除法 $res = bcdiv($n1, $n2, $scale); break; case &quot;%&quot;://求余、取模 $res = bcmod($n1, $n2, $scale); break; default: $res = &quot;&quot;; break; &#125; return $res;&#125;","categories":[],"tags":[{"name":"PHP","slug":"PHP","permalink":"http://example.com/tags/PHP/"}]},{"title":"MacOS中搭建VS Code + XDebug的PHP调试环境","slug":"setup-vscode-with-php-xdebug-for-macos","date":"2020-04-24T03:48:03.000Z","updated":"2023-11-20T02:27:39.775Z","comments":true,"path":"2020/04/24/setup-vscode-with-php-xdebug-for-macos/","link":"","permalink":"http://example.com/2020/04/24/setup-vscode-with-php-xdebug-for-macos/","excerpt":"","text":"笔者近期在MacOS Catalina环境下搭建了VS Code+XDebug的调试环境，用起来体验还不错。首先交代一下我电脑的环境： 123System: MacOS Catalina 10.15.4Editor: Visual Studio Code 1.44.2Language: PHP 7.4.4 (cli) (built: Mar 19 2020 20:12:27) ( NTS ) 搭建步骤如下： 安装并配置XDebug1. 安装XDebug首先，遵循XDebug官网指示，安装XDebug。这里官方建议使用pecl包管理工具安装： 1pecl install xdebug 也可选择从源码编译安装。安装步骤是标准的configure -&gt; make -&gt; make install, 这里不再赘述，具体请参考官方文档指示。 2. 配置XDebug这里主要是在php.ini文件中指定XDebug的动态链接库的位置、监听ip和端口等。由于系统中可能存在多个php.ini文件，一不小心就改错文件了。因此首先需要定位到当前使用中的php.ini文件。这就需要使用命令php --ini，输出如下： 1234Configuration File (php.ini) Path: /usr/local/etc/php/7.4Loaded Configuration File: /usr/local/etc/php/7.4/php.iniScan for additional .ini files in: /usr/local/etc/php/7.4/conf.dAdditional .ini files parsed: /usr/local/etc/php/7.4/conf.d/ext-opcache.ini 从上面的输出内容中可以看出来，我的php.ini文件位于/usr/local/etc/php/7.4/php.ini。 然后，在这个php.ini文件中添加[xdebug]配置段。我的配置如下： 123456789; put lines below into your working php.ini[xdebug]zend_extension = /usr/local/lib/php/pecl/20190902/xdebug.soxdebug.remote_enable = truexdebug.remote_port = 9001xdebug.profiler_enable = truexdebug.remote_autostart = 1xdebug.remote_host=localhostxdebug.remote_log=/var/log/xdebug/xdebug.log 注意，zend_extension需指向你电脑里的xdebug.so所在位置。xdebug默认端口是9000，由于我电脑里9000端口被php-fpm占了，这里把xdebug的端口改成了9001。remote_log有时候还是很有用的，建议开启。 配置完成后， VS Code安装并配置PHP Debug插件1. 安装插件点击vscode左侧边栏Extensions，打开搜索框，输入PHP Debug搜索，同名的插件有好几个，功能几乎没啥区别，我选择了带felixfbecker.php-debug标签的，因为它的配置文档比较详细一些。点击install安装即可。 2. 配置插件点击vscode左侧边栏Run，在打开的小侧栏里点击右上角的⚙齿轮图标，即可按提示新建或打开插件的配置文件launch.json。修改里边的端口号为你的xdebug监听端口号，其它配置可以不用改。这样就可以了。 测试一下在vscode中随便打开一个php文件，打上断点（在代码行的左侧边栏点击一下，出现小红点即可）。然后执行它，就可以看到程序停在断点位置了。","categories":[],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"}]},{"title":"正确设置.gitignore忽略已经纳入版本控制的文件","slug":"gitignore-files-already-under-git-version-control","date":"2020-04-23T10:59:02.000Z","updated":"2023-11-20T02:27:39.764Z","comments":true,"path":"2020/04/23/gitignore-files-already-under-git-version-control/","link":"","permalink":"http://example.com/2020/04/23/gitignore-files-already-under-git-version-control/","excerpt":"","text":"初建git项目时，考虑不完整，常常会将logs、cache等目录也纳入版本控制中。后续进入开发过程中，才意识到要将这些目录屏蔽掉。于是想到.gitignore文件。简单设置.gitignore 文件后，执行git push，发现被屏蔽的目录下文件仍然赫然在列，忽略设置并未生效。咋回事呢？ 不生效原因被纳入版本管理的文件，在git中会有缓存，即使声明了要ignore掉也不行 解决办法知道是缓存搞怪，清掉本地缓存重新push就ok了。具体操作如下： 1234git rm -r --cached .git add .git commit -m &quot;update .gitignore and clear local cache&quot;git push","categories":[],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"},{"name":"Git","slug":"Git","permalink":"http://example.com/tags/Git/"}]},{"title":"Django修改request对象的两种方法","slug":"how-to-modify-django-request","date":"2020-04-15T08:33:08.000Z","updated":"2023-11-20T02:27:39.765Z","comments":true,"path":"2020/04/15/how-to-modify-django-request/","link":"","permalink":"http://example.com/2020/04/15/how-to-modify-django-request/","excerpt":"","text":"Django使用request.GET或request.POST来获取参数，而这两个属性都是不可变的django.http.QueryDict对象，默认是不支持修改的。而我们有时候需要修改请求参数，怎么做呢？ 方法1：拷贝副本-&gt; 修改 -&gt; 赋值回去可以利用QueryDict的copy()方法，得到一个可变的QueryDict副本，在副本上修改参数值后，再赋值给request.GET对象。 代码如下： 123456789101112131415def local_product_list(request): &quot;&quot;&quot; 获取本地产品列表 &quot;&quot;&quot; params = request.GET.copy() params[&#x27;local&#x27;] = True request.GET = params return product_list(request)def product_list(request): &quot;&quot;&quot; 获取产品列表 &quot;&quot;&quot; ... 方法2：修改不可变属性直接上代码： 123456789101112131415161718192021def local_product_list(request): &quot;&quot;&quot; 获取本地产品列表 &quot;&quot;&quot; mutable_value = request.GET._mutable if not mutable_value: # 原来不可变，改为可变 request.GET._mutable = True # 修改参数值 request.GET[&#x27;local&#x27;] = True if not mutable_value: # 原来不可变，这里改回去，保持原值 request.GET._mutable = False return product_list(request)def product_list(request): &quot;&quot;&quot; 获取产品列表 &quot;&quot;&quot; ... 注意：QueryDict的update()方法跟我们常用的dict.update()有所不同。以下两段代码的效果是不一样的： 123456&gt;&gt;&gt; q2 = QueryDict(&#x27;local=False&#x27;, mutable=True)&gt;&gt;&gt; q2&lt;QueryDict: &#123;&#x27;local&#x27;: [&#x27;False&#x27;]&#125;&gt;&gt;&gt;&gt; q2[&#x27;local&#x27;] = True&gt;&gt;&gt; q2&lt;QueryDict: &#123;&#x27;local&#x27;: [True]&#125;&gt; 123456&gt;&gt;&gt; q3 = QueryDict(&#x27;local=False&#x27;, mutable=True)&gt;&gt;&gt; q3&lt;QueryDict: &#123;&#x27;local&#x27;: [&#x27;False&#x27;]&#125;&gt;&gt;&gt;&gt; q3.update(&#123;&#x27;local&#x27;: True&#125;)&gt;&gt;&gt; q3&lt;QueryDict: &#123;&#x27;local&#x27;: [&#x27;False&#x27;, True]&#125;&gt; 这是因为， request.GET[&#39;local&#39;] = True是直接修改原local参数的值，而request.GET.update(&#123;&#39;local&#39;: True&#125;)是追加新的值到local参数值的数组中。请务必小心！","categories":[],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"},{"name":"Django","slug":"Django","permalink":"http://example.com/tags/Django/"}]},{"title":"修改MySQL的自增ID","slug":"mysql-change-auto-increment-id","date":"2020-04-12T12:05:13.000Z","updated":"2023-11-20T02:27:39.773Z","comments":true,"path":"2020/04/12/mysql-change-auto-increment-id/","link":"","permalink":"http://example.com/2020/04/12/mysql-change-auto-increment-id/","excerpt":"","text":"近期在做一个数据迁移的项目时，需要把产品分类数据导入新表中。因为数据是爬虫抓取下来的，有些字段数据内容不完整或格式错误，因此执行了多次导入才最终导入成功。期间需要清空错误数据然后重新导入，如果不重置自增ID，则每次导入同样的数据，ID会越来越大。 那么如何设置自增ID呢？首先，可以用如下语句查看当前的自增ID是多少： 1SELECT AUTO_INCREMENT FROM information_schema.TABLES WHERE TABLE_SCHEMA = &#x27;your-database-name&#x27; AND TABLE_NAME = &#x27;your-table-name&#x27;; 然后，我们来修改自增ID： 1ALTER TABLE your-table-name AUTO_INCREMENT=1000; 以上语句就可以把自增ID设置为1000。至于最终设置的对不对，用上面第一条SQL查一下就知道了。","categories":[],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"}]},{"title":"","slug":"python-loop-with-index","date":"2020-04-12T11:48:30.000Z","updated":"2023-11-20T02:27:39.775Z","comments":true,"path":"2020/04/12/python-loop-with-index/","link":"","permalink":"http://example.com/2020/04/12/python-loop-with-index/","excerpt":"","text":"Python默认的for ... in ...循环是不带索引序号的，例如： 1234presidents = [&quot;Washington&quot;, &quot;Adams&quot;, &quot;Jefferson&quot;, &quot;Madison&quot;, &quot;Monroe&quot;, &quot;Adams&quot;, &quot;Jackson&quot;]for name in presidents: print(&quot;President : &#123;&#125;&quot;.format(name)) 执行结果如下： 1234567President : WashingtonPresident : AdamsPresident : JeffersonPresident : MadisonPresident : MonroePresident : AdamsPresident : Jackson 在这个例子中，我们可以打印出总统的名字，但不能打印出该总统是第几任总统。那么，如何打印出是第几任总统呢？用enumerate()函数。改成如下形式： 1234presidents = [&quot;Washington&quot;, &quot;Adams&quot;, &quot;Jefferson&quot;, &quot;Madison&quot;, &quot;Monroe&quot;, &quot;Adams&quot;, &quot;Jackson&quot;]for num, name in enumerate(presidents, start=1): print(&quot;President &#123;&#125;: &#123;&#125;&quot;.format(num, name)) 执行结果如下： 1234567President 1: WashingtonPresident 2: AdamsPresident 3: JeffersonPresident 4: MadisonPresident 5: MonroePresident 6: AdamsPresident 7: Jackson 搞定！","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"}]},{"title":"MySQL数据库编码更改为utf8mb4","slug":"mysql-utf8mb4","date":"2020-04-11T02:04:31.000Z","updated":"2023-11-20T02:27:39.774Z","comments":true,"path":"2020/04/11/mysql-utf8mb4/","link":"","permalink":"http://example.com/2020/04/11/mysql-utf8mb4/","excerpt":"","text":"现在大家打字聊天都喜欢发表情符号，而一个表情符号需要4个字节存储，对应的字符编码是utf8mb4。MySQL如果不做设置，默认编码会是乱七八糟的，什么都可能出现。比如下面这个： 如上图所示，我们可以使用SHOW VARIABLES WHERE Variable_name LIKE &#39;character_set_%&#39; OR Variable_name LIKE &#39;collation%&#39;;命令查询数据库服务器的编码设置。 使用utf8编码大家应该都没有异议，虽然关于utf8的争议从来就没有消停过，但它仍然一骑绝尘，逐渐成为存储多字节文字的事实标准。所以在这里不讨论为何不适用gbk甚至更古老的gb2312的话题。 为什么使用utf8mb4那么，为什么一定要使用utf8mb4编码呢？继续使用utf8编码不可以吗? 以前可以，现在不可以了。简单来说，utf8mb4是utf8的超集。utf8mb4完全兼容utf8，换句话说，用utf8mb4代替utf8是没有问题的；反之，utf8是不能替代utf8mb4的。采用utf8mb4,主要是为了解决文章开头我们提到的存储表情符号的问题。关于mysql使用utf8编码，网上有很多惨痛案例， 比如记住：永远不要在 MySQL 中使用 UTF-8 如何设置首先，设置 my.cnf文件，这个文件一般位于/etc/my.cnf。设置如下： 123456789[client]default-character-set=utf8mb4[mysql]default-character-set=utf8mb4[mysqld]character-set-client-handshake=FALSEcharacter-set-server=utf8mb4collation-server=utf8mb4_unicode_ciinit_connect=&#x27;SET NAMES utf8mb4&#x27; 注意，不同版本mysql或mariadb, 配置文件位置可能不一样，请灵活处理。 设置完成后，需要重启mysql服务。重启后，登陆mysql后台，继续用SHOW VARIABLES WHERE Variable_name LIKE &#39;character_set_%&#39; OR Variable_name LIKE &#39;collation%&#39;;命令检查配置是否OK。如果出现下面的配置，说明配置OK了。 另外，不要忘了把现有的数据库和表都转成utf8mb4编码。更改数据库编码： 1ALTER DATABASE caitu99 CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci; 更改表编码： 1ALTER TABLE TABLE_NAME CONVERT TO CHARACTER SET utf8mb4 COLLATEutf8mb4_general_ci;","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"}]},{"title":"Django开发环境搭建","slug":"setup-django-develop-environment","date":"2020-04-04T04:27:04.000Z","updated":"2023-11-20T02:27:39.775Z","comments":true,"path":"2020/04/04/setup-django-develop-environment/","link":"","permalink":"http://example.com/2020/04/04/setup-django-develop-environment/","excerpt":"","text":"整理了一下我的Django开发环境配置，步骤如下： 安装并配置conda我直接下载Anaconda。","categories":[],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"},{"name":"Django","slug":"Django","permalink":"http://example.com/tags/Django/"}]},{"title":"Django常用命令","slug":"django-common-usage","date":"2020-04-04T03:27:09.000Z","updated":"2023-11-20T02:27:39.762Z","comments":true,"path":"2020/04/04/django-common-usage/","link":"","permalink":"http://example.com/2020/04/04/django-common-usage/","excerpt":"","text":"最近在用Django做项目，整理了一下常用的命令，以备自查。 工程构建&amp;运行 查看Django版本1python -m django --version 创建工程1django-admin startproject your_project_name 创建App1python manage.py startapp your_app_name 本地测试运行工程1python manage.py runserver 8000 创建后台管理员1python manage.py createsuperuser 数据迁移migration 执行迁移1python manage.py migrate 创建迁移1python manage.py makemigrations your_app_name 检查迁移sql1python manage.py sqlmigration your_app_name your_migration_sequence_no 日常调试 &amp; 测试 打开命令行AP1python manage.py shell 执行自动测试1python manage.py test your_app_name","categories":[],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"},{"name":"Django","slug":"Django","permalink":"http://example.com/tags/Django/"}]},{"title":"命令行操作sqlite","slug":"access-sqlite3-from-command-line","date":"2020-04-04T03:03:32.000Z","updated":"2023-11-20T02:27:39.759Z","comments":true,"path":"2020/04/04/access-sqlite3-from-command-line/","link":"","permalink":"http://example.com/2020/04/04/access-sqlite3-from-command-line/","excerpt":"","text":"sqlite是世界上最广泛部署的数据库引擎。它无需服务器，仅仅需要一个数据文件，就能够实现自给自足、零配置且带事务支持的数据库引擎。因为轻便简单，是各种嵌入式程序的首选数据库。通过命令行操作sqlite也十分简单。最常用的命令列举如下： 打开数据库 1sqlite3 your_db_filename.sqlite3 sqlite数据库文件一般以*.sqlite3或.db*结尾。 查看帮助 1.help 查看数据库表 1.table 查看建表语句 1.schema your_table_name 查询某个表的数据 1select * from your_table_name; 注意这里的sql语句后面必须带分号。 同select一样，一般的标准sql语句都是支持的。","categories":[],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"}]},{"title":"Elasticsearch安全设置","slug":"secure-your-elasticsearch","date":"2020-04-03T03:55:32.000Z","updated":"2020-04-03T08:01:54.000Z","comments":true,"path":"2020/04/03/secure-your-elasticsearch/","link":"","permalink":"http://example.com/2020/04/03/secure-your-elasticsearch/","excerpt":"","text":"经常在网上看到因Elasticsearch服务裸奔造成的安全事件，比如某婚庆网站因Elasticsearch数据暴露在公网上被曝光，我本来不以为意，没想到自己的一台小服务器今天也中招了。 123# curl -XGET 192.168.1.11:9200/_cat/indicesyellow open locationkeywordv1 XH3c3vSWRAWOeAD9ZRDUKA 5 1 93 0 147.4kb 147.4kbyellow open nightlionsecurity.com X_uOYfJ9ThitglEA17LzbA 5 1 0 0 955b 955b 攻击者删除了我几乎所有的索引数据，还嚣张地以用他的网站域名nightlionsecurity.com建了一个新索引。 看来侥幸心理要不得，安全问题随时都不能马虎。那么，如何保障Elasticsearch服务的安全呢？今天只说一条：禁止外网访问Elasticsearch。 禁止外网访问Elasticsearch首先要做的就是修改Elasticsearch的配置文件。 1. 将Elasticsearch绑定到内网地址修改配置文件elasticsearch.yml，设置固定的内网IP： 1network.host: 192.168.1.11 然后需要禁止从外网访问Elasticsearch。可以从以下三方面入手： 2. 防火墙禁止Elasticsearch端口访问Elasticsearch节点暴露了三个默认端口： 9200： 集群对外访问端口 9300： 集群内部通信端口 5601：Kibana的对外访问端口 我们需要做的，就是限制直接从外网访问这几个端口。如果已经修改了默认端口，限制方法相同。我们拿9200端口举例，看一下如何限制访问。 在这里我们把目标明确一下：外网无法访问9200端口，内网同一网段可以访问。假定我的内网IP为192.168.1.30。按以下步骤操作 12345# 允许内网同一网段ip过来的请求iptables -A INPUT -p tcp --dport 9200 -s 192.168.1.0/24 -j ACCEPT# 拒绝其他请求iptables -A INPUT -p tcp --dport 9200 -j DROP# 其他两个端口9300和5601按类似步骤操作即可。配置完成后，可使用以下命令检查规则顺序： 1iptables -L -n 最后，这里设置的规则只是临时的，重启后就失效了。如果想重启后继续生效，需要执行以下命令将规则保存起来： 1service iptables save 注意，若执行 service iptables save时提示不存在save指令等情况，说明没有安装iptables-service 服务。需要先安装iptables-service后再执行保存。","categories":[],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://example.com/tags/Elasticsearch/"}]},{"title":"centos7安装并启用iptables","slug":"centos7-enable-iptables","date":"2020-04-02T11:02:31.000Z","updated":"2020-04-03T07:29:04.000Z","comments":true,"path":"2020/04/02/centos7-enable-iptables/","link":"","permalink":"http://example.com/2020/04/02/centos7-enable-iptables/","excerpt":"","text":"centos从7之后默认使用firewalld作为防火墙配置服务, 很多Linux老手不熟悉，还是喜欢原汁原味的iptables。这里整理一下如何把firewalld换回iptables。 安装iptables-service首先检查是否安装了iptables，如果没有安装，需要先安装： 1yum install -y iptables 若已经安装了，先升级： 1yum update iptables 再安装iptables-service: 1yum install -y iptables-service 停用自带的firewalld12systemctl stop firewalldsystemctl disable firewalld 开启iptables-service12systemctl enable iptables.servicesystemctl start iptables.service OK，接下来就可以用iptables愉快地玩耍了。更多iptables设置请参考这篇文章。","categories":[],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"}]},{"title":"iptables常用配置","slug":"iptables-common-configuration","date":"2020-04-02T10:39:23.000Z","updated":"2020-04-03T07:27:00.000Z","comments":true,"path":"2020/04/02/iptables-common-configuration/","link":"","permalink":"http://example.com/2020/04/02/iptables-common-configuration/","excerpt":"","text":"iptables初始设置这是一份来自网友清园的iptables初始设置清单，供有选择地参考： 123456789101112131415161718192021222324252627282930#查看iptables现有规则iptables -L -n#先允许所有,不然有可能会杯具iptables -P INPUT ACCEPT#清空所有默认规则iptables -F#清空所有自定义规则iptables -X#所有计数器归0iptables -Z#允许来自于lo接口的数据包(本地访问)iptables -A INPUT -i lo -j ACCEPT#开放22端口iptables -A INPUT -p tcp --dport 22 -j ACCEPT#开放21端口(FTP)iptables -A INPUT -p tcp --dport 21 -j ACCEPT#开放80端口(HTTP)iptables -A INPUT -p tcp --dport 80 -j ACCEPT#开放443端口(HTTPS)iptables -A INPUT -p tcp --dport 443 -j ACCEPT#允许pingiptables -A INPUT -p icmp --icmp-type 8 -j ACCEPT#允许接受本机请求之后的返回数据 RELATED,是为FTP设置的iptables -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT#其他入站一律丢弃iptables -P INPUT DROP#所有出站一律绿灯iptables -P OUTPUT ACCEPT#所有转发一律丢弃iptables -P FORWARD DROP iptables常用规则1. 删除现有规则1iptables -F 2. 阻止某个特定ip比如，要阻止101.101.101.101这个ip的访问： 1iptables -A INPUT -s 101.101.101.101 -j DROP 3. 只允许内网访问某端口比如，对于mysql默认端口3306,只能从内网访问： 12iptables -A INPUT --dport 3306 -s 192.168.1.0/24 -j ACCEPTiptables -A INPUT --dport 3306 -j DROP 更多规则可参考这篇文章。 iptables规则的保存首先确保启用iptables服务： 12systemctl enable iptables.servicesystemctl start iptables.service 然后使用 1service iptables save 命令把规则保存到/etc/sysconfig/iptables文件里。这样这样当计算机重启时，可自动重新加载。","categories":[],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"}]},{"title":"Java静态代码块、构造代码块、构造函数执行顺序","slug":"java-tips-2-initialization-order","date":"2020-04-01T07:18:03.000Z","updated":"2020-04-01T08:22:36.000Z","comments":true,"path":"2020/04/01/java-tips-2-initialization-order/","link":"","permalink":"http://example.com/2020/04/01/java-tips-2-initialization-order/","excerpt":"","text":"名词解释静态代码块：类中以*static {}*形式包围起来的代码块，Jvm加载类时执行，仅执行一次。构造代码块：类中以*{}*形式包围起来的代码块，不包括方法中的普通代码块。每次创建对象时都要执行。构造函数：每次创建对象时就会执行构造函数，构造函数的作用时给对象初始化。 单个类中的执行顺序执行顺序静态代码块 &gt; 构造代码块 &gt; 构造函数 验证执行以下代码： 1234567891011121314151617181920public class HelloTest &#123; public HelloTest() &#123; System.out.println(&quot;执行 HelloTest() 构造函数&quot;); &#125; &#123; System.out.println(&quot;执行构造代码块&quot;); &#125; static &#123; System.out.println(&quot;执行静态代码块&quot;); &#125; public static void main(String[] args) &#123; System.out.println(&quot;准备new第一个对象&quot;); HelloTest one = new HelloTest(); System.out.println(&quot;准备new第二个对象&quot;); HelloTest two = new HelloTest(); &#125;&#125; 结果输出： 1234567准备new第一个对象执行静态代码块执行构造代码块执行 HelloTest() 构造函数准备new第二个对象执行构造代码块执行 HelloTest() 构造函数 继承关系下的执行顺序考虑父子继承情况，顺序又会是怎么样呢？ 执行顺序父类静态代码块 &gt; 子类静态代码块 &gt; 父类构造代码块 &gt; 父类构造函数 &gt; 子类构造代码块 &gt; 子类构造函数 验证执行以下代码： 12345678910111213141516171819202122232425262728293031public static class HelloA &#123; public HelloA() &#123; System.out.println(&quot;执行HelloA的构造函数&quot;); &#125; &#123; System.out.println(&quot;执行HelloA的构造代码块&quot;); &#125; static &#123; System.out.println(&quot;执行HelloA的静态代码块&quot;); &#125;&#125;public static class HelloB extends HelloA &#123; public HelloB() &#123; System.out.println(&quot;执行HelloB的构造函数&quot;); &#125; &#123; System.out.println(&quot;执行HelloB的构造代码块&quot;); &#125; static &#123; System.out.println(&quot;执行HelloB的静态代码块&quot;); &#125; public static void main(String[] args) &#123; HelloB b = new HelloB(); &#125;&#125; 执行结果如下: 123456执行HelloA的静态代码块执行HelloB的静态代码块执行HelloA的构造代码块执行HelloA的构造函数执行HelloB的构造代码块执行HelloB的构造函数","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"}]},{"title":"Java tips 1 - final变量的几种初始化方式","slug":"java-tips-1-how-to-initialize-a-final-variable","date":"2020-03-31T16:00:00.000Z","updated":"2023-11-20T02:27:39.771Z","comments":true,"path":"2020/04/01/java-tips-1-how-to-initialize-a-final-variable/","link":"","permalink":"http://example.com/2020/04/01/java-tips-1-how-to-initialize-a-final-variable/","excerpt":"","text":"final成员变量的初始化方式方法1：在定义变量时直接赋值123public final class MyString &#123; private final char value[] = &quot;&quot;;&#125; 方法2：在构造函数中初始化1234567public final class MyString &#123; private final char value[]; public MyString() &#123; this.value = &quot;&quot;.value; &#125;&#125; 方法3：在构造代码块中初始化1234567public final class MyString &#123; private final char value[]; &#123; this.value = &quot;&quot;.value; &#125;&#125; 注意： 构造代码块会在构造函数之前被执行。 （构造代码块、静态代码块执行顺序） final静态变量的初始化方式方法1： 在定义时直接赋值123public final class MyString &#123; private static final long serialVersionUID = -6849794470754667710L;&#125; 方法2： 在静态代码块中赋值1234567public final class MyString &#123; private static final long serialVersionUID; static &#123; this.serialVersionUID = -6849794470754667710L; &#125;&#125; 关于静态代码块、构造代码块、构造函数的执行顺序，请参考我的另一篇blog：构造代码块、静态代码块执行顺序。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"}]},{"title":"centos8安装docker","slug":"install-docker-for-centos8","date":"2020-03-31T10:37:03.000Z","updated":"2023-11-20T02:27:39.766Z","comments":true,"path":"2020/03/31/install-docker-for-centos8/","link":"","permalink":"http://example.com/2020/03/31/install-docker-for-centos8/","excerpt":"","text":"安装依赖12yum install -y yum-utils device-mapper-persistent-data lvm2yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 安装docker engine community1yum install -y docker-ce docker-ce-cli containerd.io 此时，若报错：requires containerd.io &gt;&#x3D; 1.2.2-3 ，那就先通过rpm安装装新版的 containerd.io：1dnf install https://download.docker.com/linux/centos/7/x86_64/stable/Packages/containerd.io-1.2.6-3.3.el7.x86_64.rpm 再安装docker-ce和docker-ce-cli：1yum install -y docker-ce docker-ce-cli 检查安装：1docker -v 设置开机启动docker服务1systemctl enable docker 启动docker服务1systemctl restart docker Have fun!","categories":[],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"}]},{"title":"intellij idea添加阿里巴巴编码规范插件","slug":"add-alibaba-coding-guidelines-for-intellij-idea","date":"2020-03-31T07:49:10.000Z","updated":"2023-11-20T02:27:39.759Z","comments":true,"path":"2020/03/31/add-alibaba-coding-guidelines-for-intellij-idea/","link":"","permalink":"http://example.com/2020/03/31/add-alibaba-coding-guidelines-for-intellij-idea/","excerpt":"","text":"我们编写java程序都需要遵循一定的编码规范。阿里巴巴提供了一个优秀的IDEA插件，用来检测代码是否符合《阿里巴巴Java开发手册》里规定的编码规范。 安装插件安装方法很简单：依次打开IDEA -&gt; File -&gt; Settings -&gt; Plugins， 然后在搜索框里搜索alibaba，第一个就是“Alibaba Java Coding Guidelines”，点击安装即可。安装完成后，重启IDEA生效。 使用插件在代码窗口右键，点击”编码规约扫描“即可启动扫描程序，对不符合阿里编码规范的地方会在底部Event Log窗口展示出来。","categories":[],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"}]},{"title":"安装和配置maven","slug":"maven-setup-for-win10","date":"2020-03-30T09:52:09.000Z","updated":"2023-11-20T02:27:39.772Z","comments":true,"path":"2020/03/30/maven-setup-for-win10/","link":"","permalink":"http://example.com/2020/03/30/maven-setup-for-win10/","excerpt":"","text":"安装完JDK，我们接下来安装maven。maven是java生态系统下的最普及的包管理软件，可以对Java项目进行构建和依赖管理。 下载安装maven注意，maven是基于java构建的一个开源项目，因此安装maven之前需要先安装JDK。 下载首先从maven官网下载最新版maven。 安装maven是绿色软件，无需安装，直接解压即可。建议将maven解压到专门保存可执行程序的目录，比如 D:\\Tools\\apache-maven 这样的。 配置maven配置环境变量首先，新建环境变量 MAVEN_HOME，取值为: D:\\Tools\\apache-maven。（请根据你的maven实际解压目录调整）。然后，编辑环境变量Path，追加%MAVEN_HOME%\\bin。最后，使用mvn -version来测试环境变量是否配置完成。 配置本地仓库目录maven本地仓库默认在C盘，为避免C盘空间不够，建议设置到其他磁盘分区。可如下操作：首先，新建文件夹D:\\Tools\\apache-maven\\repository用作本地仓库。然后，修改配置文件 D:\\Tools\\apache-maven\\conf\\settings.xml的localRepository如下： 1234567&lt;!-- localRepository | The path to the local repository maven will use to store artifacts. | | Default: $&#123;user.home&#125;/.m2/repository&lt;localRepository&gt;/path/to/local/repo&lt;/localRepository&gt;--&gt;&lt;localRepository&gt;D:\\Tools\\apache-maven\\repository&lt;/localRepository&gt; 可执行 mvn help:system 命令检查配置是否生效。 配置远程仓库maven默认的中央仓库在国外，国内访问很慢。可以考虑使用阿里云的远程仓库来替代。首先，在settings.xml文件的mirrors节点下增加如下内容： 123456789&lt;mirrors&gt; &lt;!-- aliyun --&gt; &lt;mirror&gt; &lt;id&gt;alimaven&lt;/id&gt; &lt;name&gt;aliyun maven&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/repositories/central/&lt;/url&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;/mirror&gt;&lt;/mirrors&gt; 可再次执行 mvn help:system 命令检查远程仓库配置是否生效。","categories":[],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"}]},{"title":"安装配置java","slug":"jdk-setup-for-win10","date":"2020-03-30T08:34:00.000Z","updated":"2023-11-20T02:27:39.771Z","comments":true,"path":"2020/03/30/jdk-setup-for-win10/","link":"","permalink":"http://example.com/2020/03/30/jdk-setup-for-win10/","excerpt":"","text":"java的安装配置比较简单。步骤如下： 安装java从Oracle官网下载最新版本，直接安装即可。 配置java右键“我的电脑“选择”属性”，打开左侧菜单左下方的”高级系统设置“，再点击”环境变量(N)…“，完成以下两个步骤: 新建环境变量 JAVA_HOME新建-&gt;变量名”JAVA_HOME”，变量值C:\\Java\\jdk1.8.0_05（即JDK的安装路径） 设置环境变量 Path编辑-&gt;变量名”Path”，在原变量值的最后面加上 %JAVA_HOME%\\bin然后，一路确定保存即可。 测试验证打开 cmd，输入java -version 观察命令是否有效，以及版本号是否跟我们安装的版本一致。再输入javac -version检查命令是否存在，以及版本号是否正确。","categories":[],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"}]},{"title":"一步步打造高效coding环境 - git的安装和配置","slug":"git-setup-and-basic-configuration-for-win10","date":"2020-03-30T08:05:01.000Z","updated":"2023-11-20T02:27:39.763Z","comments":true,"path":"2020/03/30/git-setup-and-basic-configuration-for-win10/","link":"","permalink":"http://example.com/2020/03/30/git-setup-and-basic-configuration-for-win10/","excerpt":"","text":"安装git从git官方下载。安装时一路next即可。 配置git 配置user和email账号 12git config --global user.name &quot;your name&quot;git config --global user.email &quot;your email address&quot; 创建SSH key 1ssh-keygen -t rsa -C &quot;your email address&quot; 以上命令将在用户目录下生成一个隐藏目录.ssh，里边有id_rsa和id_rsa.pub两个密钥文件。这两个文件就是本机SSH的密钥对，前者是私钥，务必保密，后者是公钥，可以放心告诉其他人。 关联GitHub登录GitHub，点击右上角用户头像打开settings -&gt; SSH and GPG keys页面，点击 Add SSH Key,将上一步生成的公钥id_rsa.pub文件内容拷贝到输入框，点Add Key保存即可。","categories":[],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"},{"name":"Git","slug":"Git","permalink":"http://example.com/tags/Git/"}]},{"title":"2020年新电脑常用软件清单","slug":"most-common-softwares-for-win10","date":"2020-03-30T05:24:03.000Z","updated":"2023-11-20T02:27:39.773Z","comments":true,"path":"2020/03/30/most-common-softwares-for-win10/","link":"","permalink":"http://example.com/2020/03/30/most-common-softwares-for-win10/","excerpt":"","text":"大家都知道，新买的电脑只提供最基础的Win10系统程序，要满足我们日常使用，往往需要安装一大堆软件。找软件、装软件的过程索然无味，而且通常需要耗费大量时间。笔者最近就被新电脑折腾得够呛，因此基于自身认知和立场，整理出一份常用的软件清单，抛砖引玉，供大家参考。 系统基础在畅快折腾之前，有必要安装一些基本的系统工具来扩展和优化系统的使用体验。 1. 应用市场&#x2F;软件商店应用市场又叫软件商店，它好比一个大集市，里边的软件应有尽有，有了应用市场，我们就不用到处费力的找软件的官网，再一个一个下载了。因此强烈建议优先安装应用市场，再通过应用市场安装其他软件。应用商店可选择第三方大牌的，也可以使用品牌电脑自带的。 腾讯应用宝 或 360软件管家笔者为了图省事，直接使用了联想自带的联想软件商店，跟上面两款功能都差不多。 2. 硬件驱动新电脑自身不缺驱动，然而常常需要外接打印机等外设。这时候可以选择安装： 驱动精灵 3. 安全防护众所周知，针对Windows系统的病毒、木马很多，所以有必要安装一款合适的网络安全防护软件。可以选择综合性的杀毒+防火墙，如： 腾讯电脑管家 或 360电脑管家也可以安装专门的杀毒软件，如： 金山毒霸 或 Macfee 4. 输入法不用纠结了，直接搜狗输入法即可。话说，微软自带的输入法也不错。 5. 文件管理文件查找工具墙裂推荐 everything， 小巧快速，比windows任务管理器好用一千倍。 压缩&#x2F;解压工具以前用过很长时间的winrar，因为没购买License，一直被winrar弹出的各种广告骚扰。新电脑我果断安装了免费的7zip，轻量小巧且无存在感，比较符合这种工具软件的定位。 音视频播放视频播放器太多了，暴风影音、QQ影音、PotPlayer等随便选一个即可。能播放大部分格式的视频，甚至快过气的DVD。音频播放一般不需要安装特定的软件，视频播放器就可以直接代劳了。 上网冲浪网络时代，一台不联网的电脑，跟废品没多大差别。很多人买电脑的主要动机就是上网冲浪，包括查资料，追剧看电影，打游戏等等。 1. 浏览器不必说了，chrome是首选。因为其他各种知名浏览器，如360急速浏览器、QQ浏览器，大多是对chrome的同胞兄弟chromium开源项目的封装和扩展。 2. 网络视频大家看网剧，通常都有喜欢的特定平台应用，比如腾讯视频、爱奇艺、优酷PC客户端、搜狐视频、PP视频、芒果TV等。可根据自身喜好安装。 3. 聊天通讯以下两大利器没得说，都是必装的： 微信电脑版 QQ 或 TIM 4. 网络存储首选 百度网盘。 5. 网络下载我一般只用 迅雷。 6. 邮件收发推荐 foxmail。没错，就是微信之父张小龙做的那个。 高效办公常用办公软件。 1. 办公套件不必说，以下两者功能几乎一模一样，完全可相互替代。二选一即可： Microsoft Office WPS Office 2. 远程办公 阿里的钉钉 头条的飞书 腾讯的TIM，以及比较古老的RTX 3. 远程协助屏幕远程协助推荐 team view。 上面这些软件，基本上覆盖了大家日常上网和办公的高频场景，日常使用应该问题不大了。","categories":[],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"}]},{"title":"权限控制的相关概念辨析","slug":"concepts-about-authentication","date":"2020-03-05T04:58:01.000Z","updated":"2020-03-30T08:30:12.000Z","comments":true,"path":"2020/03/05/concepts-about-authentication/","link":"","permalink":"http://example.com/2020/03/05/concepts-about-authentication/","excerpt":"","text":"我们做后端开发，权限控制是绕不开的话题。几乎所有后台系统都需要权限控制模块。权限控制涉及的概念不多，但容易混淆，这里尝试简单梳理一下。为了便于大家理解，我们结合案例来加以说明。 什么是权限控制?某个主体(subject)对某个客体(object)需要实施某种操作(operation)，系统对这种操作的限制就是权限控制。权限控制涉及三个概念： **主体(subject)**：可以拥有权限的概念对象，比如 用户、角色、岗位、部门等。 **客体(object)**：可以被用来进行权限控制的概念对象，比如 文件、菜单、功能、操作等。 **操作(operation)**：主体对客体进行的访问动作，比如 读、写、执行、查询、修改、新增、删除等。 主体能够做什么，就是权限。权限可以细分为不同的能力。比如，在Linux文件系统中，文件具备读、写、执行三种能力。 要充分理解权限控制，需要仔细分辨以下几组概念。 认证 和 授权 访问 和 验证 操作权限 和 数据权限 认证(Authentication) VS 授权(Authorization)认证是识别操作者是谁的过程，解决Who am I的问题。授权是识别操作者能够做什么事，解决What can I do的问题。 认证是进入系统的第一步，通常就是指系统中的“登录”这一步。认证的常见实现方式有：表单验证、Http Basic验证、OAuth2等。在做授权之前，需要先完成认证。举个例子，我要在Github中新建一个project，第一步要做的就是登录Github，完成用户鉴权，让Github知道我是谁，然后Github才能判断我是否有权限创建一个project。 认证只关注我是谁，不管后面的业务权限如何分配。通过认证进入系统的用户，能够做什么事，则交给授权来处理。 访问(Access) VS 验证(Validation)访问和验证可以看做是授权的两个步骤。访问解决Can I call this operation的问题，验证解决Can I access the data behind this operation的问题。对于接口来说，我能不能调用这个接口，是访问问题，它与数据无关，可以在网关层拦截。而我能够调用这个接口，但能不能操作接口后面的数据，则需要验证。再拿Github举例，假定我要删除一个project。首先，我作为登陆用户，可以访问删除project接口，但我只能删除属于我的项目，不能删除别人的项目，这就是验证要做的工作。验证一般需要在接口的业务逻辑层实现。 操作权限 VS 数据权限操作权限 就是控制用户可以访问的操作。数据权限则控制被访问数据的可见范围。实际上，访问 和 验证 就分别对应了 操作权限 和 数据权限。 我们一般的权限管理系统，都是针对操作权限给出的解决方案。目前比较成熟的有 Apache Shiro、Spring Security等基于RBAC模型的框架。而对于数据权限，由于跟业务结合过于紧密，目前尚无统一的成熟框架。 总结本文介绍了权限控制相关的核心概念，并对认证和授权、访问和验证、操作权限和数据权限这几组容易混淆的概念做了澄清。希望能够帮助大家在做权限控制系统设计时少走弯路。","categories":[],"tags":[{"name":"Architecture","slug":"Architecture","permalink":"http://example.com/tags/Architecture/"}]},{"title":"如何理解编程接口的幂等性？","slug":"how-to-understand-idempotence-in-programing","date":"2020-03-04T16:58:03.000Z","updated":"2020-03-30T08:30:12.000Z","comments":true,"path":"2020/03/05/how-to-understand-idempotence-in-programing/","link":"","permalink":"http://example.com/2020/03/05/how-to-understand-idempotence-in-programing/","excerpt":"","text":"幂等性是编程中一个很重要的概念。特别是我们在设计编程接口时，往往需要考虑接口是否满足幂等性。那么，什么是幂等性呢？幂等性具体应用于哪些场景？实现幂等性有哪些可行的方案？本文一一为您揭秘。 什么是幂等性幂等原本是一个数学概念，用数学公式表示为： 1f(f(x)) = f(x) 引入到计算机编程领域，幂等性是指客户端对服务端接口调用一次和调用多次，对服务端状态的影响是相同的。对于HTTP请求，一次请求和多次请求，如果对被请求资源本身的影响完全相同，则可认为请求是幂等的。同样地，对于一个微服务接口，如果多次调用和一次调用的效果一样，则认为这个接口是幂等的。我们用幂等性的上述定义来检查数据库的增删改查。显然，查询和删除是幂等的。新增和更新操作，则不是幂等的。举反例如下： 新增客户记录时，每执行一次insert操作，都会在数据库表中添加一条记录。 更新文章浏览量时，需要在原有浏览量数值上执行+1操作，每执行一次，浏览量数值都会随之改变。 幂等是服务端对外的一种承诺，承诺只要调用服务端成功，无论客户端调用多少次，都不用担心因重复调用打乱服务端的状态。 什么场景下需要幂等性 不允许重复提交时。 比如电商系统下订单时，用户重复点击下单按钮，后台应避免重复下单、重复扣款。 客户端引入失败重试机制时。在某些情况下，服务端执行操作成功而未来得及把操作结果返回给客户端，客户端误认为服务端操作失败，自动发起重试。 如何实现幂等性实现幂等性，总体思路就是先判断再插入&#x2F;更新。也就是check if exist then insert和check if not updated then update类似的操作。这类操作往往不是原子的，需要加锁。具体有以下几种方案： 使用唯一索引适用于业务上要求只存在一条记录的数据表，比如用手机号来作为客户的唯一标识，则针对手机号建立唯一索引，这样在插入相同手机号的客户记录时，数据库就会报错并回滚插入操作，从而保证幂等性。 token校验借助外部系统存储的token来判断是否重复提交。具体做法是，服务端先生成一个token保存下来，然后发给客户端使用。客户端在提交时，请求中必须带上该token。服务端收到客户端请求后，在执行具体操作前，先校验客户端传入的token，看是否和服务端已存储的token一致。若一致则表明是第一次请求，可以开绿灯放行，并在操作完成后删除或更新token。若不一致或未找到，则认为是重复提交，不予放行。我们常见的csrf_token就是为防止表单重复提交而使用的。 悲观锁悲观锁一般配合事务一起使用，用于记录更新频繁的场景。在更新某条记录前，需要先使用select ... where id=111 for update语法来对记录加锁，然后再执行更新操作。 乐观锁乐观锁只需要在更新数据的瞬间锁表，往往比悲观锁更高效。一般用增加记录版本号的方式来实现乐观锁。比如下面这个微博计数表： weibo_id repost_count version 1001 37 4 每次转发，都需要将转发数+1。这里我们用version字段来保存记录版本号。更新时，为保证幂等性，需执行如下SQL: 1update t_weibo_count set repost_count=repost_count+1, version=version+1 where id=1001 and version=4 这样，如果是第一次请求，version匹配，更新成功，version+1。而后续的请求，无论执行多少次，因为version在第一次请求后已经+1，和SQL中的version对不上，因此更新不会被执行。 分布式锁分布式锁可以变相地认为是一种token校验机制。业务系统在插入或更新数据前，需要先获得锁。操作完成后，需要释放锁。在锁定期间，其他客户端只能等待。分布式锁一般用redis和zookeeper实现。 有限状态机有些领域对象比如订单，它的状态较为固定，转化途径也比较确定。我们在构造订单更新SQL时，可以带上订单状态字段，类似上面乐观锁的情况。若订单状态不匹配，则认为是重复操作，不予执行。 总结幂等性规定多次操作和一次操作对系统状态的影响是想同的。幂等性同时也是接口对外部调用方的一种承诺。在接口和系统设计中，我们需要充分衡量某个接口是否需要实现成幂等性的。实现幂等性的主要思路就是先判断再插入&#x2F;更新，可通过判断唯一索引、单次有效token、是否有锁、状态是否匹配等方式来识别并无视重复操作，达到幂等性的要求。","categories":[],"tags":[{"name":"API","slug":"API","permalink":"http://example.com/tags/API/"},{"name":"Programing","slug":"Programing","permalink":"http://example.com/tags/Programing/"}]},{"title":"使用defaultdict精简Python代码","slug":"python-use-defaultdict-to-reduce-code","date":"2020-02-26T14:27:00.000Z","updated":"2020-03-30T08:30:12.000Z","comments":true,"path":"2020/02/26/python-use-defaultdict-to-reduce-code/","link":"","permalink":"http://example.com/2020/02/26/python-use-defaultdict-to-reduce-code/","excerpt":"","text":"普通dict实现计数统计我们常常用Python的dict来做简单的计数统计。先看下面一段代码： 123456789names = [&#x27;alice&#x27;,&#x27;bob&#x27;,&#x27;cindy&#x27;,&#x27;ocre&#x27;,&#x27;alice&#x27;,&#x27;ocre&#x27;,&#x27;ocre&#x27;,&#x27;cindy&#x27;,&#x27;tom&#x27;]name_counts = &#123;&#125;for name in names: if name not in counts: name_counts[name] = 1 else: name_counts[name] += 1print(name_counts) 这段代码能够统计出每个名字出现的次数。这里我们使用了普通的dict结构names_counts来保存名字和出现次数的映射关系。我们知道，如果直接访问字典中不存在的键，会抛出KeyError异常。比如： 123456&gt;&gt;&gt; name_counts = &#123;&#125;&gt;&gt;&gt; name_counts[&#x27;ocre&#x27;] += 1Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;KeyError: &#x27;ocre&#x27;&gt;&gt;&gt; 为了避免KeyError异常，通常需要使用一个if name in name_counts: ... else ...的代码段来检查词典中是否存在特定的键。如果键已经存在，则直接累加操作，如果不存在，则先赋一个初始值。 引入defaultdict来简化代码对于有代码洁癖的猿来说，这样的代码仍然有一股坏味道。我们可以用defaultdict来简化一下。简化后的代码如下： 12345678from collections import defaultdictnames = [&#x27;alice&#x27;,&#x27;bob&#x27;,&#x27;cindy&#x27;,&#x27;ocre&#x27;,&#x27;alice&#x27;,&#x27;ocre&#x27;,&#x27;ocre&#x27;,&#x27;cindy&#x27;,&#x27;tom&#x27;]name_counts = defaultdict(int)for name in names: name_counts[name] +=1 print(name_counts) 可见，在引入defaultdict后，烦人的if-else被干掉了。（BTW， 统计代码还可以利用其他方法进一步简化，参考我的另一篇博文：Python中实现计数统计的4种方法） 引申：如何构造defaultdict？这里我们使用了defaultdict来代替普通dict，来给name_counts中不存在的键设置默认值，默认值由defaultdict()的第一个参数确定。 构造defaultdict，需传递一个工厂函数作为参数： 1mydict = collections.defaultdict( factory_function ) 这里的工厂函数，可以是普通类型，比如 list,set,str,int等，当访问一个不存在键不存在时，返回这些类型的默认值，比如： 1234567891011121314151617&gt;&gt;&gt; from collections import defaultdict&gt;&gt;&gt;&gt;&gt;&gt; d1 = defaultdict(int)&gt;&gt;&gt; d2 = defaultdict(list)&gt;&gt;&gt; d3 = defaultdict(set)&gt;&gt;&gt; d4 = defaultdict(str)&gt;&gt;&gt; d1defaultdict(&lt;class &#x27;int&#x27;&gt;, &#123;&#125;)&gt;&gt;&gt; d1[&#x27;key&#x27;]0&gt;&gt;&gt; d2[&#x27;key&#x27;][]&gt;&gt;&gt; d3[&#x27;key&#x27;]set()&gt;&gt;&gt; d4[&#x27;key&#x27;]&#x27;&#x27;&gt;&gt;&gt; 工厂函数也可以是普通的无参函数，比如： 1234567891011&gt;&gt;&gt; from collections import defaultdict&gt;&gt;&gt;&gt;&gt;&gt; def factory_func():... return []...&gt;&gt;&gt; d5 = defaultdict(factory_func)&gt;&gt;&gt; d5defaultdict(&lt;function factory_func at 0x0000027817B3F378&gt;, &#123;&#125;)&gt;&gt;&gt; d5[&#x27;ocre&#x27;][]&gt;&gt;&gt; 工厂函数还可以用lambda表达式（匿名函数）来代替，比如： 12345678&gt;&gt;&gt; from collections import defaultdict&gt;&gt;&gt;&gt;&gt;&gt; d6 = defaultdict(lambda : 0)&gt;&gt;&gt; d6defaultdict(&lt;function &lt;lambda&gt; at 0x0000027817C2E268&gt;, &#123;&#125;)&gt;&gt;&gt; d6[&#x27;ocre&#x27;]0&gt;&gt;&gt;","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"}]},{"title":"Python中实现计数统计的4种方法","slug":"four-ways-to-count-in-python","date":"2020-02-26T11:10:00.000Z","updated":"2020-03-30T08:30:12.000Z","comments":true,"path":"2020/02/26/four-ways-to-count-in-python/","link":"","permalink":"http://example.com/2020/02/26/four-ways-to-count-in-python/","excerpt":"","text":"我们在日常开发过程中经常会遇到这样的需求，统计某个IP的访问次数，统计某个商户的订单数 等等。这类统计统称为计数统计。作为一门优秀的高级语言，Python提供了至少4种方式来方便地实现计数统计。下面我们举例说明。首先给出问题: 给定下面的输入和输出，实现name_count方法。 123456789# Input:names = [&#x27;alice&#x27;,&#x27;bob&#x27;,&#x27;cindy&#x27;,&#x27;ocre&#x27;,&#x27;alice&#x27;,&#x27;ocre&#x27;,&#x27;ocre&#x27;,&#x27;cindy&#x27;,&#x27;tom&#x27;]# Intefaceresult = name_count(names)# Output:&#123;&#x27;alice&#x27;: 2, &#x27;bob&#x27;: 1, &#x27;cindy&#x27;: 2, &#x27;ocre&#x27;: 3, &#x27;tom&#x27;: 1&#125; 1. 使用dict字典实现计数统计12345678def name_count(names): name_counts = &#123;&#125; for name in names: if name not in counts: name_counts[name] = 1 else: name_counts[name] += 1 return name_counts 2. 使用defaultdict实现计数统计1234567from collections import defaultdictdef name_count(names): name_counts = defaultdict(lambda: 0) for name in names: name_counts[name] += 1 return name_counts 3. 使用set和list实现计数统计123456def name_count(names): name_set = set(names) name_list = [] for name in name_set: name_list.append(name, names.count(name)) return name_list 4.使用Counter实现计数统计1234from collections import Counterdef name_count(names): return dict(Counter(names)) 可见，使用Counter类的第4种方法代码最简洁。有了以上4种方法，平时面对小规模数据集的计数统计问题时就能够手到擒来了。 更多统计实现方式等待发现！","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"}]},{"title":"Python的*和**运算符是什么意思？有什么区别？","slug":"python-star-operator","date":"2020-02-24T02:12:03.000Z","updated":"2020-03-30T08:30:12.000Z","comments":true,"path":"2020/02/24/python-star-operator/","link":"","permalink":"http://example.com/2020/02/24/python-star-operator/","excerpt":"","text":"看到这么一段Flask代码： 123456view_data = dict( rows = posts[start:end], page = page, has_next_page = has_next_page,)return render_template(&#x27;posts.html&#x27;, **view_data) 代码中最后一行时，发现里边有**这样两个星号连在一起用的语法，不解其意。查阅资料后，才发现星号运算符还是真是神通广大。具体来说，有4种不同用途。 1. 算数运算符* 表示乘法运算， **表示乘方运算。 1234&gt;&gt;&gt; 3 * 26&gt;&gt;&gt; 3 ** 29 2. 序列解包序列解包是Python的一种语法糖，可以用来简化代码。普通的序列解包，要求赋值运算符=左侧的变量个数和右侧的变量值个数相等。示例如下： 12345&gt;&gt;&gt; lat, lon = 108, 33&gt;&gt;&gt; lat108&gt;&gt;&gt; lon33 若=左边的变量个数和右侧的变量值个数不相等，则解包失败报错： 12345&gt;&gt;&gt; a, b = 1, 2, 3Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;ValueError: too many values to unpack (expected 2)&gt;&gt;&gt; 12345678910111213&gt;&gt;&gt; a, b, c = 1, 2Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;ValueError: not enough values to unpack (expected 3, got 2)&gt;&gt;&gt;这时，就可以使用 `*`星号运算符来处理了。`*`运算符将右侧多余的变量值**按顺序合并**成一个序列赋值给`*`标记的变量，用法示例如下:​```python&gt;&gt;&gt; a, *b = 1, 2, 3&gt;&gt;&gt; a1&gt;&gt;&gt; b[2, 3] 12345&gt;&gt;&gt; *a, b = 1, 2, 3&gt;&gt;&gt; a[1, 2]&gt;&gt;&gt; b3 12345&gt;&gt;&gt; a, *b = 1, 2&gt;&gt;&gt; a1&gt;&gt;&gt; b[2] 12345&gt;&gt;&gt; a, *b = 1&gt;&gt;&gt; a1&gt;&gt;&gt; b[] 3. 函数形参*和**都可以用作函数的形参，用来将不定数量的参数传递给一个函数。一个星号用来传递元组tuple，两个星号用来传递字典dict，通常用*args和*kwargs来分别表示。示例如下： 123456&gt;&gt;&gt; def func(a, *args):... print(a, args)...&gt;&gt;&gt; func(1, 2, 3)1 (2, 3)&gt;&gt;&gt; 12345&gt;&gt;&gt; def func(a, **kwargs):... print(a, kwargs)...&gt;&gt;&gt; func(1, lat=108, lon=33)1 &#123;&#x27;lat&#x27;: 108, &#x27;lon&#x27;: 33&#125; 12345&gt;&gt;&gt; def func(*args, **kwargs):... print(args, kwargs)...&gt;&gt;&gt; func(1, 2, 3, name=&#x27;ocre&#x27;, sex=&#x27;male&#x27;)(1, 2, 3) &#123;&#x27;name&#x27;: &#x27;ocre&#x27;, &#x27;sex&#x27;: &#x27;male&#x27;&#125; 4. 函数实参为避免实参过长，可以用*和**对多个参数进行打包，示例如下： 12345678&gt;&gt;&gt; def func(a, **kwargs):... print(a, kwargs)...&gt;&gt;&gt; func(1, name=&#x27;ocre&#x27;, sex=&#x27;male&#x27;)1 &#123;&#x27;name&#x27;: &#x27;ocre&#x27;, &#x27;sex&#x27;: &#x27;male&#x27;&#125;&gt;&gt;&gt; data = &#123;&#x27;name&#x27;:&#x27;ocre&#x27;, &#x27;sex&#x27;:&#x27;male&#x27;&#125;&gt;&gt;&gt; func(1, **data)1 &#123;&#x27;name&#x27;: &#x27;ocre&#x27;, &#x27;sex&#x27;: &#x27;male&#x27;&#125; 本文开头我碰到的情况，就属于最后这种用法。","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"}]},{"title":"修复Hexo中时序图插件hexo-filter-sequence不显示的问题","slug":"show-flowchart-and-sequence-in-hexo","date":"2020-02-20T05:49:51.000Z","updated":"2020-03-30T08:30:12.000Z","comments":true,"path":"2020/02/20/show-flowchart-and-sequence-in-hexo/","link":"","permalink":"http://example.com/2020/02/20/show-flowchart-and-sequence-in-hexo/","excerpt":"","text":"问题描述写Blog时，想展示时序图和流程图，网友给推荐了流程图插件hexo-filter-flowchart和时序图插件hexo-filter-sequence。装上两个插件之后，根据github上的示例测试了一下，发现在Hexo中时序图无法显示。 问题处理根据这篇博文的指示，顺利解决了这个问题。修改过程记录如下： 修改node_modules\\hexo-filter-sequence\\index.js文件，flowchart改为sequence，另外去掉snap.svg.js添加rahpael.js，具体改动部分如下：1234567891011hexo.config.sequence = assign(&#123; webfont: &#x27;https://cdnjs.cloudflare.com/ajax/libs/webfont/1.6.27/webfontloader.js&#x27;, // snap: &#x27;https://cdnjs.cloudflare.com/ajax/libs/snap.svg/0.4.1/snap.svg-min.js&#x27;, raphael: &#x27;https://cdn.bootcss.com/raphael/2.3.0/raphael.min.js&#x27;, underscore: &#x27;https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.8.3/underscore-min.js&#x27;, sequence: &#x27;https://cdnjs.cloudflare.com/ajax/libs/js-sequence-diagrams/1.0.6/sequence-diagram-min.js&#x27;, css: &#x27;&#x27;, options: &#123; theme: &#x27;simple&#x27; &#125;&#125;, hexo.config.sequence); 修改node_modules\\hexo-filter-sequence\\lib\\renderer.js文件第25行左右，flowchart改为sequence，config.snap改为config.rahpael，改动后的内容如下：12345678if (sequences.length) &#123; var config = this.config.sequence; // resources data.content += &#x27;&lt;script src=&quot;&#x27; + config.webfont + &#x27;&quot;&gt;&lt;/script&gt;&#x27;; // data.content += &#x27;&lt;script src=&quot;&#x27; + config.snap + &#x27;&quot;&gt;&lt;/script&gt;&#x27;; data.content += &#x27;&lt;script src=&quot;&#x27; + config.raphael + &#x27;&quot;&gt;&lt;/script&gt;&#x27;; data.content += &#x27;&lt;script src=&quot;&#x27; + config.underscore + &#x27;&quot;&gt;&lt;/script&gt;&#x27;; data.content += &#x27;&lt;script src=&quot;&#x27; + config.sequence + &#x27;&quot;&gt;&lt;/script&gt;&#x27;; hexo的_config.yml配置文件中启用国内CDN（默认的cdnjs.cloudflare.com国内可能无法访问），修改如下：1234567891011# sequence configsequence: webfont: &#x27;https://cdn.bootcss.com/webfont/1.6.28/webfontloader.js&#x27; raphael: &#x27;https://cdn.bootcss.com/raphael/2.3.0/raphael.min.js&#x27; # snap: &#x27;https://cdn.bootcss.com/snap.svg/0.5.1/snap.svg-min.js&#x27; underscore: &#x27;https://cdn.bootcss.com/underscore.js/1.9.1/underscore-min.js&#x27; sequence: &#x27;https://cdn.bootcss.com/js-sequence-diagrams/1.0.6/sequence-diagram-min.js&#x27; css: # optional, the url for css, such as hand drawn theme options: theme: css_class: 123456# flowchart configflowchart: raphael: &#x27;https://cdn.bootcss.com/raphael/2.3.0/raphael.min.js&#x27; flowchart: &#x27;https://cdn.bootcss.com/flowchart/1.12.2/flowchart.min.js&#x27; options: # options used for `drawSVG` 修改完成后，依次执行hexo clean,hexo g,hexo d重新部署，问题解决。 附测试代码： 123456Client-&gt;Server: requestNote right of Server: WSGIServer-&gt;Application: app_callable(environ, start_response)Application-&gt;Server: start_response(status, response_headers, exc_info=None)Application-&gt;Server: return iteratorServer-&gt;Client: response 展示效果如下： 123456Client-&gt;Server: requestNote right of Server: WSGIServer-&gt;Application: app_callable(environ, start_response)Application-&gt;Server: start_response(status, response_headers, exc_info=None)Application-&gt;Server: return iteratorServer-&gt;Client: response","categories":[],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://example.com/tags/Hexo/"}]},{"title":"Python的WSGI是什么？","slug":"what-is-wsgi","date":"2020-02-20T00:26:10.000Z","updated":"2020-03-30T08:30:12.000Z","comments":true,"path":"2020/02/20/what-is-wsgi/","link":"","permalink":"http://example.com/2020/02/20/what-is-wsgi/","excerpt":"","text":"什么是WSGI？WSGI的全称是Web Server Gateway Interface，即Web服务器网管接口。注意，它不是一个服务器、不是Python模块、不是框架、也不是API程序，它不是任何一种软件，而仅仅是Python语言针对Web服务器和Web应用程序之间通用接口的规范（PEP 3333）。符合WSGI规范的应用程序可以运行在任何符合该规范的Web服务器上。 WSGI规范WSGI规范十分简单。下面这张时序图展示了WSGI所处的位置，以及调用规则。 123456Client-&gt;Server: requestNote right of Server: WSGIServer-&gt;Application: app_callable(environ, start_response)Application-&gt;Server: start_response(status, response_headers, exc_info=None)Application-&gt;Server: return iteratorServer-&gt;Client: response 从上图可见，WSGI处于Server和Application之间。Server端负责实现start_response这个callback，Application端负责实现app_callable这个callable对象。其中，app_callable接受两个参数： environ: 包含有Server提供的所有请求信息的一个dict对象。 start_response: Server端提供的回调方法，Application端可以通过它发送HTTP状态码和HTTP头部信息。app_callable最后返回一个封装成可迭代对象的响应体字符串。 以下是一个简单的app_callable实现： 12345678def app_callable(environ, start_response): response_body = &#x27;Request method: %s&#x27; % environ[&#x27;REQUEST_METHOD&#x27;] status = &#x27;200 OK&#x27; response_headers = [(&#x27;Content-type&#x27;, &#x27;text/plain&#x27;)] start_response(status, response_headers) return [response_body] WSGI的Application端可以支持堆栈式调用。调用栈中间的Application又被称为Middleware。Middleware同时扮演Server和Application两种角色，因此需要同时实现WSGI两端的接口。下图是对Middleware所处位置的一个简单表示： 123456789101112131415Note right of Server: WSGIServer-&gt;Application1: Note right of Application1: WSGiMiddleware1-&gt;Application1: Note right of Middleware1: WSGIApplication1-&gt;Middleware2: Note right of Middleware2: WSGIMiddleware2-&gt;Middleware3: Note right of Middleware3: WSGIMiddleware3-&gt;Application2: Application2-&gt;Middleware3: Middleware3-&gt;Middleware2: Middleware2-&gt;Middleware1: Middleware1-&gt;Application1: WSGI实现示例在生产环境，一般用Apache+mod_wsgi来作为Server端的标准实现。这里我们使用Python内置的WSGI服务器wsgiref来实现一个简单示例。编写一个wsgi_test.py文件，内容如下： 1234567891011121314151617181920212223#!/usr/bin/env python# -*- coding: utf-8 -*-&quot;&quot;&quot;test wsgi&quot;&quot;&quot;# wsgi_test.pyfrom wsgiref.simple_server import make_serverdef application (environ, start_response): status = &#x27;200 OK&#x27; response_headers = [(&#x27;Content-Type&#x27;, &#x27;text/plain&#x27;)] start_response(status, response_headers) return [f&#x27;Request &#123;environ[&quot;REQUEST_METHOD&quot;]&#125;&#x27; f&#x27; &#123;environ[&quot;PATH_INFO&quot;]&#125; has been&#x27; f&#x27; processed\\r\\n&#x27;.encode(&#x27;utf-8&#x27;)]server = make_server(&#x27;localhost&#x27;, 8000, application)# Wait for a single request, serve it and quitprint(&#x27;Serving HTTP on port 8000...&#x27;)server.serve_forever() 接着在命令行运行python wsgi_test.py，启动WSGI服务器。然后打开浏览器，输入http://localhost:8000/ 就可以看到效果了。","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"}]},{"title":"Scrapy中的JSON Lines文本格式是什么鬼？","slug":"json-lines","date":"2020-02-18T13:38:10.000Z","updated":"2020-03-30T08:30:12.000Z","comments":true,"path":"2020/02/18/json-lines/","link":"","permalink":"http://example.com/2020/02/18/json-lines/","excerpt":"","text":"什么是JSON LinesJSON Lines是一种类似JSON的文本格式。它采用\\\\n作为分隔符存储多个JSON对象的列表，每个JSON对象仍然使用JSON格式表示。它有三个硬性约束：1.使用UTF-8编码。2.每一行都是一个有效的JSON对象。3.行分隔符为\\\\n。 JSON Line文件的建议扩展名是.jsonl。一般建议使用gzip或者bzip2进行压缩，生成.jsonl.gz或.jsonl.bz2文件，进一步节省存储空间。 为什么使用JSON Lines我们平时习惯用CSV和JSON文本格式来存储列表类对象。同样的数据，CSV相比JSON更简洁，更节省空间，但是可读性很差（数据列分隔符随便定义没有统一标准，数据列定义只在第一行体现，不够直观），并且不支持嵌套数据。而JSON格式的可读性更好，能够支持嵌套数据，但是在存储数据列表时，需要识别数组首尾的[和]，涉及到读取、解析、存储整个文件，不适合大文件的高效存取。因此，JSON Lines应运而生。采用 JSON Lines 保存数据集，则文件中每一行就是一条JSON数据，可以一边读取一边解析、操作。而在添加数据时，只需要 append 数据到文件尾部即可。 示例一个简单的JSON Lines格式文件内容如下： 1234&#123;&quot;name&quot;: &quot;Gilbert&quot;, &quot;wins&quot;: [[&quot;straight&quot;, &quot;7♣&quot;], [&quot;one pair&quot;, &quot;10♥&quot;]]&#125;&#123;&quot;name&quot;: &quot;Alexa&quot;, &quot;wins&quot;: [[&quot;two pair&quot;, &quot;4♠&quot;], [&quot;two pair&quot;, &quot;9♠&quot;]]&#125;&#123;&quot;name&quot;: &quot;May&quot;, &quot;wins&quot;: []&#125;&#123;&quot;name&quot;: &quot;Deloise&quot;, &quot;wins&quot;: [[&quot;three of a kind&quot;, &quot;5♣&quot;]]&#125; 应用场景JSON Lines文本格式由于同时具备可读性和便于流式处理的特点，常常被用于以下场景：1.日志记录2.流数据API3.爬虫数据存储","categories":[],"tags":[{"name":"JSON","slug":"JSON","permalink":"http://example.com/tags/JSON/"},{"name":"Scrapy","slug":"Scrapy","permalink":"http://example.com/tags/Scrapy/"}]},{"title":"Conda简介及基本用法","slug":"conda-basic-usage","date":"2020-02-18T05:59:10.000Z","updated":"2023-11-20T02:27:39.761Z","comments":true,"path":"2020/02/18/conda-basic-usage/","link":"","permalink":"http://example.com/2020/02/18/conda-basic-usage/","excerpt":"","text":"什么是Conda？Conda是一种通用包管理系统，旨在构建和管理任何语言和任何类型的软件。Conda主要提供包管理和环境管理两种能力。包管理与pip的使用类似，环境管理则允许用户同时安装多个版本的python，并支持快速切换。 Conda常用命令Conda包管理1.查看已安装的所有包: conda list2.查看已安装的特定包：conda list scrapy3.搜索云上的包: conda search scrapy4.安装包: conda install scrapy5.一次安装多个包: conda install numpy pandas scipy6.安装固定版本的包: conda install numpy&#x3D;1.107.从指定频道安装包: conda install scrapy -c conda-forge8.升级一个包: conda update scrapy9.升级全部包: conda upgrade –all Conda环境管理1.查看所有虚拟环境： conda env list2.激活特定环境：activate env_name3.退出环境：deactivate env_name4.创建虚拟环境：conda create -n env_name 5.创建虚拟环境并指定特定Python版本：conda create -n env_name python2&#x3D;2.76.删除虚拟环境：conda env remove -n env_name","categories":[],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"},{"name":"Conda","slug":"Conda","permalink":"http://example.com/tags/Conda/"},{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"}]},{"title":"Scrapy开发环境搭建","slug":"scrapy-startup","date":"2020-02-18T03:49:51.000Z","updated":"2020-03-30T08:30:12.000Z","comments":true,"path":"2020/02/18/scrapy-startup/","link":"","permalink":"http://example.com/2020/02/18/scrapy-startup/","excerpt":"","text":"准备Python3运行环境Scrapy基于Python语言编写，因此运行Scrapy需要先安装Python运行环境。所谓Python运行环境指可以编译执行Python代码的软件集合。已经安装了运行环境的请直接跳过。目前常见的Python运行环境有三种方式：1.直接安装Python32.安装Anaconda3.安装Miniconda 我选择安装Anaconda，因为相对于直接安装Python3，Anaconda提供了更简便强大的包管理和环境管理功能。Anaconda是Python的一个科学计算发行版，支持 Linux, Mac和Windows系统，可以很方便地解决多版本python并存、切换以及各种第三方包安装问题。Anaconda内置了数百个Python标准库，装上Anaconda，就相当于把Python和一些如Numpy、Pandas、Scrip、Matplotlib等常用的库自动安装好了，使得安装比常规python安装要容易。因而建议直接安装Anaconda。直接从官网下载最新版Anaconda社区版安装包安装即可。 当然，喜欢掌控一切的同学可以选择安装Miniconda。Miniconda可以看做是Anaconda的一个精简版。如果拿房子来比喻，Anaconda是精装房，Miniconda是毛坯房。Miniconda去掉了Anaconda内置的大量常用工具包，只提供一个较为纯净的Python运行环境和Conda（Conda是一种通用包管理系统，旨在构建和管理任何语言和任何类型的软件。Conda简介及基本用法）。需要什么包就自己装什么包。 装好Anaconda后，就可以继续安装Scrapy了。 安装Scrapy按惯例，参照Scrapy官网的建议进行安装。官网提供了conda和pip两种安装方式，一条命令即可搞定。 12# 选择conda方式安装conda install scrapy -c conda-forge 12# 选择pip方式安装pip install scrapy 安装好Scrapy后，就可以创建Scrapy项目了。 创建Scrapy项目首先进入将要存放Scrapy工程代码的目录，执行如下命令即可创建一个名为tutorial的工程。 1scrapy startproject tutorial 我在执行上面命令的时候系统报错了，提示Fatal error in launcher: Unable to create process using &#39;&quot;d:\\bld\\scrapy_1572360424769\\_h_env\\python.exe&quot;。改为执行以下命令即可： 1python -m scrapy startproject tutorial 执行成功后，将在当前目录下创建一个新的tutorial目录，目录结构如下： 12345678910tutorial/ scrapy.cfg # Scrapy的部署配置文件 tutorial/ # Scrapy项目的Python模块 __init__.py items.py # items definition file middlewares.py # project middlewares file pipelines.py # project pipelines file settings.py # project settings file spiders/ # spider子模块 __init__.py 接下来就可以编写自己的spider类了。请参考Scrapy官方的Tutorial。 Scrapy常见命令 创建spider（基于basic模板）：1python -m scrapy genspider quotes &quot;quotes.toscrape.com&quot; 运行spider：1python -m scrapy crawl quotes 或者1python -m scrapy runspider quotes.py 测试提取数据：1python -m scrapy shell &#x27;http://quotes.toscrape.com/page/1/&#x27; 导出数据到JSON文档：1python -m scrapy crawl quotes -o quotes.json","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"},{"name":"Scrapy","slug":"Scrapy","permalink":"http://example.com/tags/Scrapy/"}]},{"title":"阿里云RDS Mysql物理备份文件恢复到自建数据库","slug":"mysql-data-recovery-from-physical-db-files","date":"2020-01-19T12:30:01.000Z","updated":"2023-11-20T02:27:39.774Z","comments":true,"path":"2020/01/19/mysql-data-recovery-from-physical-db-files/","link":"","permalink":"http://example.com/2020/01/19/mysql-data-recovery-from-physical-db-files/","excerpt":"","text":"今天需要将Mysql数据从RDS迁移到ECS云服务器上自建Mysql中。因我的RDS已到期停机，无法通过mysqldump等命令导出数据，好在RDS给提供了数据库物理文件的每日全量备份，姑且用之。整个操作流程可分为三个：下载解压物理文件备份， 使用Percona XtraBackup恢复数据，启动MySQL并校验数据。 下载解压备份文件在RDS的备份恢复界面找到最新备份: 获取下载地址并使用wget或curl下载到ECS机器上。下载得到的是一个tar.gz压缩包，使用如下命令解压缩： 123tar -izxvf &#x27;&lt;backup_file_name.tar.gz&gt;&#x27; -C &#x27;&lt;MySQL data dir&gt;&#x27;# for example，my command is:# tar -izxvf /mnt/backup_data/db_backup/rds_data_20200118.tar.gz -C /var/lib/mysql 这里我直接解压到了默认的MySQL数据目录&#x2F;var&#x2F;lib&#x2F;mysql.（我的MySQL是新装的，还没启动，因此默认数据目录下是空的）。 使用Percona XtraBackup恢复数据首先，需要安装Percona XtraBackup。这里需要注意，不同的MySQL版本，需要不同的Percona XtraBackup版本。比如，MySQL 5.6及之前的版本需要安装 Percona XtraBackup 2.3，MySQL 5.7版本需要安装 Percona XtraBackup 2.4，MySQL 8.0版本需要安装 Percona XtraBackup 8.0。安装完毕后，执行如下命令，恢复解压后的文件： 1innobackupex --defaults-file=/var/lib/mysql/backup-my.cnf --apply-log /var/lib/mysql 若恢复成功，则会提示类似文字： 启动MySQL并校验数据设置正确的文件属主： 1chown -R mysql:mysql /var/lib/mysql 执行如下命令启动mysql： 1service mysql restart 使用各种客户端软件连接MySQL，根据业务情况校验各数据库、各表的数据。 参考文档 RDS MySQL 物理备份文件恢复到自建数据库 - 阿里云","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"}]},{"title":"CentOS 7 Yum安装低版本的MySQL（MySQL 5.6）","slug":"how-to-yum-install-old-version-mysql","date":"2020-01-19T10:10:15.000Z","updated":"2020-03-30T08:30:12.000Z","comments":true,"path":"2020/01/19/how-to-yum-install-old-version-mysql/","link":"","permalink":"http://example.com/2020/01/19/how-to-yum-install-old-version-mysql/","excerpt":"","text":"我有一台阿里云RDS数据库到期了，考虑到目前业务规模，续费的性价比太低，不如在自己的ECS云服务器上装MySQL再把数据迁移过来。为了避免数据文件迁移时产生兼容性问题，要尽量保证自建MySQL跟RDS上的MySQL的主版本保持一致。我的RDS上MySQL是5.6版本，而Mysql Yum仓库默认已经升级到8.0版本了，在Yum安装前需要做一些额外设置。 添加MySQL Yum源首先，从 MySQL官方Yum仓库选择适合当前CentOS版本的rpm包。 下载到ECS云服务器上。 1wget -i -c https://dev.mysql.com/get/mysql80-community-release-el7-3.noarch.rpm 添加Yum仓库。 1sudo rpm -Uvh mysql80-community-release-el7-3.noarch.rpm 设置默认安装版本查询可安装的MySQL版本： 1yum repolist all | grep mysql 图中enabled状态的版本为Yum安装时的默认版本。如果默认版本不是5.6，需手工编辑/etc/yum.repos.d/mysql-community.repo文件来调整所需版本的启用状态，比如，要想安装5.6版本，则需要将以下代表5.6版本的代码段的enabled设置为1，同时将其他代码片段的enabled值置0。 1234567# Enable to use MySQL 5.6[mysql56-community]name=MySQL 5.6 Community Serverbaseurl=http://repo.mysql.com/yum/mysql-5.6-community/el/7/$basearch/enabled=1gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-mysql 调整完毕后，可重新执行yum repolist all | grep mysql命令复查一下，看默认版本是否符合预期。 执行安装MySQL默认版本设置检查无误后，执行以下命令即可安装MySQL： 1sudo yum install mysql-community-server 检查MySQL版本号： 1mysql -V 我这里输出为： 1mysql Ver 14.14 Distrib 5.6.47, for Linux (x86_64) using EditLine wrapper 版本号为5.6.XX，符合预期，安装成功！ 参考资料：A Quick Guide to Using the MySQL Yum Repository","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"},{"name":"Linux","slug":"Linux","permalink":"http://example.com/tags/Linux/"}]},{"title":"Docker简介","slug":"docker-basic-concepts","date":"2020-01-12T05:59:10.000Z","updated":"2020-03-30T08:30:12.000Z","comments":true,"path":"2020/01/12/docker-basic-concepts/","link":"","permalink":"http://example.com/2020/01/12/docker-basic-concepts/","excerpt":"","text":"Docker 基本概念理解Docker, 必须先搞懂以下三个基本概念: 镜像(Image): 相当于一套root文件系统。 容器(Container): 容器是镜像运行的实体，实际上就是一个普通进程。 仓库(Repository): 存储Docker镜像的中心仓库。比如Docker Hub就是公共的镜像仓库。 容器和镜像的关系类似于面向对象语言的类和实例。 Docker 结构图Docker采用C&#x2F;S模式管理远程Docker容器。Docker容器可被创建、启动、停止、删除、暂停。Docker容器通过Docker镜像来创建。","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://example.com/tags/Docker/"}]},{"title":"Hexo引用自己的文章","slug":"how-to-quote-my-old-post-in-hexo","date":"2020-01-07T05:23:29.000Z","updated":"2020-04-01T07:32:26.000Z","comments":true,"path":"2020/01/07/how-to-quote-my-old-post-in-hexo/","link":"","permalink":"http://example.com/2020/01/07/how-to-quote-my-old-post-in-hexo/","excerpt":"","text":"用Hexo写Blog文章时，经常需要引用自己的另一篇文章，如何做呢？可以使用Hexo自带的post_link标签。用法如下： 1&#123;% post_link url_slug show_title %&#125; 其中，url_slug表示Hexo项目source/_posts目录中markdown文件的名字。比如，我有一篇Blog 使用netlify自动发布hexo博客, 它对应的markdown文件是hexo-with-netlify.md, 则url_slug就是hexo-with-netlify。show_title表示你想要在这里显示给用户看的文章标题，可以不用跟原博客标题保持一致。拿刚刚这篇文章来说，我在引用它时，需要输入： 1&#123;% post_link hexo-with-netlify 使用netlify自动发布hexo博客 %&#125;","categories":[],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"}]},{"title":"Apache Shiro简介","slug":"shiro-at-a-glance-01","date":"2020-01-06T10:51:03.000Z","updated":"2020-03-30T08:30:12.000Z","comments":true,"path":"2020/01/06/shiro-at-a-glance-01/","link":"","permalink":"http://example.com/2020/01/06/shiro-at-a-glance-01/","excerpt":"","text":"Shiro是什么？Shiro是Java领域一个开源安全框架，可以为应用程序提供全面的安全管理服务，功能包括但不限于身份认证、授权、Session管理、加密等。Shiro目前隶属于Apache Software Foundation，其主要竞争对手是Spring Security。相对于Spring Security, Shiro更加简单轻便，适合入门使用。 Shiro能做什么？Shiro的核心功能可以用下图表示： 从上图可知，Shiro提供以下四个核心功能： 身份认证: 用户身份认证，通常指用户登陆 授权：即权限验证，处理访问控制 Session管理： 加密服务除了上述四个核心功能外，Shiro还针对不同应用环境提供额外的Feature来简化应用集成： Web支持 Cache 并发 测试 Run as Remeber me Shiro适用于哪些领域？Shiro即可应用于JavaSE环境，用于一般Java程序开发，也适用于JavaEE环境，用于大规模企业级Java应用开发。 Shiro是如何设计的？读书时我习惯先读读作者自序，来了解作者写书时面临的问题以及想要传达给读者的意图。同样的，学习一个新的框架，也可以先花点时间看看框架的历史、设计目标和核心概念。 （未完待续） Shiro极简史Shiro诞生（2020年）已经有17岁了。 （未完待续） Shiro的核心概念（未完待续） Shiro的技术架构（未完待续）","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"},{"name":"Authorization","slug":"Authorization","permalink":"http://example.com/tags/Authorization/"}]},{"title":"Spring IOC 和 DI","slug":"spring-ioc","date":"2019-12-25T03:49:51.000Z","updated":"2020-03-30T08:30:12.000Z","comments":true,"path":"2019/12/25/spring-ioc/","link":"","permalink":"http://example.com/2019/12/25/spring-ioc/","excerpt":"","text":"IOC - 一种编程思想定义 （Inversion of Control) 对象把对其他对象的控制权交给第三方容器（比如Spring），由第三方容器来统一管理对象的生命周期，提供所需的依赖。 控制权：创建、销毁 IOC VS DI 思想 VS 实现方式 处理依赖的第三种方法假定A依赖B，如何处理依赖关系：方法1. 原始做法new B() 12345678910class B &#123; public void doSomeThing() &#123;&#125;&#125;class A &#123; public doSomeThing() &#123; B b = new B(); b.doSomeThing(); &#125;&#125; 方法2. 简单工厂等创造器模式 1234567891011121314151617181920212223242526interface IB &#123; void doSomeThing();&#125;class B1 implements IB &#123;&#125;class B2 implements IB &#123;&#125;class B3 implements IB &#123;&#125;class BFactory &#123; public static IB newB(int type) &#123; if (type == 1) &#123; return new B1(); &#125; else if (type == 2) &#123; return new B2(); &#125; else &#123; return new B3(); &#125; &#125;&#125;class A &#123; public doSomeThing() &#123; IB b = BFactory.newB(1); b.doSomeThing(); &#125;&#125; 方法3. 依赖注入 123456789101112class B &#123; public void doSomeThing() &#123;&#125;&#125;class A &#123; @Autowired private B b; public doSomeThing() &#123; b.doSomeThing(); &#125;&#125; Spring 两大核心思想之一 IOC AOP DI - IOC的实现方式Spring的DI机制降低了业务对象替换的复杂性，提高了组件之间的解耦。 Spring 实现依赖注入的两种方式 属性 setter 方法注入 有参构造函数注入 IOC 容器 - 对象的超级工厂IOC 容器主要作用 对象的实例化、组装和管理 （instantiate、assembly、manage） 为对象注入依赖 （Dependency Injection） Spring Core 就是一个IOC容器在Spring体系结构中，Spring Core牢牢占据C位。 Spring容器抽象视图 Spring如何实现IOC容器对外接口 定义和注册bean 获取bean 核心概念 Bean - Spring容器管理的Java对象。 BeanFactory - 专门用来生成和获取Bean的接口。 ApplicationContext - Spring IOC容器的对外代表（接口）。 BeanDefination - 存储Bean定义的接口。 BeanRegistry - Bean的注册中心。 这里的BeanDefination接口就是xml配置文件中的标签在Spring中的表示形式。 Spring提供的两种IOC容器 BeanFactory - org.springframework.beans.factory.BeanFactory管理Bean的超级工厂。 ApplicationContext - org.springframework.context.ApplicationContext通过继承和组合的方式对BeanFactory做的一层封装。除了具备BeanFactory的能力外，还要负责环境配置管理、生命周期管理、复杂的初始化操作。 BeanFactory和ApplicationContext的关系还又一个StaticListableBeanFactory。 Spring官方文档的对两者关系的简短表述： 1In short, the BeanFactory provides the configuration framework and basic functionality, and the ApplicationContext adds more enterprise-specific functionality. The ApplicationContext is a complete superset of the BeanFactory and is used exclusively in this chapter in descriptions of Spring’s IoC container ApplicationContext的继承结构 Bean的定义bean的属性列表bean的三种定义方式 xml文件中的bean标签 注解 + 扫描 ComponentScan 定义Configuration类，在类中提供 @Bean 方法 xml形式的定义12345678910111213&lt;bean id=&quot;exampleBean&quot; name=&quot;name1, name2, name3&quot; class=&quot;com.javadoop.ExampleBean&quot; scope=&quot;singleton&quot; lazy-init=&quot;true&quot; init-method=&quot;init&quot; destroy-method=&quot;cleanup&quot;&gt; &lt;!-- 可以用下面三种形式指定构造参数 --&gt; &lt;constructor-arg type=&quot;int&quot; value=&quot;7500000&quot;/&gt; &lt;constructor-arg name=&quot;years&quot; value=&quot;7500000&quot;/&gt; &lt;constructor-arg index=&quot;0&quot; value=&quot;7500000&quot;/&gt; &lt;!-- property 的几种情况 --&gt; &lt;property name=&quot;beanOne&quot;&gt; &lt;ref bean=&quot;anotherExampleBean&quot;/&gt; &lt;/property&gt; &lt;property name=&quot;beanTwo&quot; ref=&quot;yetAnotherBean&quot;/&gt; &lt;property name=&quot;integerProperty&quot; value=&quot;1&quot;/&gt;&lt;/bean&gt; 注解形式的定义 + 注解扫描1234567891011121314151617@Controllerpublic class EmployeeController &#123; @Autowired private EmployeeDao employeeDao; public String index() &#123; return &quot;Hello from Spring!&quot;; &#125;&#125;@SpringBootApplication@ComponentScan(basePackages = &quot;com.company.app&quot;)public class MySpringBootApp &#123; public static void main(String[] args) &#123; ApplicationContext context = SpringApplication.run(MySpringBootApp.class, args); &#125;&#125; bean定义、注册、获取的示例代码1234567891011121314151617181920212223242526272829303132333435363738// 新建一个工厂DefaultListableBeanFactory factory = new DefaultListableBeanFactory();// 新建一个 bean definitionGenericBeanDefinition beanDefinition = (GenericBeanDefinition) BeanDefinitionBuilder .genericBeanDefinition(SomeService.class) .setAutowireMode(GenericBeanDefinition.AUTOWIRE_BY_TYPE) .getBeanDefinition();// 注册到工厂factory.registerBeanDefinition(&quot;someService&quot;, beanDefinition);// 自己定义一个 bean post processor. 作用是在 bean 初始化之后, 判断这个 bean 如果实现了 ApplicationContextAware 接口, 就把 context 注册进去..(先不要管 context 哪来的...例子嘛)factory.addBeanPostProcessor(new BeanPostProcessor() &#123; @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; return bean; &#125; @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; if (bean instanceof ApplicationContextAware) &#123; GenericApplicationContext context = new GenericApplicationContext(factory); ((ApplicationContextAware) bean).setApplicationContext(context); &#125; return bean; &#125;&#125;);// 再注册一个 bean post processor: AutowiredAnnotationBeanPostProcessor. 作用是搜索这个 bean 中的 @Autowired 注解, 生成注入依赖的信息.AutowiredAnnotationBeanPostProcessor autowiredAnnotationBeanPostProcessor = new AutowiredAnnotationBeanPostProcessor();autowiredAnnotationBeanPostProcessor.setBeanFactory(factory);factory.addBeanPostProcessor(autowiredAnnotationBeanPostProcessor);// getBean() 时, 初始化SomeService SomeService = factory.getBean(&quot;someService&quot;,SomeService.class);SomeService.doSomething(); Spring Core中模块之间的依赖关系图 核心实现类最简单的BeanFactory：StaticListableBeanFactory 1234567891011121314151617181920212223242526272829303132333435363738394041public class StaticListableBeanFactory implements ListableBeanFactory &#123; private final Map&lt;String, Object&gt; beans; public StaticListableBeanFactory() &#123; this.beans = new LinkedHashMap(); &#125; public StaticListableBeanFactory(Map&lt;String, Object&gt; beans) &#123; Assert.notNull(beans, &quot;Beans Map must not be null&quot;); this.beans = beans; &#125; public void addBean(String name, Object bean) &#123; this.beans.put(name, bean); &#125; public Object getBean(String name) throws BeansException &#123; String beanName = BeanFactoryUtils.transformedBeanName(name); Object bean = this.beans.get(beanName); if (bean == null) &#123; throw new NoSuchBeanDefinitionException(beanName, &quot;Defined beans are [&quot; + StringUtils.collectionToCommaDelimitedString(this.beans.keySet()) + &quot;]&quot;); &#125; else if (BeanFactoryUtils.isFactoryDereference(name) &amp;&amp; !(bean instanceof FactoryBean)) &#123; throw new BeanIsNotAFactoryException(beanName, bean.getClass()); &#125; else if (bean instanceof FactoryBean &amp;&amp; !BeanFactoryUtils.isFactoryDereference(name)) &#123; try &#123; Object exposedObject = ((FactoryBean)bean).getObject(); if (exposedObject == null) &#123; throw new BeanCreationException(beanName, &quot;FactoryBean exposed null object&quot;); &#125; else &#123; return exposedObject; &#125; &#125; catch (Exception var5) &#123; throw new BeanCreationException(beanName, &quot;FactoryBean threw exception on object creation&quot;, var5); &#125; &#125; else &#123; return bean; &#125; &#125; ...&#125; 单例Bean对象的注册表类： 12345678910111213141516171819202122232425262728293031323334353637383940414243public class DefaultSingletonBeanRegistry extends SimpleAliasRegistry implements SingletonBeanRegistry &#123; /** Cache of singleton objects: bean name to bean instance. */ private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;&gt;(256); /** Cache of singleton factories: bean name to ObjectFactory. */ private final Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories = new HashMap&lt;&gt;(16); /** Cache of early singleton objects: bean name to bean instance. */ private final Map&lt;String, Object&gt; earlySingletonObjects = new HashMap&lt;&gt;(16); /** Set of registered singletons, containing the bean names in registration order. */ private final Set&lt;String&gt; registeredSingletons = new LinkedHashSet&lt;&gt;(256); /** Names of beans that are currently in creation. */ private final Set&lt;String&gt; singletonsCurrentlyInCreation = Collections.newSetFromMap(new ConcurrentHashMap&lt;&gt;(16)); /** Names of beans currently excluded from in creation checks. */ private final Set&lt;String&gt; inCreationCheckExclusions = Collections.newSetFromMap(new ConcurrentHashMap&lt;&gt;(16)); /** List of suppressed Exceptions, available for associating related causes. */ @Nullable private Set&lt;Exception&gt; suppressedExceptions; /** Flag that indicates whether we&#x27;re currently within destroySingletons. */ private boolean singletonsCurrentlyInDestruction = false; /** Disposable bean instances: bean name to disposable instance. */ private final Map&lt;String, Object&gt; disposableBeans = new LinkedHashMap&lt;&gt;(); /** Map between containing bean names: bean name to Set of bean names that the bean contains. */ private final Map&lt;String, Set&lt;String&gt;&gt; containedBeanMap = new ConcurrentHashMap&lt;&gt;(16); /** Map between dependent bean names: bean name to Set of dependent bean names. */ private final Map&lt;String, Set&lt;String&gt;&gt; dependentBeanMap = new ConcurrentHashMap&lt;&gt;(64); /** Map between depending bean names: bean name to Set of bean names for the bean&#x27;s dependencies. */ private final Map&lt;String, Set&lt;String&gt;&gt; dependenciesForBeanMap = new ConcurrentHashMap&lt;&gt;(64); ...&#125; Spring Bean实例的创建123456789101112131415// org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final @Nullable Object[] args) throws BeanCreationException &#123; // Instantiate the bean. ... instanceWrapper = createBeanInstance(beanName, mbd, args); // line 555 ... // inject dependencies for bean properties populateBean(beanName, mbd, instanceWrapper); // line 592 exposedObject = initializeBean(beanName, exposedObject, mbd); ... return exposedObject;&#125; createBeanInstance方法如下： 12345678910111213141516171819202122232425262728293031323334353637// org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory line 759protected BeanWrapper createBeanInstance(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) &#123; Class&lt;?&gt; beanClass = this.resolveBeanClass(mbd, beanName, new Class[0]); if (beanClass != null &amp;&amp; !Modifier.isPublic(beanClass.getModifiers()) &amp;&amp; !mbd.isNonPublicAccessAllowed()) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, &quot;Bean class isn&#x27;t public, and non-public access not allowed: &quot; + beanClass.getName()); &#125; else &#123; Supplier&lt;?&gt; instanceSupplier = mbd.getInstanceSupplier(); if (instanceSupplier != null) &#123; return this.obtainFromSupplier(instanceSupplier, beanName); &#125; else if (mbd.getFactoryMethodName() != null) &#123; return this.instantiateUsingFactoryMethod(beanName, mbd, args); &#125; else &#123; boolean resolved = false; boolean autowireNecessary = false; if (args == null) &#123; synchronized(mbd.constructorArgumentLock) &#123; if (mbd.resolvedConstructorOrFactoryMethod != null) &#123; resolved = true; autowireNecessary = mbd.constructorArgumentsResolved; &#125; &#125; &#125; if (resolved) &#123; return autowireNecessary ? this.autowireConstructor(beanName, mbd, (Constructor[])null, (Object[])null) : this.instantiateBean(beanName, mbd); &#125; else &#123; Constructor&lt;?&gt;[] ctors = this.determineConstructorsFromBeanPostProcessors(beanClass, beanName); if (ctors == null &amp;&amp; mbd.getResolvedAutowireMode() != 3 &amp;&amp; !mbd.hasConstructorArgumentValues() &amp;&amp; ObjectUtils.isEmpty(args)) &#123; ctors = mbd.getPreferredConstructors(); return ctors != null ? this.autowireConstructor(beanName, mbd, ctors, (Object[])null) : this.instantiateBean(beanName, mbd); &#125; else &#123; return this.autowireConstructor(beanName, mbd, ctors, args); &#125; &#125; &#125; &#125; &#125; 经过多次弯弯绕之后，终于来到了最终的实例化方法： 1234567891011121314151617// org.springframework.beans.BeanUtils line 49public static &lt;T&gt; T instantiateClass(Constructor&lt;T&gt; ctor, Object... args) throws BeanInstantiationException &#123; Assert.notNull(ctor, &quot;Constructor must not be null&quot;); try &#123; ReflectionUtils.makeAccessible(ctor); return KotlinDetector.isKotlinReflectPresent() &amp;&amp; KotlinDetector.isKotlinType(ctor.getDeclaringClass()) ? BeanUtils.KotlinDelegate.instantiateClass(ctor, args) : ctor.newInstance(args); &#125; catch (InstantiationException var3) &#123; throw new BeanInstantiationException(ctor, &quot;Is it an abstract class?&quot;, var3); &#125; catch (IllegalAccessException var4) &#123; throw new BeanInstantiationException(ctor, &quot;Is the constructor accessible?&quot;, var4); &#125; catch (IllegalArgumentException var5) &#123; throw new BeanInstantiationException(ctor, &quot;Illegal arguments for constructor&quot;, var5); &#125; catch (InvocationTargetException var6) &#123; throw new BeanInstantiationException(ctor, &quot;Constructor threw exception&quot;, var6.getTargetException()); &#125; &#125; 可见，本质上还是使用反射来获取构造函数，实现对象的实例化的。 Spring Bean的销毁1234567891011121314151617181920212223242526/** * Actually performs context closing: publishes a ContextClosedEvent and * destroys the singletons in the bean factory of this application context. * &lt;p&gt;Called by both &#123;@code close()&#125; and a JVM shutdown hook, if any. * @see org.springframework.context.event.ContextClosedEvent * @see #destroyBeans() * @see #close() * @see #registerShutdownHook() */ protected void doClose() &#123; // Publish shutdown event. publishEvent(new ContextClosedEvent(this)); // Stop all Lifecycle beans, to avoid delays during individual destruction. this.lifecycleProcessor.onClose(); // Destroy all cached singletons in the context&#x27;s BeanFactory. destroyBeans(); // Close the state of this context itself. closeBeanFactory(); // Let subclasses do some final clean-up if they wish... onClose(); &#125; &#125;","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"}]},{"title":"java annotation (1)","slug":"java annotation 1","date":"2019-12-11T01:45:02.000Z","updated":"2023-11-20T02:27:39.767Z","comments":true,"path":"2019/12/11/java annotation 1/","link":"","permalink":"http://example.com/2019/12/11/java%20annotation%201/","excerpt":"","text":"在各种流行的Java开发框架比如Spring boot中，大量使用了注解Annotation来做自动化配置。学习Spring有必要先了解一下注解。注解是从Java 1.5版本开始加入到Java语言中的，因其便利性逐渐被Java开发者广泛接受。那么，注解到底是什么东西呢？ 注解的定义就个人理解，注解就是贴在程序源码上的语法标签，为编译器和JVM提供关于被贴代码（类、方法、构造函数、变量、参数等等）的一些辅助信息，这些信息可以帮助编译器做一些额外处理（比如@Overrride注解告诉编译器需要检查是否真的做了方法覆盖），或者让JVM在加载这段代码时做必要的前置工作（比如@DependsOn注解告知JVM需要先加载所依赖的类）。我看到的比较靠谱的注解定义在这里。 元注解Java语言提供如下元注解： @Override典型的标记类注解，作用是明确告知编译器该方法Override了基类、接口、Object等的共有方法。编译器将对该注解标记的方法进行检查，若发现不符合Override定义，会直接报错。 @Deprecated标记类注解，标记方法已被弃用。如果有人继续使用该方法，编译器将抛出警告⚠️。 @SuppressWarnings让编译器忽略指定的一种或多种编译器警告。 @Retention指定被它标记的注解的存储位置，从而决定它的生命周期。比如RetentionPolicy.SOURCE 定义注解只存储在源码中，不会被编译进.class文件，那么注解的生命周期也就被限制在源码编译成字节码之前。 默认值为RetentionPolicy.CLASS。 @Target指定被它标记的注解的作用目标。目前取值有TYPE,FIELD,METHOD,PARAMETER,CONSTRUCTOR,LOCAL_VARIABLE,ANNOTATION_TYPE,PACKAGE,TYPE_PARAMETER,TYPE_USE。 @Documented标记文档生成工具在生成的文档中包含被它标记的注解。 @Inherited定义Java子类在继承父类时，同时继承拥有这个元注解的注解。注意，只针对普通类之间的继承，接口继承、接口实现时不会继承注解。 @Repeatable定义注解可以多次重复应用于相同的目标Target。 @Native标记目标常量可以被native代码引用。 @FunctionalInterface该注解用于标记函数式接口。加上该注解后，若编写的接口不符合函数式接口的定义，编译器将报错。 @SafeVarargs针对可变参数构造函数或方法生效，让编译器忽略unchecked警告⚠️。 自定义注解 我们可以通过组合现有注解的方式来定义新的注解。注解的定义语法如下： 123[Access Specifier] @interface &lt;AnnotationName&gt; &#123; DataType &lt;Method Name&gt;() [default Value];&#125; 参照以上语法和现有元注解，我们可以自定义如下新注解： 12345@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)public @interface HelloAnnotation &#123; String value() default &quot;Hi&quot;;&#125; 然后，可以像其他注解一样使用： 1234567@HelloAnnotation(&quot;Hello&quot;)public class MyApplication &#123; public static void main(String[] args) &#123; HelloAnnotation annotation = MyApplication.class.getAnnotation(HelloAnnotation.class); System.out.println(annotation.value()); &#125;&#125;","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"}]},{"title":"使用netlify自动发布hexo博客","slug":"hexo-with-netlify","date":"2019-12-08T12:30:01.000Z","updated":"2020-03-30T08:30:12.000Z","comments":true,"path":"2019/12/08/hexo-with-netlify/","link":"","permalink":"http://example.com/2019/12/08/hexo-with-netlify/","excerpt":"","text":"使用hexo博客发布一篇博文的流程为： 12hexo n &quot;a new post&quot;hexo g -d 以上操作将博文的.md文件编译成.html文件，连同资源文件一起打包发布到网站空间里。对于.md源文件，默认是没有版本控制的。 为了防止丢失、误删，以及使用多个电脑管理博客，我们需要为hexo工程建一个单独的git仓库，并同步到github、coding等托管平台。实际使用中，除了上面列出来的两条命令外，还需要执行以下操作： 123git add .git commit -m &quot;add a new post, bla bla bla&quot;git push 我正在尝试一种新方式，使用netlify来做持续集成和自动部署。在source&#x2F;_posts目录下新建一个.md文件用来写博文，可以用任何markdown编辑器来写，写完后直接add commit push即可。具体命令为： 123git add .git commit -m &quot;add a new post, bla bla bla&quot;git push 这种新方式非常灵活，不需要hexo命令，也就不需要在每台电脑上安装hexo以及所依赖的node.js, npm等。只需要电脑上有git即可操作。 netlify配置步骤，可参考官方blog：A Step-by-Step Guide: Hexo on Netlify","categories":[],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://example.com/tags/Hexo/"}]},{"title":"Homebrew每次装软件都卡在更新界面怎么办？","slug":"accelerate-homebrew-install","date":"2019-12-08T03:15:03.000Z","updated":"2023-11-20T02:27:39.758Z","comments":true,"path":"2019/12/08/accelerate-homebrew-install/","link":"","permalink":"http://example.com/2019/12/08/accelerate-homebrew-install/","excerpt":"","text":"自从用上Mac，Homebrew就成了一个绕不开的工具。Homebrew是Mac的软件包管理工具，作用相当于CentOS上的yum。Mac上的好多软件，都需要用Homebrew安装。基本上使用brew install &lt;packageName&gt;或者brew cask install &lt;packageName&gt;就能一步到位装好软件了。但是头疼的是，我在运行brew install的时候，经常会提示Updating Homebrew...，然后卡住好几分钟，也不知道后台实际上在干些什么，体验很不好。截图如下： 一般遇到这种情况，直接使用control + C快捷键就可以打断更新，直接进入后续的install环节。control + C一时爽，可是如果每次都要这样操作，却有违俺样的美学。所谓知其然，还要知其所以然。于是收集各种网上资料，并结合自己的实践测试了一下，对卡顿原因有了一定的了解。 问题分析检查Homebrew脚本代码 /usr/local/Homebrew/Library/Homebrew/brew.sh可以发现，Homebrew在执行install操作时，默认会先去更新自己。 而更新操作，实际上是调用git pull从Homebrew位于github的官方镜像仓库拉取最新的版本到本地仓库（即Homebrew的安装目录）。如果github被墙或者访问速度太慢，就会出现卡顿现象。 可以使用brew update --verbose测试一下实际的更新速度，感受一下实际的卡顿： 解决方法：弄明白原因后，就可以对症下药了。 总的来说，要解决这个卡顿问题，有三种方法： 一是简单粗暴直接禁用brew update，二是使用国内镜像源，三是延长update的检查时间间隔。 方法1: 禁用brew update设置环境变量HOMEBREW_NO_AUTO_UPDATE即可。这里需要区分一下shell种类，可以使用echo $SHELL命令查看。针对/bin/zsh, 执行如下命令： 12echo &#x27;export HOMEBREW_NO_AUTO_UPDATE=true&#x27; &gt;&gt; ~/.zshrcsource ~/.zshrc 针对/bin/bash, 执行如下命令： 12echo &#x27;export HOMEBREW_NO_AUTO_UPDATE=true&#x27; &gt;&gt; ~/.bash_profilesource ~/.bash_profile 禁用之后，如果需要更新brew包，可以执行如下命令： 12brew update &amp;&amp; brew upgrade &amp;&amp; brew cleanup ; say brew updatedbrew update &amp;&amp; brew upgrade brew-cask &amp;&amp; brew cleanup ; say brew-cask updated 方法2: 更换更快的镜像源可选的镜像源有： 清华：git:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;homebrew.git 中科大：http://mirrors.ustc.edu.cn/homebrew.git Coding.net：https://git.coding.net/homebrew/homebrew.git这里我使用了清华的镜像源，操作命令如下：12345git -C &quot;$(brew --repo)&quot; remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/brew.gitgit -C &quot;$(brew --repo homebrew/core)&quot; remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-core.gitgit -C &quot;$(brew --repo homebrew/cask)&quot; remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-cask.git 顺便也可以设置一下Homebrew二进制预编译包的镜像地址，具体需要通过设置环境变量HOMEBREW_BOTTLE_DOMAIN来实现。这里也需要区分一下shell版本： 如果使用 /bin/zsh， 则执行如下命令： 12echo &#x27;export HOMEBREW_BOTTLE_DOMAIN=https://mirrors.tuna.tsinghua.edu.cn/homebrew-bottles&#x27; &gt;&gt; ~/.zshrcsource ~/.zshrc 而如果使用为/bin/bash，则执行如下命令： 12echo &#x27;export HOMEBREW_BOTTLE_DOMAIN=https://mirrors.tuna.tsinghua.edu.cn/homebrew-bottles&#x27; &gt;&gt; ~/.bash_profilesource ~/.bash_profile 然后重新执行一下： 12cd $homebrew update 装两个软件试试：卡顿有了明显改善。:) 方法3: 延长自动update的检查间隔时间通过阅读源码或帮助文档manpage，发现可以通过设置环境变量HOMEBREW_AUTO_UPDATE_SECS来控制检查更新的间隔时间。 在近期发布的Homebrew 2.2.0版本，也提到了一个主要更新feature： HOMEBREW_AUTO_UPDATE_SECS 的无操作情况明显更快，默认为 5 分钟（而不是 1 分钟）。 这在homebrew&#x2F;brew的代码中也得到了证实： 可见，Homebrew官方自己也认为这个时间设置的太短了没啥意义。 考虑到我们装软件是个低频操作，不会天天装软件，犯不着每次装软件都去检查一次更新。这个环境变量的取值可以设置的大胆一些，比如一个月，或着两周。设置方法跟本文中其他环境变量的方式相同，这里不再赘述。 注意，这种方法只是尽可能延迟检查更新的时间，达到减少更新次数的目的，并不能完全避免卡顿，所以显得比较鸡肋。个人更喜欢第二种方法，更换更快的镜像源。","categories":[],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"}]},{"title":"log this hexo setup","slug":"log-this-hexo-setup","date":"2019-12-08T02:10:29.000Z","updated":"2023-11-20T07:05:56.627Z","comments":true,"path":"2019/12/08/log-this-hexo-setup/","link":"","permalink":"http://example.com/2019/12/08/log-this-hexo-setup/","excerpt":"","text":"setup your hexo blog with github pages hostinginstall hexofirst, install these two npm packages: hexo-cli, hex-deployer-git 12npm install -g hexo-clinpm install hexo-deployer-git --save create a hexo projectcreate a hexo project with the same name as your github repo 1hexo init ocre.github.io create a new post script1hexo new &quot;my first hexo blog&quot; verify your hexo project: 1hexo server and you will get a running hexo site at http://localhost:4000/ create github pages repocreate a new github repoistory named as ‘your_github_username’.github.io deploy to githubmodify git config in _config.yml script123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: git@github.com:ocre/ocre.github.io.git branch: master test deploy script12hexo generatehexo deploy verify it via https://ocre.github.io Mission Complete!","categories":[],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://example.com/tags/Hexo/"}]}],"categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://example.com/tags/Linux/"},{"name":"redis","slug":"redis","permalink":"http://example.com/tags/redis/"},{"name":"yum","slug":"yum","permalink":"http://example.com/tags/yum/"},{"name":"Tools","slug":"Tools","permalink":"http://example.com/tags/Tools/"},{"name":"DevOps","slug":"DevOps","permalink":"http://example.com/tags/DevOps/"},{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"},{"name":"数据分析","slug":"数据分析","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"},{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"http://example.com/tags/PostgreSQL/"},{"name":"Database","slug":"Database","permalink":"http://example.com/tags/Database/"},{"name":"node.js","slug":"node-js","permalink":"http://example.com/tags/node-js/"},{"name":"SQL","slug":"SQL","permalink":"http://example.com/tags/SQL/"},{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"},{"name":"example","slug":"example","permalink":"http://example.com/tags/example/"},{"name":"Javascript","slug":"Javascript","permalink":"http://example.com/tags/Javascript/"},{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"},{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"Git","slug":"Git","permalink":"http://example.com/tags/Git/"},{"name":"PHP","slug":"PHP","permalink":"http://example.com/tags/PHP/"},{"name":"Django","slug":"Django","permalink":"http://example.com/tags/Django/"},{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://example.com/tags/Elasticsearch/"},{"name":"Architecture","slug":"Architecture","permalink":"http://example.com/tags/Architecture/"},{"name":"API","slug":"API","permalink":"http://example.com/tags/API/"},{"name":"Programing","slug":"Programing","permalink":"http://example.com/tags/Programing/"},{"name":"Hexo","slug":"Hexo","permalink":"http://example.com/tags/Hexo/"},{"name":"JSON","slug":"JSON","permalink":"http://example.com/tags/JSON/"},{"name":"Scrapy","slug":"Scrapy","permalink":"http://example.com/tags/Scrapy/"},{"name":"Conda","slug":"Conda","permalink":"http://example.com/tags/Conda/"},{"name":"Docker","slug":"Docker","permalink":"http://example.com/tags/Docker/"},{"name":"Authorization","slug":"Authorization","permalink":"http://example.com/tags/Authorization/"}]}